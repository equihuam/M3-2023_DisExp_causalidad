{
  "hash": "6109b9fafd5f403918f55d697bbbe36d",
  "result": {
    "markdown": "---\ntitle: \"Diagramas Causales\"\nauthor: [\"Miguel Equihua\", \"Octavio Pérez Maqueo\", \"Elio Lagunes\"]\ndate: \"2024-01-31\"\nlang: es\ndraft: false\ncategories: [clase]\nformat:\n  html:\n    code-fold: true\n---\n\n\n![](images/autores_y_The_Book_of_Why.jpg){width=\"500\"}\n\nJudea Pearl se ha aproximado a la causalidad desde una peerspectiva matemática y computacional. En ese camino retomó y dio un nuevo impulso a los llamados [modelos probabilísticos gráficos](https://eduzaurus.com/free-essay-samples/history-of-probabilistic-graphical-model/) en su variante de *redes Bayesianas.* También ha incursionado en los llamados *modelos de ecuaciones estructuradas*, también de la familia de los modelos gráficos. Todo ello vinculado con los *Gráfos Acíclicos Dirigidos*, a los que llamaremos **DAG** (del inglés directed acyclic graphs). Pearl y colaboradores así como otros investigadores ahora, han venido desarrollando la teoría que nos permite analizar tales **DAG**s para comprender los patrones de dependencia causal así como los de correlación que implica una proposición causal dada. En esta contribución buscamos mostrarles algunos elementos interesantes de esto y con ello, animarlos a estudiar estas ideas con mayor profundidad.\n\n\\\n\\\n\\\n\n::: {layout=\"[[-1, 2, -1], [-1, 2, -1]]\"}\n[![](images/web-6704764_1280.jpg)](../../presentaciones/04-diagramas-causales/Diagramas Causales.qmd)\n\nHaz click sobre la imágen para ver la presentación\n:::\n\n\\\n\\\n\\\n\n# Dudas sobre puerta trasera\n\nLa cuestión que se nos complicó más en la clase de hoy fue el asunto de la _puerta trasera_. Aquí retomo el tema alrededor de la pregunta sobre _aspirina_ en la que nos atoramos.\n\nPara referencia esta son la pregunta y **DAG** asociados:\n\n![](images/asprina.png)\n\nLos autores de este ejemplo, [Hernan & Robins](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) explican lo siguiente:\n\n![](images/sesgo-por-inidicacion.png)\n\n### Confusión por indicación o _prescripción_\n\nEl contexto de este **DAG** se relaciona con la práctica farmacoepidemiológica al realizar estudios observacionales del efecto de los medicamentos, con protocolos en los que se comparan los resultados de personas que toman medicamentos específicos contra los de personas que no los toman (aunque pueden, por ejemplo, tomar otro tipo de medicación). En estos estudios, los participantes o sus médicos eligen si van a tomar o no los medicamentos. Por tanto, la asignación del tratamiento dista mucho de ser aleatoria. Se suelen hacer como seguimiento una vez liberado un fármaco en el mercado. La _confusión por indicación_ es un sesgo que se encuentra con frecuencia en estos estudios observacionales farmacoepidemiológicos de los efectos de los fármacos. \n\nPara obtener más ayuda, les recomendamos acercarse a [dagitty](http://dagitty.net), que es un sitio de aprendizaje y uso de **DAGs**. Ahí hay una herramienta de dibujo de **DAGs** y permite explorar opciones para el diseño de estudios y _recibir consejos_ sobre la calidad de la estimación que distintos enfoques de diseño pueden ofrecer. Esta herramienta también está disponible como una biblioteca para **R**. Con esta herramienta produjimos este resultado. \n\n![](images/dagitty.png)\n\n### Simulardor computacional para aprender \n\nContruyamos un conjunto de datos artificial que tenga las propiedades que especifica el **DAG**. Que sean, digamos, 1000 pacientes tomados aleatoriamente de la comunidad en nuestro vecindario.  \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nset.seed(2024) # Habilita Repetibilidad\nn <- 1000 # Tamaño de muestra\n```\n:::\n\n\nAhora, Cada uno de ellos puede estar afectado, en forma continua, por la arteriosclerosis, U, aunque en el ejemplo esto no es observable, pero el paciente sí tiene ese efecto encima. Lo representaremos con números que pueden ser negativos o positivos, digamos que en cero el paciente está normalmente sano, por abajo mejor salud (en cuanto a este mal) y por arria de cero tiene mayor grado del padecimiento. Para no complicarnos podemos elegir razonablemente que estos números se parezcan a una distribución normal.\n\nAlgo semejante ocurre con la enfermedad cardíaca, salvo que la agrava la presciencia de arteriosclerosis en el paciente. Digamos que la enfermedad cardíaca puede ser cero ( la condición que tiene un paciente normal), menor quue cero entre más sano más pequeño este valor) y los valores positivos indica que está enfermo. Además, el mal se agrava añadiendo 10 veces el grado de arteriosclerosis que padezca el paciente. Todo esto, nos lleva a estas líneas de cálculo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# De acuerdo con el ejemplo\nU <- rnorm(n)  # Arteriosclerosis\nT <- 10 * U + rnorm(n)  # Enfermedad cardíaca\n```\n:::\n\n\nUn poquito más complicado es el factor aspirina. Se trata de un tratamiento que el paciente recibe o no, según su condición  también lo que le **haya indicado el médico**. Es una variable categórica. Hay varias formas de hacerlo, pero les muestro aqui un camino que pienso es más fácil de seguir para un lector sin experiencia computacional. \n\nPrimero, considero que entre los 1000 pacientes algunos ya toman aspirina y otros no\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tratamiento con aspirina \nA <- sample(c(\"con aspirina\", \"sin aspirina\"), n, replace = TRUE)\n```\n:::\n\n\nAhora, a todos los pacientes que sean detectados con _enfermedad cardiaca_ se les indica tomar aspirina y supondremos que todos ellos la tomarán.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA[T > 0 ] <-  \"con aspirina\"\nA <- factor(A, levels = c(\"sin aspirina\", \"con aspirina\"))\n```\n:::\n\n\nFinalmente, calculamos la respuesta de los pacientes al tratamiento y a los padecimientos que lo afectan y ponemos todos los datos en una tabla.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nY <-  -2 * (A==\"con aspirina\") + 2 * T + U + rnorm(n)  # Accidente cerebral\n\n# Para comodidad de cálculo junto los datos en una tabla, un \"data.frame\"\ndatos_aspirina <- tibble(U, T, A, Y)\n```\n:::\n\n\nEl modelo real es por lo tanto:\n\n$$\nY = -2 A +  2T + U\n$$\n\n#### Situación erronea, no se controló el factor de confusión *enfermedad cardíaca*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ A, datos_aspirina)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ A, data = datos_aspirina)\n\nCoefficients:\n  (Intercept)  Acon aspirina  \n       -15.28          18.02  \n```\n:::\n:::\n\n\n#### Situación apropiada, control de factor de confusión por *enfermedad cardíaca*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ A + T, datos_aspirina)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ A + T, data = datos_aspirina)\n\nCoefficients:\n  (Intercept)  Acon aspirina              T  \n      0.04985       -2.08984        2.09974  \n```\n:::\n:::\n\n\n#### Situación imposile en la práctica, control de factor de confusión por *enfermedad cardíaca* y documentación de una _variable no observada_.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ A + T + U, datos_aspirina)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ A + T + U, data = datos_aspirina)\n\nCoefficients:\n  (Intercept)  Acon aspirina              T              U  \n      0.04904       -2.08483        1.97986        1.20793  \n```\n:::\n:::\n\n\n\n\n# Los DAG y modelos estadísticos\n\n$\\newcommand{\\ci}{\\perp\\!\\!\\!\\perp\\!\\!\\!~~~}$\n\n<img src=\"https://images.ecestaticos.com/MKj85n1PcWWKTkz_KGAbBek3-gk=/0x0:783x1200/490x752/filters:fill(white):format(.JPG)/f.elconfidencial.com/original/576/350/da1/576350da1a73890bf7e9710e9f63c5fe.jpg\" style=\"float: right;\" width=\"20%\"/>\n\n[Lübkea K, et. al (2020)](https://www.tandfonline.com/doi/full/10.1080/10691898.2020.1752859). nos ofrecen el artículo *Why We Should Teach Causal Inference: Examples in Linear Regression With Simulated Data*. La propuesta es atractiva y vamos a ensayar hacerlo. Esta publicación, dicen los propios autores, surge de que desde hace ya algunos años se ha venido señalando la importancia de propiciar la integración de la inferencia causal (**DAG**s y similares) en los cursos introductorios de estadística. Judea Pearl llama a este enfoque la \"revolución causal\". Con su obra **El libro del Porqué** ha logrado incrementar el interés en hacer esta fusión en la enseñanza de la estadística.\\\n\\\n\\\n\n<img src=\"images/guia_autores_confunding.png\" style=\"float:left;\" width=\"40%\"/>La influencia de este modo de pensar es tal que está provocando incluso que algunas revistas se interesen en generar guias de uso de estas ideas, por ejemplo: *Control of Confounding and Reporting of Results 1n Causal Inference Studies Guidance for Authors...*. En gran parte, la tradición de experimentos aleatorizados ofrece una sólida herramienta para estudiar relaciones causales. El problema, es que hay muchas disciplinas y más situaciones, en donde el enfoque de experimentos aleatorizados es inviable.\n\nEl hecho es que los datos observacionales son una proporción abrumadora de la materia prima para la investigación empírica. Por lo tanto es necesario que, además de adquirir las destrezas que los experimentos aleatorizado requieren, también deben aprender a pensar en una forma más amplia acerca del proceso a través del cual se generan los datos. Esto es indispensable para fortalecer habilidades críticas necesarias para estar en posibilidad de extraer conclusiones adecuadas a partir de ellos.\n\nUn tema importante es comprender que en la inferencia causal, además de la habilidad para observar y operar con los datos, la **evaluación contrafáctica** es necesaria para lograr una comprensión más profunda de lo que se puede y quizás aún más importante, lo que no se puede deducir del análisis de un conjunto de datos.\n\nEn la siguiente sección vamos a seguir este camino con uno de los ejemplos que nos proponen Lübkea K, et. al (2020).\n\nVivimos en un mundo pleno de datos observacionales multivariados. Se trata de datos en lo que también abundan los procesos que pueden generar confusión (en el sentido estadístico, además del cognitivo), y se tiene importantes dificultades para llegar a conclusiones.\n\n## Ejemplo: Efectos de sesgo en las causas\n\nEl primer ejemplo de simulación que haremos parte de la proposición causal:\n\n-   El aprendizaje (X) tiene como efecto el conocimiento (C), y conocer provoca la comprensión (Y),\n\nAdemás actúan algunos factores exógenos (U, son el término de error en el modelo estadístico). En la vida real, el aprendizaje, el conocimiento y la comprensión pueden ser operacionalizados por algún cuestionario y estandarizados para dar la precisión necesaria al análisis.\n\nEl ejemplo consiste ahora en producir un conjunto de datos que cumpla, por diseño, con la descripción que acabo de hacer. En este caso utilizaremos las ecuaciones siguientes.\n\n$$\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\ \nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n$$\n\nen donde *N*(*μ*, *σ*) indica que existen variaciones por causas no observadas que vamos a suponer generan oscilaciones aleatorias o un *ruido*, cuya distribución es semejante a la que produciría una distribución Normal de probabilidades. Ahora escribimos estas ecuaciones en un escript de **R**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1896) # Si interesa repetir la misma secuencia de numeros aleatorios. Habilita Repetibilidad\nn <- 1000 # Sample Size\n\naprender <- rnorm(n)\nconocer <- 5 * aprender + rnorm(n)  # Conocer depende del comportamiento de aprender\nentender <- 3 * conocer + rnorm(n)  # entender depende del comportamiento de conocer\n\n# Para comodidad de cálculo junto los datos en una tabla, un \"data.frame\"\ndatos <- data.frame(aprender, conocer, entender)\n```\n:::\n\n\nEl **DAG** que describe la situación descrita lo podemos producir en **R** con ayuda de la biblioteca DAGitty. Con las instrucciones siguentes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dagitty)\n\nejemplo_1_DAG <- dagitty('dag{\n                     aprender -> conocer\n                     conocer -> entender\n\n                     aprender[exposure, pos=\"0,0\"]\n                     conocer[pos=\"1,0\"]\n                     entender[outcome, pos=\"2,0\"]}')\noptions(repr.plot.width=10, repr.plot.height=3)\npar(cex=2, lwd = 5)\nplot(ejemplo_1_DAG)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nSi optamos por no \"corregir\" la estimación por el efecto del mediador, Supondríamos que el efecto total del aprendizaje sobre el entendimiento no tiene sesgo. La estimación de esta relación la obtenemos con el modelo que calculamos en `ejemplo_1_ecuación_1`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nejemplo_1_ecuacion_1 <- lm(entender ~ aprender)\nsummary(ejemplo_1_ecuacion_1)$coefficients[,1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Estimate Std. Error\n(Intercept) -0.02227676 0.09661146\naprender    15.12087585 0.09781602\n```\n:::\n:::\n\n\n¿Qué piensas de este resultado? ¿El modelo es congruente con la proposición causal? Si ahora optamos por sí \"corregir\" los efectos considerando que el *conocimiento* puede estar interfiriendo la estimación del efecto total del aprendizaje sobre el entendimiento. Ahora, el modelo que da cuenta de esta nueva situación es el que calculamos en `ejemplo_1_ecuación_2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nejemplo_1_ecuacion_2 <- lm(entender ~ aprender + conocer)\nsummary(ejemplo_1_ecuacion_2)$coefficients[,1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                Estimate Std. Error\n(Intercept) -0.004947807 0.03077153\naprender     0.121514701 0.16253665\nconocer      2.981736249 0.03171170\n```\n:::\n:::\n\n\nLos resultados de esta exploración produce dos ecuaciones:\n\n$$\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\ \nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n$$\n\n$$\n\\begin{align}\nentender &= -0.022 + 15.12 \\, aprender  + \\varepsilon \\\\\nentender &= -0.005 +  0.122 \\, aprender + 2.98 \\, conocer + \\varepsilon \n\\end{align}\n$$\n\n-   [¿Puedes explicar qué pasó aquí?]{style=\"color:GoldenRod\"}\n\n-   [¿Qué relación tiene esto con lo que cabría esperar de acuerdo con as reglas de la \"separación direccional\"?]{style=\"color:GoldenRod\"}\n\n-   [¿Qué sugieren los datos del ajuste del modelo estadístico `lm`?]{style=\"color:GoldenRod\"}\n\n-   [¿Tienen relevancia el aprendizaje y el conocimiento?]{style=\"color:GoldenRod\"}\n\n-   [¿Cuál es el modelo adecuado dada la proposición causal considerada?]{style=\"color:GoldenRod\"}\n\nPodemos utilizar a `dagitty` para explorar el DAG directamente de la siguiente manera. Podemos preguntarnos cuales serían las formas de *separar* el grafo con criterios de independencia condicional. Se trata de aplicar las tres reglas de separación direccional al grafo. Afortunadamente `dagitty` lo puede hacer por nosotros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimpliedConditionalIndependencies(ejemplo_1_DAG)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\naprn _||_ entn | cncr\n```\n:::\n:::\n\n\n¿Qué indica este resultado?\n\n$$\naprender \\,\\, \\ci \\,\\, entender \\,\\, | \\,\\, conocer\n$$\n\nAdemás de hacer esto por nosotros, la biblioteca `dagitty` nos permite poner a prueba la correspondencia de los datos con estas ideas. Lo hacemos con la función `localTests`.\n\nLa función `localTests` calcula el coeficiente de correlación de Pearson para cada condición considerada. El resultado incluye el valor *p* y el intervalo de confianza del coeficiente de correlación para cada una de las relaciones de **independencias condicionales implicadas** por la estructura del modelo.\n\nEl coeficiente de correlación de Pearson varía entre -1 y 1. El valor 0 implica que no hay correlación, mientras que -1 o 1 implica una correlación lineal perfecta.\n\nEl valor *p* de la prueba indica la probabilidad de obtener un conjunto de datos como el que se tiene, asumiendo la hipótesis de que la *condición de independencia* correspondiente es verdadera.\n\nPor lo tanto, un coeficiente de correlación cercano a 0 con un valor *p* alto es sugerente de que la *independencia condicional* indicada es congruente con el patrón detectable en los datos.\n\nPor el contrario, un valor alto del coeficiente de correlación con un valor *p* bajo sugiere que la *independencia condicional* considerada no es congruente con el conjunto de datos.\n\nLas columnas etiquetadas com 2.5% y 97,5% contienen el intervalo de confianza del 95% para el coeficiente de correlación.\n\nCuanto más estrecho sea el intervalo de confianza y alejado de cero resulte, más fuerte será la evidencia de que la independencia condicional que implica el DAG no se mantiene en el conjunto de datos disponible para el ensayo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# El tipo de análisis \"cis\" usa regresión lineal para poner a prueba la correlación\nejemplo_1_analisis_DAG <- localTests(x=ejemplo_1_DAG, data=datos, type=\"cis\") \n\nprint(ejemplo_1_analisis_DAG)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        estimate   p.value        2.5%      97.5%\naprn _||_ entn | cncr 0.02367054 0.4549614 -0.03840997 0.08556934\n```\n:::\n:::\n\n\nSi lo preferimos, podemos obtener una representación gráfica de estos resultados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repr.plot.width=14, repr.plot.height=5)\npar(cex=1.5, lwd = 3, oma = c(1,2,1,1), mar = (c(4,2,1,1) + 0.5))\nplotLocalTestResults(ejemplo_1_analisis_DAG, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n### [**¿Puedes comentar tu interpretación de estos resultados del modelo y los datos sobre aprendizaje y conocimiento?**]{style=\"color:GoldenRod\"}\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}