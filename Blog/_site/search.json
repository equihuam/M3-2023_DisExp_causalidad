[
  {
    "objectID": "presentaciones.html",
    "href": "presentaciones.html",
    "title": "M3-Presentaciones",
    "section": "",
    "text": "Leyes de la Ciencia\n\n\nDiseño de estudios y experimentos\n\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nModelo Estadístico Lineal\n\n\nmodelación y prueba de hipótesis\n\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio G. Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nIntroducción a Diagramas Causales\n\n\n\n\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio G. Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nMedidas Repetidas\n\n\n\n\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n\n\n8 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nInfraestructura de Experimentación\n\n\nalgunos ejemplos\n\n\n\n\npresentación\n\n\n\n\n\n\n\n\n\n\n\n8 feb 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio G. Lagunes\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-escalera-de-la-causalidad",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-escalera-de-la-causalidad",
    "title": "Introducción a Diagramas Causales",
    "section": "",
    "text": "Pearl, Judea. The Book of Why: The New Science of Cause and Effect (p. 28). Basic Books."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#terminología-básica-de-un-dag",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#terminología-básica-de-un-dag",
    "title": "Introducción a Diagramas Causales",
    "section": "Terminología básica de un DAG",
    "text": "Terminología básica de un DAG\n\n\n\nNodo : una variable\nArista : una relación causal, representada por una flecha\nVariable Explicativa : Es nuestro predictor causal de interés. Aquí es la representada por X . También se le llama variable independiente.\nRespuesta : En el DAG es la representada por Y . También se le llama variable dependiente.\nAncestros : Nodos que están “aguas arriba” de una variable dada. En este DAG A y C son ancestros de X .\nDescendientes : Nodos que están “aguas abajo” de una variable en particular. En este DAG Y y B son descendientes de X ."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#b-es-una-variable-mediadora-del-efecto-de-a",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#b-es-una-variable-mediadora-del-efecto-de-a",
    "title": "Introducción a Diagramas Causales",
    "section": "B es una variable “mediadora” del efecto de A",
    "text": "B es una variable “mediadora” del efecto de A"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#papel-de-las-variables-en-un-dag",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#papel-de-las-variables-en-un-dag",
    "title": "Introducción a Diagramas Causales",
    "section": "Papel de las variables en un DAG",
    "text": "Papel de las variables en un DAG\n\n\n\nFactor de Confusión : Es ancestro tanto de la explicativa X como de la respuesta Y . A lo es el DAG .\nMediador : Es al mismo tiempo descendiente de la explicativa y ancestro de la respuesta. F lo es. Parte (o la totalidad) del efecto causal sobre la respuesta se transmite a través de él.\nProxy de un Factor de Confusión : Es descendiente de un factor de confusión y ancestro de la explicativa o de la respuesta (pero no de ambas, pues entonces sería un factor de confusión). El efecto de confusión se transmite a través de esta variable. B es proxy.\nCompetidor de la explicativa : Es un ancestro de la variable de respuesta Y, sin ser ni ancestro ni descendiente de la exposición X . G compite aquí.\nInstrumento : Un instrumento es un ancestro de la explicativa. No tiene ningún camino hacia la respuesta Y que no pase a través de la explicativa X (pues sería un factor de confusión). D es un instrumento.\nColisionador : Un colisionador es un descendiente tanto de la exposición X como de la respuesta Y. E es un colisionador en el ejemplo DAG."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#cuándo-esperar-asociación",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#cuándo-esperar-asociación",
    "title": "Introducción a Diagramas Causales",
    "section": "Cuándo esperar asociación",
    "text": "Cuándo esperar asociación\n\n\n\n\n\n\n\n\n \n\n\n… a veces por pura buen fortuna"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#sesgo-sistemático-efecto-de-confusión",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#sesgo-sistemático-efecto-de-confusión",
    "title": "Introducción a Diagramas Causales",
    "section": "Sesgo sistemático: efecto de confusión",
    "text": "Sesgo sistemático: efecto de confusión\n\n\n\n\n\n\n\n\n \n\n\nHay sesgo sistemático si hay una asociación entre A e Y que no surge del efecto causal de A sobre Y. Cuando existe una asociación entre A e Y, incluso si A tiene un efecto causal cero sobre Y, se dice que hay sesgo bajo la condición nula."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#sesgo-por-selección",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#sesgo-por-selección",
    "title": "Introducción a Diagramas Causales",
    "section": "Sesgo por Selección",
    "text": "Sesgo por Selección"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#en-un-dag-con-nodos-l-a-e-y-en-este-orden-de-aparición",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#en-un-dag-con-nodos-l-a-e-y-en-este-orden-de-aparición",
    "title": "Introducción a Diagramas Causales",
    "section": "En un DAG con nodos L, A e Y (en este orden de aparición)",
    "text": "En un DAG con nodos L, A e Y (en este orden de aparición)\nVevox\n¿Qué significa que no haya un arco del nodo A al Y?\nIngresa a: vevox.app con el ID: 169-614-732"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#si-nuestro-conocimiento-en-la-materia-es-insuficiente-para-descartar-la-existencia-de-un-efecto-directo-de-la-variable-d-sobre-la-e.",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#si-nuestro-conocimiento-en-la-materia-es-insuficiente-para-descartar-la-existencia-de-un-efecto-directo-de-la-variable-d-sobre-la-e.",
    "title": "Introducción a Diagramas Causales",
    "section": "Si nuestro conocimiento en la materia es insuficiente para descartar la existencia de un efecto directo de la variable D sobre la E.",
    "text": "Si nuestro conocimiento en la materia es insuficiente para descartar la existencia de un efecto directo de la variable D sobre la E.\nvevox\n¿Deberíamos incluir un arco de D a E en el diagrama causal?\nIngresa a: vevox.app con el ID: 169-614-732"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-inteligencia-reduce-el-tiempo-necesario-de-estudio-para-aprender.-al-mismo-tiempo-la-inteligencia-junto-con-el-tiempo-de-estudio-explican-la-calificación-en-el-examen.-cuál-es-el-dag-que-describe-esta-proposición-causal",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-inteligencia-reduce-el-tiempo-necesario-de-estudio-para-aprender.-al-mismo-tiempo-la-inteligencia-junto-con-el-tiempo-de-estudio-explican-la-calificación-en-el-examen.-cuál-es-el-dag-que-describe-esta-proposición-causal",
    "title": "Introducción a Diagramas Causales",
    "section": "La inteligencia reduce el tiempo necesario de estudio para aprender. Al mismo tiempo, la inteligencia, junto con el tiempo de estudio explican la calificación en el examen. ¿Cuál es el DAG que describe esta proposición causal?",
    "text": "La inteligencia reduce el tiempo necesario de estudio para aprender. Al mismo tiempo, la inteligencia, junto con el tiempo de estudio explican la calificación en el examen. ¿Cuál es el DAG que describe esta proposición causal?\nIngresa a: vevox.app con el ID: 169-614-732"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#reglas-de-independencia-condicional",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#reglas-de-independencia-condicional",
    "title": "Introducción a Diagramas Causales",
    "section": "Reglas de independencia condicional",
    "text": "Reglas de independencia condicional\nUn DAG también describe aspectos clave del “flujo de la asociación” a través de la estructura causal.\n\nCuando las variables están conectadas, correlacionan, lo que implica que la información puede fluir entre ellas en cualquier dirección.\nHay tres reglas fundamentales sobre como se puede dar esta interconexión, es decir de como se separan o conectan los nodos."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#regla-1-variable-intermedia",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#regla-1-variable-intermedia",
    "title": "Introducción a Diagramas Causales",
    "section": "Regla 1 “variable intermedia”",
    "text": "Regla 1 “variable intermedia”\n\n\n\nDos variables, X e Y, son condicionalmente independientes dado A , si sólo hay una ruta unidireccional entre X e Y , cuando A es una variable (podrían ser muchas) intercalada en el camino."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#regla-2-causa-común",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#regla-2-causa-común",
    "title": "Introducción a Diagramas Causales",
    "section": "Regla 2 “causa común”",
    "text": "Regla 2 “causa común”\n\n\n\n \n\n\n\n\nSi una variable A es una causa común de las variables X e Y , y solo hay una ruta entre X e Y , entonces X e Y son condicionalmente independientes cuando se consideran como condicionantes los datos de A ."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#regla-3-colisionador",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#regla-3-colisionador",
    "title": "Introducción a Diagramas Causales",
    "section": "Regla 3 “colisionador”",
    "text": "Regla 3 “colisionador”\n\n\n\n \n\n\n\n\nSi una variable A es el nodo de colisión entre dos variables X e Y , y solo hay un camino entre X e Y , entonces X e Y son incondicionalmente independientes pero dependen condicionalmente de A así como de cualquier descendiente de A ."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#separación-direccional-d-separation",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#separación-direccional-d-separation",
    "title": "Introducción a Diagramas Causales",
    "section": "Separación-direccional (d-separation)",
    "text": "Separación-direccional (d-separation)\nEl flujo de información en una ruta p queda bloqueado por un conjunto de nodos Z si y sólo si:\n1 p contiene una cadena de nodos A → B → C o una horquilla A ← B → C , de tal manera que el nodo medio B proporciona datos como criterio condicional de observación. Es decir si la ruta es del tipo variable intermedia o causa común, el condicionarlas bloquea.\n2 p contiene un colisionador A → B ← C tal que ni el nodo de colisión B , ni ninguno de sus descendientes, son criterio para condicionar las observaciones. Es decir condicionar sore un colisionador desbloquea ."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#se-puede-medir-el-efecto-sin-sesgos-de-la-aspirina",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#se-puede-medir-el-efecto-sin-sesgos-de-la-aspirina",
    "title": "Introducción a Diagramas Causales",
    "section": "¿Se puede medir el efecto, sin sesgos, de la aspirina?",
    "text": "¿Se puede medir el efecto, sin sesgos, de la aspirina?\nIngresa a: vevox.app con el ID: 169-614-732"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#colisionadores",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#colisionadores",
    "title": "Introducción a Diagramas Causales",
    "section": "Colisionadores",
    "text": "Colisionadores\n\nMcElreath nos ofrece esta proposición:\n\nLos estudios científicos más noticiables son los menos fiables. Cuanto más probable es que te mate, si es cierto, menos probable es que sea cierto. Cuanto más aburrido el tema, más rigurosos los resultados.\n\n\nFuente: The Haunted DAG & The Causal Terror | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition (bookdown.org)"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#cómo-se-produce-esta-correlación-negativa",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#cómo-se-produce-esta-correlación-negativa",
    "title": "Introducción a Diagramas Causales",
    "section": "¿Cómo se produce esta correlación negativa?",
    "text": "¿Cómo se produce esta correlación negativa?\nEsta asociación NO CAUSAL se produce cuando los revisores se preocupan tanto por el interés “innovador” (pensando en su potencial noticioso), como por la fiabilidad.\nUna fuerte selección induce una correlación negativa entre los criterios utilizados en la selección.\n¿Por qué? Si la única forma de cruzar el umbral es obtener una puntuación alta, es más frecuente obtener una puntuación alta en un criterio que en ambos.\nFuente: The Haunted DAG & The Causal Terror | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition (bookdown.org)"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-paradoja-de-simpson",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-paradoja-de-simpson",
    "title": "Introducción a Diagramas Causales",
    "section": "La paradoja de Simpson",
    "text": "La paradoja de Simpson\nEjemplo con datos de COVID-19 sobre mortalidad por raza, tal y como se describe en el blog de Judea Pearl .\nLa paradoja: los blancos no hispanos tienen una mayor mortalidad si nos fijamos en los datos agregados. Pero: Desagregados por edad (relativo a la expectativa de vida, de ahí el arco B), los blancos tienen una mortalidad menor en todos los grupos de edad. El DAG correspondiente:\n\nComo podemos ver en el gráfico, la edad es un factor de confusión para esta relación y, por tanto, mirar los datos observacionales Pr (Muerte|Raza) no dará la respuesta correcta. Una vez que observamos Pr (Muerte|Raza, Edad), el efecto de la variable Raza se invierte. La razón por la que puede ocurrir esto es poco intuitiva."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-paradoja-de-berkson",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-paradoja-de-berkson",
    "title": "Introducción a Diagramas Causales",
    "section": "La paradoja de Berkson",
    "text": "La paradoja de Berkson\n\n\n\nLa paradoja de Berkson surge al condicionar un colisionador. Esto puede parecer paradójico pero usualmente es un artefacto del diseño del estudio, por ejemplo durante la selección de participantes.\nSupongamos investigas si existe alguna relación entre contraer COVID y padecer alguna otra enfermedad.\nSupongamos además que en la población general la COVID es independiente de otras enfermedades. Ahora bien, si basas tu estudio únicamente en pacientes hospitalizados, encontrarás que Pr(COVID|no Otras enfermedades) = ¡1!\nObviamente hubo algún padecimiento para estar hospitalizados.\nCondicionar a la hospitalización hace que las dos variables resulten asociadas, cuando antes no lo eran.\nEl condicionamiento sobre el colisionador ha desbloqueado la vía causal entre las dos variables."
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#efecto-problemático-de-un-colisionador",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#efecto-problemático-de-un-colisionador",
    "title": "Introducción a Diagramas Causales",
    "section": "Efecto problemático de un “colisionador”",
    "text": "Efecto problemático de un “colisionador”\n\n\n\n Fuente: https://www.nature.com/articles/s41467-020-19478-2"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#cómo-influye-la-edad-sobre-la-felicidad",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#cómo-influye-la-edad-sobre-la-felicidad",
    "title": "Introducción a Diagramas Causales",
    "section": "¿cómo influye la edad sobre la felicidad?",
    "text": "¿cómo influye la edad sobre la felicidad?\nSi disponemos de una amplia encuesta de personas felices, ¿cabría esperar alguna asociación entre la edad y la felicidad?"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-paradoja-del-bajo-peso-al-nacer",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html#la-paradoja-del-bajo-peso-al-nacer",
    "title": "Introducción a Diagramas Causales",
    "section": "La paradoja del bajo peso al nacer",
    "text": "La paradoja del bajo peso al nacer\nEste es un ejemplo real que desconcertó a la comunidad médica durante muchos años.\nAl estudiar el efecto del tabaco en la mortalidad infantil. Ya se sabía que fumar provocaba un mayor riesgo de bajo peso al nacer y que el bajo peso al nacer aumenta el riesgo de mortalidad infantil.\n¿El tabaquismo tiene algún otro efecto sobre la mortalidad infantil?, aparte de causar bajo peso al nacer.\nLa intuición de los investigadores sugirió condicionar el peso al nacer y entonces observar el efecto del tabaquismo sobre la mortalidad: ¡se descubrió que fumar tenía un efecto protector!\nLa explicación es que ¡se trata de un sesgo del colisionador!\nHay varias causas de bajo peso al nacer. Fumar es una de ellas, pero hay otras.\nLas otras causas de bajo peso al nacer tienen un mayor riesgo negativo sobre la mortalidad infantil, aparte de su efecto sobre el bajo peso al nacer.\nComo reto, dibuja el DAG correspondiente y combina todos estos hechos para averiguar cómo el condicionamiento sobre el peso al nacer puede crear el hallazgo de que fumar tiene un falso efecto protector."
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#instrucciones-para-participar",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#instrucciones-para-participar",
    "title": "Leyes de la Ciencia",
    "section": "",
    "text": "lo que hay que hacer es\n\n\n\n\nEn tu computadora ir vevox.app\nPara usar el celular instala Vevox desde la tienda de apps"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#para-ti-qué-es-la-ciencia",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#para-ti-qué-es-la-ciencia",
    "title": "Leyes de la Ciencia",
    "section": "1. Para ti, ¿qué es la ciencia?",
    "text": "1. Para ti, ¿qué es la ciencia?\n\nParticipa: vevox.app ID: 152-551-925\n\n\n\n\n \n\n\n\n\n(escribe de 3 a 20 palabras que reflejan tu percepción)\n\n\n\n\nEscribe una palabra y oprime enviar"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#supuestos-que-se-hacen-al-hacer-ciencia",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#supuestos-que-se-hacen-al-hacer-ciencia",
    "title": "Leyes de la Ciencia",
    "section": "Supuestos que se hacen al hacer ciencia",
    "text": "Supuestos que se hacen al hacer ciencia\n\nToda argumentación racional inicia con ciertos supuestos .\nEstos supuestos típicamente quedan implícitos en la práctica de las actividades científicas\nConviene hacerlas explícitas para darle claridad a nuestra forma de hacer ciencia."
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#qué-damos-por-sentados-cuando-hacemos-ciencia",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#qué-damos-por-sentados-cuando-hacemos-ciencia",
    "title": "Leyes de la Ciencia",
    "section": "2. ¿Qué damos por sentados cuando hacemos ciencia?",
    "text": "2. ¿Qué damos por sentados cuando hacemos ciencia?\n\nParticipa: vevox.app ID: 152-551-925\n\n\n\n\n \n\n\n\n\n(escribe de 3 a 20 palabras que reflejan tu percepción)\n\n\n\n\nEscribe una palabra y oprime enviar"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#algunos-otros-corolarios-interesantes",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#algunos-otros-corolarios-interesantes",
    "title": "Leyes de la Ciencia",
    "section": "Algunos otros corolarios interesantes",
    "text": "Algunos otros corolarios interesantes\n\nLa naturaleza es comprensible . Einstein afirmaba que: la cosa más incomprensible del universo es que sea comprensible.\nLa naturaleza es uniforme . Es decir los procesos y patrones observados sólo en una escala limitada se mantendrán universalmente (esto es obviamente imprescindible en ciencias como la Astronomía).\n\n¿Qué pasa con este supuesto en ciencias como la Ecología, la Psicología o las Ciencias sociales? De paso, hay que notar que este supuesto implica la homogeneidad del material experimental.\n\nLa causalidad existe . El principio de causalidad es la noción que consiste en que “cada evento (o fenómeno) natural se supone tiene una causa, de modo que si tal situación causal puede ser restituida, el evento será duplicado” (Underwood1957)."
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#cómo-debe-interpretarse-esto",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#cómo-debe-interpretarse-esto",
    "title": "Leyes de la Ciencia",
    "section": "3. ¿Cómo debe interpretarse esto?",
    "text": "3. ¿Cómo debe interpretarse esto?\n\nParticipa: vevox.app ID: 152-551-925\n\n\n\n\n \n\n\n\n\n\n90% de las semillas en un grupo tratado germinan.\n20% lo hacen en el grupo control.\n\n\n\n\n\nElije la respuesta que consideres más apropiada"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#qué-tan-de-acuerdo-estás-con-la-siguiente-aseveración",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#qué-tan-de-acuerdo-estás-con-la-siguiente-aseveración",
    "title": "Leyes de la Ciencia",
    "section": "4. ¿Qué tan de acuerdo estás con la siguiente aseveración?",
    "text": "4. ¿Qué tan de acuerdo estás con la siguiente aseveración?\n\nParticipa: vevox.app ID: 152-551-925\n\n“La causalidad implica correlación”"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#causalidad-finita-y-desprecio",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#causalidad-finita-y-desprecio",
    "title": "Leyes de la Ciencia",
    "section": "Causalidad finita y desprecio…",
    "text": "Causalidad finita y desprecio…\n\nPara Bachelard, uno de los signos distintivos del espíritu científico y del espíritu filosófico es el derecho a despreciar . Para él, el espíritu científico explicita clara y distintamente este derecho a despreciar lo despreciable\nDerecho que incansablemente el espíritu filosófico le rehúsa.\nPara ilustrar esto, recurre a Ostwald:\n\n“Cualquiera que sea el fenómeno considerado, siempre hay un número extremadamente grande de circunstancias que no tienen influencia mesurable sobre él”.\n¿Cómo influye el color de un proyectil en sus propiedades balísticas?"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#conoces-alguna-metodología-científica-para-describir-y-analizar-estructuras-de-relación-causa-efecto",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#conoces-alguna-metodología-científica-para-describir-y-analizar-estructuras-de-relación-causa-efecto",
    "title": "Leyes de la Ciencia",
    "section": "5. ¿Conoces alguna metodología científica para describir y analizar estructuras de relación causa efecto?",
    "text": "5. ¿Conoces alguna metodología científica para describir y analizar estructuras de relación causa efecto?\n\nParticipa: vevox.app ID: 152-551-925"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#cuáles-son-los-aspectos-clave-para-diseñar-un-experimentoestudio",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#cuáles-son-los-aspectos-clave-para-diseñar-un-experimentoestudio",
    "title": "Leyes de la Ciencia",
    "section": "6 ¿Cuáles son los aspectos CLAVE para diseñar un experimento/estudio?",
    "text": "6 ¿Cuáles son los aspectos CLAVE para diseñar un experimento/estudio?\n\nParticipa: vevox.app ID: 152-551-925"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#section-5",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html#section-5",
    "title": "Leyes de la Ciencia",
    "section": "",
    "text": "M3-Causalidad"
  },
  {
    "objectID": "posts/03-modelo-lineal/index.html",
    "href": "posts/03-modelo-lineal/index.html",
    "title": "El Modelo estadístico lineal",
    "section": "",
    "text": "El diseño, análisis y reporte de los resultados de experimentos o estudios en general tiene un vínculo muy estrecho con la modelación estadística. Las hipótesis de investigación deben ser expresadas de modo tal que sean suceptibles de ser valoradas con apoyo estadístico y a partir de ahí, el análiisis de los datos y el reporte de resultados hacen referencia obligada a los atributos de los modelos estudiados, desde luego considerando su correspondencia o falta de ella, con los datos obtenidos en el estudio y las ideas que el equipo de investigación se ha propuesto desentrañar. Es así como usualmente se aplica la llamada prueba de hipótesis que se basa en la comparación y selección de modelos, buscando encontrar aquellos que ofrezcan la mejor correspondencia con una explicación plausible del proceso que genera datos semejantes a los que se utilizaron en el estudio. En esta sesión abordaremos esta temática.\n\n\n\n \n\n\n\n\n\n\n\n \n\n\n\n\n \n\n\nHaz click sobre la imagen para ver la presentación"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "McElreath (2020) presenta en su libro el hipotético ejemplo de la prueba de sangre para vampirismo. Propone que hay un análisis de sangre que detecta correctamente 95% de las veces, la afiliación de un individuo al linaje del conde Drácula y los inmortales vampiros. En notación matemática:\n\\[\n{Pr(resultado~ positivo~de~la~prueba|vampiro) = 0.95}\n\\]\nEs una prueba muy precisa, casi siempre identificando vampiros reales. Sin embargo, también comete errores y produce falsos positivos. Es así que el uno por ciento de las veces diagnostica incorrectamente a los simples mortales como vampiros:\n\\[\n{Pr(resultado~positivo~de~la~prueba|mortal) = 0.01}\n\\]\nLa última pieza de información que necesitamos es saber que los vampiros en realidad son bastante raros. Sólo el 0.1% de la población lo es, lo que implica:\n\\[\n{Pr(vampiro) = 0.001}\n\\]\nA partir de este conocimiento científico, supongamos que un amigo da positivo en el test de vampirismo.\n\n\n\n\n\n\n¿Cuál es la probabilidad de que sea un inmortal chupasangre\n\n\n\n\n\nEl enfoque de investigación formal empezaría por usar el teorema de Bayes para deducir la probabilidad \\({Pr(vampiro|positivo)}\\), lo que en cierta forma implica “invertir la probabilidad”, pues lo que ahora sabemos es el valor de \\({Pr(positivo|vampiro)}\\). El cálculo puede presentarse como:\n\\[\n\\Pr(vampiro|positivo) = \\frac{Pr(positivo|vampiro) \\times Pr(vampiro)}{Pr(positivo)}\n\\]\nen donde \\({Pr(positivo)}\\) es la probabilidad promedio de los resultados positivos de la prueba, es decir,\n\\[\nPr(positivo) = Pr(positivo|vampiro)\\times Pr(vampiro) + Pr(positivo|mortal) \\times ({1 − Pr(vampiro)})\n\\]\n\n\n\nTodo esto lo podemos hacer en R.\nPrimero tomamos nota de lo que ya sabemos al principio, ¡a priori!\n\n\nCódigo\nPr_positivo_vampiro &lt;- 0.95 \nPr_positivo_Mortal &lt;- 0.01 \nPr_vampiro &lt;- 0.001 \n\n\nTomamos la fórmula de Bayes para invertir la probabilidad, pues queremos saber qué está pasando cuando tenemos la fortuna de toparnos con un resultado positivo en la prueba de sangre:\n\\[\nPr(positivo|vampiro)\n\\]\nEsto equivale a preguntarnos, dado que ya vimos el resultado científico que significa la prueba de sangre, ¿será vampiro el sujeto de quien se obtuvo esa muestra?:\n\\[\nPr(vampiro|positivo)\n\\]\n\n\nCódigo\nPr_positivo &lt;- Pr_positivo_vampiro * Pr_vampiro + Pr_positivo_Mortal * (1 - Pr_vampiro) \n\nPr_vampiro_positivo &lt;- (Pr_positivo_vampiro * Pr_vampiro) / Pr_positivo\n\nround(Pr_vampiro_positivo, 3)\n\n\n[1] 0.087\n\n\nPor lo tanto, la probabilidad de que el amigo sea en realidad un vampiro es 8.7%.\n\n\n\n\n\n\n¿Encuentras este resultado afin o contrario a lo que pensabas antes de hacer los cálculos?\n\n\n\n\n\n\nEste es un resultado muy importante. Exactamente así, o algo muy parecido, es el procedimiento que se sigue en muchos contextos de prueba realistas: las pruebas de PCR, antígeno o anticuerpos para SarsCov-2, la prueba del VIH la del DNA en un perfil criminal y por supuesto la prueba de significancia estadística.\nQuizás ayude a mejorar la intuición que tenemos de las cosas el considerar que siempre que la condición de interés sea muy rara, desarrollar una prueba excelente, capaz de diagnosticar bien todos los casos verdaderos (aunque invitablemente produzca también algunos falsos positivos), no es garantía suficiente de que un resultado positivo en general conlleve mucha información.\nLa razón es que usualmente resulta inevitable tener falsos positivos y por simple aritmética, esos casos serán la mayoría de los resultados que tendremos, incluso si todos los verdaderos positivos fueran detectados correctamente.\nAunque, como dice McElreath, no hay nada particularmente bayesiano aqui. Podríamos pensar que la ecuación que usamos aquí salio de la nada, aunque quizás la recuerdes de algún curso previo, de alguna charla interesante por ahí o incluso de lo que viste con Rosario ¡hace unas semanas!\nQuizás el ejemplo puede verse en forma más intuitiva utilizando otra narrativa para comprender lo que está ocurriendo. Digamos que en lugar de informar sobre las probabilidades, como antes, te digo lo siguiente:\n\nEn una población de 100,000 personas, 100 de ellas son vampiros.\nDe los 100 que son vampiros 95 darán positivo en la prueba de vampirismo.\nDe los 99,900 simples mortales, 999 darán positivo a la prueba de vampirismo.\n\nAhora piensa en esto, si hacemos pruebas a las 100,000 personas, ¿qué proporción de los que dan positivo en las pruebas de vampirismo son realmente vampiros?\nMuchas personas, aunque ciertamente no todas, encuentran esta forma de contar la historia mucho más fácil. Sigamos por este camino.\n\n\n\n\n\n\n¿Qué tal si contamos el número de personas que dan positivo?\n\n\n\n\n\n\\[\n95 + 999 = 1094\n\\] De estas 1094 pruebas positivas, 95 de ellas son vampiros reales, lo que nos lleva sencillamente a esto:\n\\[\nPr(vampiro|positivo) = \\frac{95}{1094} ≈ 0.087\n\\]\nEsta es exactamente la misma respuesta de 8.7% que encontramos antes. Pero no tuvimos que recordar la ´“formula mágica” de Bayes, nada más tuvimos que contar y pensar con calma.\n\n\n\nEsta forma de presentar el problema mediante el “conteo de los actores” en lugar de recurrir a probabilidades, suele denominarse formato de frecuencia o frecuencias naturales.\nLas razones propuestas para explicar el por qué el formato de frecuencia ayuda a la gente a intuir el enfoque correcto siguen siendo polémicas. Podría ser que de entrada sólo podemos encontrarnos con conteos en el mundo real. Quizás sea cierto que nadie ha visto nunca una probabilidad andando por ahí. Independientemente de la explicación de este fenómeno, podemos explotarlo.\nLos eventos muestreados en el análisis de las distribuciones de probabilidades de modelos estadísticos en algún análisis de datos, son los valores de los parámetros. La mayoría de los parámetros no tienen una “materialización” empírica exacta.\nEl formalismo bayesiano trata las distribuciones de los parámetros como una plausibilidad relativa, no como un proceso aleatorio que ocurre en el mundo físico. En cualquier caso, la aleatoriedad es siempre una propiedad de la información, nunca del mundo real.\n\n\n\nEl ejemplo del vampirismo que acabamos de ver tiene la misma estructura lógica que muchos problemas de detección considerando que:\n\nHay algún estado binario al que no tenemos acceso.\nObservamos un indicio imperfecto del estado oculto.\n(Deberíamos/podríamos) usar el teorema de Bayes para deducir lógicamente el impacto del indicio en nuestra incertidumbre (aunque ve lo que salió en el periódico)\n\nLa inferencia científica puede enmarcase en términos similares:\n\nUna hipótesis es verdadera o falsa, pero no podemos saberlo;\nObtenemos un indicio estadístico de la falsedad de la hipótesis;\nDebemos/podemos utilizar el teorema de Bayes para deducir lógicamente el impacto del indicio en el estado de la hipótesis.\n\nEs el tercer paso el que casi nunca se hace. Sin debatir por lo pronto si debemos o no usar a Bayes, consideremos por un momento la idea como un ejemplo de juguete.\n\n\n\n\n\nSupongamos que la probabilidad de obtener un hallazgo positivo, cuando la hipótesis postulada es cierta, es \\({Pr(señal~detectada|verdadero) =Pr(H|V) = 0.95}\\).\nEse es lo que se suele llamar la potencia de la prueba.\n\n\n\nSupongamos que la probabilidad de un hallazgo positivo, cuando una hipótesis es falsa, es \\({Pr(señal~detectada|falso) = Pr(H|F) = 0.05}\\).\nEsa es la tasa de falsos positivos, se trata del, digamos 5%, de la prueba de significancia que usamos convencionalmente.\n\n\n\nFinalmente, tenemos que establecer la tasa base con la que ocurren las hipótesis que son verdaderas. Supongamos, por ejemplo, que 1 de cada 100 hipótesis resulta ser verdadera. Entonces \\({Pr(verdadero) = P(V) = 0.01}\\).\nEn realidad nadie conoce este valor ni se ve posible conocerlo, pero la historia de la ciencia sugiere que es pequeño.\n\n\n\nPara averiguar esto, calculamos la componente a posteriori:\n\\[\nPr(detectada|Hipótesis) = \\frac{Pr(Hipótesis|detectada) Pr(detectado)} {Pr(Hipótesis)} = \\\\\n\\\\\n\\frac{Pr(H|V) Pr(V)} {Pr(H|V) Pr(V) + Pr(H|F) Pr(F)}\n\\\\\n\\]\n\n\nCódigo\nPr_posterior_hallazgo_verdadero &lt;- (0.95 * 0.01) / ((0.95 * 0.01) + (0.05 * (1-0.01)))\nPr_posterior_hallazgo_verdadero\n\n\n[1] 0.1610169\n\n\nComo podemos ver, al substituir los valores imaginados, encontramos que la respuesta es aproximadamente \\({Pr(V|H) = 0.16}\\).\nAsí que un resultado positivo corresponde a un 16% de probabilidad de que la hipótesis sea cierta.\nEste es el mismo fenómeno de baja tasa de base que se aplica en las pruebas médicas (y en nuestro ejemplo de vampiros).\nPuedes reducir la tasa de falsos positivos al 1%\n\n\n\n\n\n\n¿qué pasaría?\n\n\n\n\n\n\n\n\n\n\nProgramar para explorar ideas\n\n\n\n\n\nUna manera de explorar esto es haciendo un escript, algoritmo o programa que nos permita automatizar una tarea repetitiva y potencialmente aburrida. Veamos como hacerlo.\n\n\nCódigo\nciencia &lt;- function (pr_pos_verdadero = 0.95, pr_verdadero = 0.01)\n{\n    pr_falso &lt;- 1 - pr_verdadero\n    pr_pos_falso &lt;- 1 - pr_pos_verdadero\n\n    pr_verdadero_pos &lt;- pr_pos_verdadero * pr_verdadero / (pr_pos_verdadero * pr_verdadero + pr_pos_falso*pr_falso)\n\n    return(pr_verdadero_pos)\n}\n\n\nHemos definido un programa como una función en R. Esta función puede tomar datos y procesarlos de acuerdo con la lógica que le hemos especificado.\nAhora podemos experimentar para tener una idea aproximada de lo que está pasando.\n\n\nCódigo\n# Elegimos una serie de valores de interés\nvalores_de_interés &lt;- seq(0.9, 0.99, 0.01)\n\n# Creamos un espacio de memoria vacío para anotar ahí los cálculos\nresultados &lt;- data.frame(numeric(0), numeric(0))\nfor (pr in valores_de_interés) \n    resultados &lt;- rbind(resultados, c(pr, ciencia(pr, 0.01)))\n\nnames(resultados) &lt;- c(\"p_error\", \"p_post\")\n\n\nAhora podemos ver los resultados del experimento con ayuda de una gráfica.\n\n\nCódigo\n# Área de graficación. mar() para el margen. oma() alrededor del margen.\npar(oma=c(2,3,1,2)) # abajo=2, izq=3, arriba=1, der=2\npar(mar=c(4,4,2,2) + 0.7)\n\n# Tamaño de la gráfica\noptions(repr.plot.width = 15, repr.plot.height = 5)\n\n# Gráfica\nplot(x = 1 - resultados$p_error, y = resultados$p_post,\n     type = \"b\", xlab = \"valor de P\", ylab = \"Pr post detección positiva\", \n     cex = 2, cex.axis  = 1, cex.lab = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna investigación muy exigente que reduce la detección de falsos positivos a 1%, nos permite llevar la probabilidad posterior de descubrimientos exitosos hasta 0.5.\nApenas tan buena como el lanzamiento de una moneda.\nPodemos pensar que lo que hemos hecho hasta aquí es prácticamente un juego, pero ¿qué tan cercano podría ser a lo que ocurre en la vida real? y si fuera una razonable aproximación ¿a qué nos conduce?\nQuizás nos sugiera que lo más importante es mejorar la tasa base, \\({Pr(V)}\\), y eso requiere pensar mejor, no hacer muchas más pruebas o incluso ponerse exageradamente exigente.\n\n\n\n\n\n\n¿Tú que piensas?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuente: Stoddart, C. (2016). Is there a reproducibility crisis in science?. Nature\n     \n\n\n\n\n\n\n¿Ha mejorado la situación?\n\n\n\n\n\n\n\n\nLa falta de reproducibilidad de los experimentos se traduce en artículos que son cuestionados y se ven forzados a retirarse. Claro, no es la única razón para retirar un artículo, pero si la más frecuente. A fines del año pasado salió esta noticia en Nature.\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\nSin duda la forma como hemos optado por hacer ciencia está teniendo problemas que debemos afrontar. La cuestión es que podemos o más bien que debemos hacer para enfrentarlos productivamente y así producir una ciencia mejor.\n\n\n\n\n\n\nBuscar la verdad\n\n\n\n\n\n\n\n\n\nLa búsqueda de la verdad siempre debería prevalecer sobre el deseo defensivo del ego de tener la razón. Esto no es fácil, porque a la mayoría de la gente le resulta difícil admitir que se equivoca. Y es precisamente por esto por lo que la ciencia resulta tan liberadora. Provee un marco de trabajo para la autocorrección, porque el conocimiento científico siempre es provisional. Un hecho científico aceptado hoy puede ser refutado mañana. Por tanto, el método científico engendra humildad epistemológica.\n\n\n\n \n\n\n\n\n\n\nGad Saad"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#estadística-para-mejorar-la-ciencia",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#estadística-para-mejorar-la-ciencia",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "El ejemplo del vampirismo que acabamos de ver tiene la misma estructura lógica que muchos problemas de detección considerando que:\n\nHay algún estado binario al que no tenemos acceso.\nObservamos un indicio imperfecto del estado oculto.\n(Deberíamos/podríamos) usar el teorema de Bayes para deducir lógicamente el impacto del indicio en nuestra incertidumbre (aunque ve lo que salió en el periódico)\n\nLa inferencia científica puede enmarcase en términos similares:\n\nUna hipótesis es verdadera o falsa, pero no podemos saberlo;\nObtenemos un indicio estadístico de la falsedad de la hipótesis;\nDebemos/podemos utilizar el teorema de Bayes para deducir lógicamente el impacto del indicio en el estado de la hipótesis.\n\nEs el tercer paso el que casi nunca se hace. Sin debatir por lo pronto si debemos o no usar a Bayes, consideremos por un momento la idea como un ejemplo de juguete.\n\n\n\n\n\nSupongamos que la probabilidad de obtener un hallazgo positivo, cuando la hipótesis postulada es cierta, es \\({Pr(señal~detectada|verdadero) =Pr(H|V) = 0.95}\\).\nEse es lo que se suele llamar la potencia de la prueba.\n\n\n\nSupongamos que la probabilidad de un hallazgo positivo, cuando una hipótesis es falsa, es \\({Pr(señal~detectada|falso) = Pr(H|F) = 0.05}\\).\nEsa es la tasa de falsos positivos, se trata del, digamos 5%, de la prueba de significancia que usamos convencionalmente.\n\n\n\nFinalmente, tenemos que establecer la tasa base con la que ocurren las hipótesis que son verdaderas. Supongamos, por ejemplo, que 1 de cada 100 hipótesis resulta ser verdadera. Entonces \\({Pr(verdadero) = P(V) = 0.01}\\).\nEn realidad nadie conoce este valor ni se ve posible conocerlo, pero la historia de la ciencia sugiere que es pequeño.\n\n\n\nPara averiguar esto, calculamos la componente a posteriori:\n\\[\nPr(detectada|Hipótesis) = \\frac{Pr(Hipótesis|detectada) Pr(detectado)} {Pr(Hipótesis)} = \\\\\n\\\\\n\\frac{Pr(H|V) Pr(V)} {Pr(H|V) Pr(V) + Pr(H|F) Pr(F)}\n\\\\\n\\]\n\n\nCódigo\nPr_posterior_hallazgo_verdadero &lt;- (0.95 * 0.01) / ((0.95 * 0.01) + (0.05 * (1-0.01)))\nPr_posterior_hallazgo_verdadero\n\n\n[1] 0.1610169\n\n\nComo podemos ver, al substituir los valores imaginados, encontramos que la respuesta es aproximadamente \\({Pr(V|H) = 0.16}\\).\nAsí que un resultado positivo corresponde a un 16% de probabilidad de que la hipótesis sea cierta.\nEste es el mismo fenómeno de baja tasa de base que se aplica en las pruebas médicas (y en nuestro ejemplo de vampiros).\nPuedes reducir la tasa de falsos positivos al 1%\n\n\n\n\n\n\n¿qué pasaría?\n\n\n\n\n\n\n\n\n\n\nProgramar para explorar ideas\n\n\n\n\n\nUna manera de explorar esto es haciendo un escript, algoritmo o programa que nos permita automatizar una tarea repetitiva y potencialmente aburrida. Veamos como hacerlo.\n\n\nCódigo\nciencia &lt;- function (pr_pos_verdadero = 0.95, pr_verdadero = 0.01)\n{\n    pr_falso &lt;- 1 - pr_verdadero\n    pr_pos_falso &lt;- 1 - pr_pos_verdadero\n\n    pr_verdadero_pos &lt;- pr_pos_verdadero * pr_verdadero / (pr_pos_verdadero * pr_verdadero + pr_pos_falso*pr_falso)\n\n    return(pr_verdadero_pos)\n}\n\n\nHemos definido un programa como una función en R. Esta función puede tomar datos y procesarlos de acuerdo con la lógica que le hemos especificado.\nAhora podemos experimentar para tener una idea aproximada de lo que está pasando.\n\n\nCódigo\n# Elegimos una serie de valores de interés\nvalores_de_interés &lt;- seq(0.9, 0.99, 0.01)\n\n# Creamos un espacio de memoria vacío para anotar ahí los cálculos\nresultados &lt;- data.frame(numeric(0), numeric(0))\nfor (pr in valores_de_interés) \n    resultados &lt;- rbind(resultados, c(pr, ciencia(pr, 0.01)))\n\nnames(resultados) &lt;- c(\"p_error\", \"p_post\")\n\n\nAhora podemos ver los resultados del experimento con ayuda de una gráfica.\n\n\nCódigo\n# Área de graficación. mar() para el margen. oma() alrededor del margen.\npar(oma=c(2,3,1,2)) # abajo=2, izq=3, arriba=1, der=2\npar(mar=c(4,4,2,2) + 0.7)\n\n# Tamaño de la gráfica\noptions(repr.plot.width = 15, repr.plot.height = 5)\n\n# Gráfica\nplot(x = 1 - resultados$p_error, y = resultados$p_post,\n     type = \"b\", xlab = \"valor de P\", ylab = \"Pr post detección positiva\", \n     cex = 2, cex.axis  = 1, cex.lab = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna investigación muy exigente que reduce la detección de falsos positivos a 1%, nos permite llevar la probabilidad posterior de descubrimientos exitosos hasta 0.5.\nApenas tan buena como el lanzamiento de una moneda.\nPodemos pensar que lo que hemos hecho hasta aquí es prácticamente un juego, pero ¿qué tan cercano podría ser a lo que ocurre en la vida real? y si fuera una razonable aproximación ¿a qué nos conduce?\nQuizás nos sugiera que lo más importante es mejorar la tasa base, \\({Pr(V)}\\), y eso requiere pensar mejor, no hacer muchas más pruebas o incluso ponerse exageradamente exigente.\n\n\n\n\n\n\n¿Tú que piensas?"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#crisis-de-reproducibilidad",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#crisis-de-reproducibilidad",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "Fuente: Stoddart, C. (2016). Is there a reproducibility crisis in science?. Nature\n     \n\n\n\n\n\n\n¿Ha mejorado la situación?\n\n\n\n\n\n\n\n\nLa falta de reproducibilidad de los experimentos se traduce en artículos que son cuestionados y se ven forzados a retirarse. Claro, no es la única razón para retirar un artículo, pero si la más frecuente. A fines del año pasado salió esta noticia en Nature.\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\nSin duda la forma como hemos optado por hacer ciencia está teniendo problemas que debemos afrontar. La cuestión es que podemos o más bien que debemos hacer para enfrentarlos productivamente y así producir una ciencia mejor.\n\n\n\n\n\n\nBuscar la verdad\n\n\n\n\n\n\n\n\n\nLa búsqueda de la verdad siempre debería prevalecer sobre el deseo defensivo del ego de tener la razón. Esto no es fácil, porque a la mayoría de la gente le resulta difícil admitir que se equivoca. Y es precisamente por esto por lo que la ciencia resulta tan liberadora. Provee un marco de trabajo para la autocorrección, porque el conocimiento científico siempre es provisional. Un hecho científico aceptado hoy puede ser refutado mañana. Por tanto, el método científico engendra humildad epistemológica.\n\n\n\n \n\n\n\n\n\n\nGad Saad"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#anova",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#anova",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "ANOVA",
    "text": "ANOVA\n\nConceptos básicos (modelo de una vía, un criterio, completamente aleatorizado)\nHay situaciones en las que la información que tenemos para predecir una respuesta la tenemos en forma cualitativa, incluso la presencia o ausencia de una categoría. Una variable categórica es una medición discreta y las clases no tienen ningún orden particular. Por ejemplo, consideremos de nuevo las diferentes especies en los datos de energía láctea. Algunas de ellas son simios, mientras que otras son monos del Nuevo Mundo. Podríamos preguntarnos cómo deberían variar las predicciones cuando la especie es un simio en lugar de un mono. El grupo taxonómico es una variable categórica, porque ninguna especie puede ser mitad simio y mitad mono (discreción), y no hay ningún sentido en el que uno sea más grande o más pequeño que el otro (desorden). Otros ejemplos comunes de variables categóricas son:\n\nSexo: macho, hembra\nEstado de desarrollo: lactante, juvenil, adulto\nRegión geográfica: África, Europa, Melanesia\n\nAlgunos de ustedes ya sabrán que variables como esta, llamadas rutinariamente factores, pueden ser fácilmente incluidas en los modelos lineales. Pero lo que no resulta tan intuitivo es la forma cómo se representan estas variables en un modelo. El ordenador hace todo el trabajo por nosotros, ocultando la maquinaria.\nLa hipótesis nula en un análisis de la varianza tipo I común es:\n\\[\nH_0: m_1 = m_2 = m_3 = ... = m_k\n\\]\n\n\n\n\n\n\n¿Cómo es que esta hipótesis se pone a prueba en un ANDEVA?\n\n\n\nPor cierto esta es una prueba “omnibus”, es decir ¡prueba todo (la igualdad de todas las medias) de un jalón!\n\n\nPara ver como es que opera el anova veamos el ejemplo que sigue. Considera un solo factor, “f”, con dos niveles.\n\n\nCódigo\nanova.data &lt;- data.frame(y=c(rnorm(7, 5.4, 1), rnorm(7, 10.8, 1)))\nanova.data$f &lt;- factor(rep(c(\"a\", \"b\"), each = 7))  \n\n\nPongamos estos datos en una gráfica simple, sgún el orden en el que fueron obtenidas las mediciones. Lo primero que haremos es definir la tabla de datos anova.data, como espacio de trabajo. Haremos esto con la función attach(). Esto hace que las variables contenidas en la tabla se puedan llamar directamente sin tener que anteponer el nombre de la estructura que las contiene. Esto es conveniente, pero si olvidamos regresar al espacio general de trabajo, con la función detach(), podemos encontrarnos con situaciones algo extrañas. En caso de que eso ocurra, resulta útil la función search(), que muestra los espacios de trabajo activos.\n\n\nCódigo\nattach(anova.data)\n\n\n\n\nCódigo\nplot(y)\nabline(mean(y), 0)\nfor (i in 1:length(y)) lines (c(i,i), c(mean(y), y[i]))\n\n\n\n\n\n\n\n\n\n\n\n¿Qué muestra esta gráfica? ¿a que equivale la suma de los trazos verticales?\n\n\n\n\n\n\n\nCódigo\ndist_med_y &lt;- sum((y - mean(y))**2)\ndist_med_y\n\n\n[1] 122.6008\n\n\n\n\n\nAhora incorporemos la información del factor f. Para esto hay que calcular los promedios de “y” que corresponden a los niveles de f\n\n\nCódigo\nmeans &lt;- tapply(y, f, mean)\nmeans\n\n\n        a         b \n 4.908902 10.623274 \n\n\nGrafiquemos esta nueva estructura de datos.\n\n\nCódigo\nplot(y)\nlines(c(1, 7.5), c(means[1], means[1]))\nlines(c(7.5, 14), c(means[2], means[2]))\nfor (i in 1:7 ) lines (c(i,i), c(means[1], y[i]))\nfor (i in 8:14) lines (c(i,i), c(means[2], y[i]))\n\n\n\n\n\n\n\n\n\n\n\n¿Qué muestra esta gráfica? ¿a que equivale la suma de los trazos verticales?\n\n\n\n\n\n\n\nCódigo\ndist_med_s &lt;- sum(m1=sum((y[1:7] - means[1])**2), \n                  m2=sum((y[8:14] - means[2])**2))\n\ndist_med_s\n\n\n[1] 8.311666\n\n\n\n\n\n\n\nSi las dos medias fueran iguales ¿cómo compararían estas dos gráficas?\n\n\n\n\n\n\n¿Qué interpretación tiene la diferencia entre las dos sumas mencionadas arriba?\n\n\n\n\n\nEsta diferencia se asocia con la siguiente gráfica:\n\n\nCódigo\nmodelo &lt;- lm(y ~ f) # ¿qué estoy haciendo aquí?\nplot (y, col = \"red\")\nabline (mean(y), 0)\npoints(predict(modelo), pch = 16, col = \"lightblue\")\nfor (i in 1:14) lines(c(i, i), c(mean(y), predict(modelo)[i]), col = \"gray\")\n\n\n\n\n\nAhora la suma de estas líneas verticales es\n\n\nCódigo\ndist_med_s_y &lt;- sum(sum((rep(means[1], 7) - mean(anova.data$y))**2),  \n                    sum((rep(means[2], 7) - mean(anova.data$y))**2))\ndist_med_s_y\n\n\n[1] 114.2892\n\n\n\n\n\nEstas tres formas de calcular las distancias entre datos y promedios se asocia con fuentes de variación\n\nvariaciones o error total\nvariaciones o error residual (componente aleatorio/efecto aleatorio)\nvariaciones o error del modelo (componente sistemático/efecto fijo)\n\nEn el cuadro de análisis de varianza se suele etiquetar a los componentes de error de acuerdo con su fuente. Se les acompaña con los grados de libertad, la suma de cuadrados de las distancias que mostré en las tres gráficas anteriores y luego los llamados cuadrados medios. Para referencia podemos pedrle a R que nos reporte el cuadro de ANOVA de este modelo.\n\n\n\n\n\n\nAnaliza la correspondencia entre los valores y las gráficas que vimos arriba con lo que reporta R\n\n\n\n\n\n\n\nCódigo\nanova(modelo)\n\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nf          1 114.289 114.289  165.01 2.257e-08 ***\nResiduals 12   8.312   0.693                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCódigo\ndist_med_y\n\n\n[1] 122.6008\n\n\nCódigo\ndist_med_s\n\n\n[1] 8.311666\n\n\nCódigo\ndist_med_s_y \n\n\n[1] 114.2892\n\n\n\n\nCódigo\ndetach(anova.data)\n\n\n\nDisposición de tratamientos e intereses sobre los factores\n\nEfectos fijos\nQuizás la forma más simple de identificar las variables explicativas que tienen efectos fijos es pensar en ellas como variables cuyos niveles identifican en forma completa las condiciones de interés para el investigador. Por ejemplo, en el caso de un experimento que analiza el desempeño de larvas de mariposa que toman una dieta rica en proteinas y al mismo tiempo están expuestas a la presencia o no de un alcaloide. Estamos interesados precisamente en esas dietas y en la presencia o no del alcaloide. Estos dos factores son fijos. Es el tipo de variables que normalmente consideramos en nuestros objetivos de investigación. Se asume que su identificación y definición es completa, se asume que no hay más niveles de interés que los definidos y por lo tanto el modelo resultante no puede utilizarse para predecir fuera del ámbito de esas definiciones.\n\n\nEfectos aleatorios\nLas variables de efectos aleatorios surgen cuando se considera que el factor considerado no es sino una muestra de los posibles resultados que se pueden obtener de muestrear la condición que caracteriza el factor. Por ejemplo, si en un experimento para explorar la germinación de Bouteloua gracilis bajo distintas condiciones de temperatura en campo, se distribuyen las semillas en varios sitios de una zona de interés. Los aprecia que hay básicamente dos tipos de ambiente, suelos arenosos y suelos con algo de grava, así que se eligen 5 sitios en cada condición, y en cada uno de ellos se ponen a prueba dos tratamientos, “pisoteo por ganado” y “sin pisoteo por ganado”. Los 10 sitios elegidos estarían definidos como de efectos aleatorios, pues podemos ver que los niveles elegidos son en realidad una muestra de las posibles condiciones que prevalecen en la zona de estudio. Además, claramente el interés de la predicción es ser generalizable para toda la zona. A veces podemos pensar en esta forma de proceder como equivalente a un muestreo estratificado, en este caso, los tipos de ambiente son los estratos. No es el caso del tratamiento pisoteo. aprovechando podemos ver que en este experimento tendremos un mínimo de 4 combinaciones experimentales, y que ese arreglo mínimo se repetirá 5 veces, así que reqeriremos 20 unidades experimentales para realizar el estudio.\n::: {.callout-tip title=“¿Puedes darnos un ejemplo en el que distingas entre efectos fijos y aleatorios?”\n\n\n\n\n\n\n\n\nAnidamiento vs. cruzamiento\nLa anidación o el cruzamiento es otra característica de los datos, o más bien del diseño experimental. Hablamos de que un conjunto de variables están cruzadas en un diseño experimental cuando todos los posibles niveles de las variables están expuestas por igual entre ellas. Podríamos decir que las variables se combinan de “igual a igual”. Es decir, podemos tener tantas posibles combinaciones de las variables como el producto del numero de niveles que tengan. En el caso del experiment de Bouteloua, el experimento sugiere que los sitios y los tratamientos están “cruzados”, de ahí que tengamos necesidad de disponer por lo menos de 4 unidades experimentales.\nEl ejemplo de escuelas que ilustro a continuación debe ayudar a entender mejor estos conceptos. Si las clases son iguales para todas las escuelas, nos estaríamos refiriendo a algo así:\n\nEsto significa que cada clase se imparte por igual y en las mismas condiciones a cada escuela. Algo difícil de imaginar, ¡pero quizás no en los tiempos de la COVID-19!. Este es un diseño cruzado (algunos también podrían llamarlo afiliación múltiple). En R y con las funciones que ajustan modelos estadísticos lineales (lm() y glm()) se produce mediante el operador *.\nEl arreglo anidado se produce cuando las unidades experimentales están subordinadas a algún criterio de clasificación. Un factor B está anidado en otro factor A cuando cada nivel del factor B aparece asociado a un único nivel del factor A (los niveles de B están subordinados a los de A). Aquí tenemos clases anidadas en escuelas, lo cual es un escenario familiar.\n\nEl punto importante aquí es que, entre cada escuela, las clases tienen el mismo identificador, aunque sean distintas si están anidadas. La clase 1 aparece en la escuela 1, la escuela 2 y la escuela 3. Sin embargo, si los datos están anidados, la clase 1 en la escuela 1 no es la misma unidad de medida que la clase 1 en la escuela 2 y la escuela 3.\nNo es posible saber, simplemente inspeccionando los datos, si tenemos efectos aleatorios anidados o cruzados. Esto sólo puede determinarse con el conocimiento de los datos y el diseño experimental. Debido a esto, es muy importante especificar con suficiente claridad el diseño experimental incluyendo las operaciones involucradas para ponerlo en práctica, para poder construir correctamente el modelo estadístico correspondiente, ya que dependiendo de la naturaleza de las variables (fija o aleatoria), los modelos producirán resultados diferentes.\nEl concepto de variables aleatorias no es fácil de comprender, por lo que no hay que preocuparse demasiado por entenderlo completamente en este momento. También es útil tener en cuenta que el hecho de que una variable se considere fija o aleatoria en cierto grado dependerá de la interpretación de la persona que diseña el experimento y realiza el análisis. En R, la operación para incluir efectos anidados es el operador /.\nEn forma específica las interacciones derivadas de cruzamiento se pueden anotar en un modelo como a:b y un anidamiento a %in% b\nNaturalmente podemos encontrar situaciones en las que el experimento combina efectos aleatorios y fijos. Naturalmente, tal diseño se denomina de efectos mixtos."
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#disposición-de-tratamientos-e-intereses-sobre-los-factores",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#disposición-de-tratamientos-e-intereses-sobre-los-factores",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "Disposición de tratamientos e intereses sobre los factores",
    "text": "Disposición de tratamientos e intereses sobre los factores\n\nEfectos fijos\nQuizás la forma más simple de identificar las variables explicativas que tienen efectos fijos es pensar en ellas como variables cuyos niveles identifican en forma completa las condiciones de interés para el investigador. Por ejemplo, en el caso de un experimento que analiza el desempeño de larvas de mariposa que toman una dieta rica en proteinas y al mismo tiempo están expuestas a la presencia o no de un alcaloide. Estamos interesados precisamente en esas dietas y en la presencia o no del alcaloide. Estos dos factores son fijos. Es el tipo de variables que normalmente consideramos en nuestros objetivos de investigación. Se asume que su identificación y definición es completa, se asume que no hay más niveles de interés que los definidos y por lo tanto el modelo resultante no puede utilizarse para predecir fuera del ámbito de esas definiciones.\n\n\nEfectos aleatorios\nLas variables de efectos aleatorios surgen cuando se considera que el factor considerado no es sino una muestra de los posibles resultados que se pueden obtener de muestrear la condición que caracteriza el factor. Por ejemplo, si en un experimento para explorar la germinación de Bouteloua gracilis bajo distintas condiciones de temperatura en campo, se distribuyen las semillas en varios sitios de una zona de interés. Los aprecia que hay básicamente dos tipos de ambiente, suelos arenosos y suelos con algo de grava, así que se eligen 5 sitios en cada condición, y en cada uno de ellos se ponen a prueba dos tratamientos, “pisoteo por ganado” y “sin pisoteo por ganado”. Los 10 sitios elegidos estarían definidos como de efectos aleatorios, pues podemos ver que los niveles elegidos son en realidad una muestra de las posibles condiciones que prevalecen en la zona de estudio. Además, claramente el interés de la predicción es ser generalizable para toda la zona. A veces podemos pensar en esta forma de proceder como equivalente a un muestreo estratificado, en este caso, los tipos de ambiente son los estratos. No es el caso del tratamiento pisoteo. aprovechando podemos ver que en este experimento tendremos un mínimo de 4 combinaciones experimentales, y que ese arreglo mínimo se repetirá 5 veces, así que reqeriremos 20 unidades experimentales para realizar el estudio.\n::: {.callout-tip title=“¿Puedes darnos un ejemplo en el que distingas entre efectos fijos y aleatorios?”"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#dag-de-un-diseño-experimental-simple",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#dag-de-un-diseño-experimental-simple",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "DAG de un diseño experimental simple",
    "text": "DAG de un diseño experimental simple\nUn experimento con asignación de tratamientos en forma completamente al azar, garantiza al máximo posile las vías de influencias ocultas o inadvertidas. Por diseño, la respuesta de las unidades experimentales, Y, al tratamiento T sólo tiene a la asignación aleatoria A como única causa que antecede al tratamiento. Esto lo podemos representar con el diagrama acíclico dirigido, DAG, siguiente:\n\\[\n\\fbox{A} \\rightarrow T \\rightarrow Y\n\\]\nEn este DAG, el marco que rodea a la A indica aleatorización, y como sugiere el diagrama, es la única causa que actua sore el tratamiento. Si hubiera una vía de influencia alternativa (backdoor), a través de alguna tercera variable como podría ser en un caso de germinación de semillas, la luminosidad del sitio o el grado de humendad en el sustrato; entonces, la aleatorización no sería el único factor que influiría sore el tratamiento. El recuadro alrededor de A (el proceso de aleatorización) indica que no existen otros factores actuando sobre T, es decir, A es una influencia puramente estocástica. Esta idea y el proceso de realización de un experimento controlado con aleatorización, da cuenta con toda claridad del valor de esta forma de realizar estudios para desentrañar relaciones de causalidad.\nEste DAG nos conduce al modelo linear siguiente\n\\[\ny = \\mu + T +  \\varepsilon\n\\]\nEn donde y son las mediciones de la variable Y en respuesta al efecto de T, \\(\\mu\\) es un valor de referencia general (tradicionalmente la media general de la variale Y, aunque puede elegirse cualquier otro valor de referencia que convenga al estudio) y la épsilon da cuenta del efecto aleatorio inducido por \\(\\fbox{A}\\), por lo que es necesario postular una distribución de probabilidades apropiada para caracterizar su comportamiento."
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#la-tradición-de-prueba-de-hipótesis",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#la-tradición-de-prueba-de-hipótesis",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "La tradición de prueba de hipótesis",
    "text": "La tradición de prueba de hipótesis\nEl planteamiento de la prueba de significancia estadística de hipótesis se pueden encontrar ya en el siglo XIX, su formalización teórica realmente ocurre en los años 20 y 30 del siglo XX con las publicaciones de Sir Ronald Fisher, Jerzy Neyman y Egon Pearson.\nEntre estos autores existieron diferencias filosóficas y conceptuales entre sus planteamientos y posturas. En special Fisher y Neyman sostuvieron acres debates que sólo se interrumpieron con el fallecimiento de Fisher en 1962. No obstante el debate continua hasta hoy.\nEl resultado es que el uso actual de la prueba estadística de hipótesis se ha conformado como un extraño híbrido surgido de una mezcla más o menos ecléctica de las dos formas de pensar y no tanto una teoría coherente sobre la prueba de hipótesis.\n\nEl procedimiento\nEl objetivo de una prueba de significancia es hacer inferencias sobre un parámetro que el investigador concibe asociado a un atributo numérico relevante de la población que define su objetivo de investigación. El procedimiento utiliza como base los datos de una muestra extraída de esa población. El enfoque se opera específicamente como un instrumento para excluir un valor o una gama de valores específicos como plausibles para el parámetro.\n\nEl paso a paso del formalismo de prueba de hipótesis\n\nConstruir un modelo estadístico. Se trata de un conjunto de supuestos sobre las variables de interés.\nEspecificar la hipótesis nula.\nDefinir un estadístico de contraste (frecuentemente llamada “la prueba estadística”).\nIdentificar la distribución del estadístico de contraste bajo los supuestos del modelo.\nCalcular, bajo el supuesto de la hipótesis nula, el valor del estadístico de contraste en la muestra observada.\nCalcular la probabilidad de tener un valor del estadístico como el resultante o un valor más extremo en la distribución de referencia (el famosos valor p).\nAceptar o rechazar la hipótesis nula. Si el valor p es menor que el criterio α de significancia (especificado a priori), se rechaza la hipótesis nula, en el caso contrario se acepta o por lo menos no se rechaza (por lo pronto).\n\nRechazar la hipótesis nula es algo que quizás produce poca tensión emocional, quizás hasta un alivio, finalmente, el investigador sospecha (desea mostrar) que lo interesante está en otra parte, en su juego de hipótesis alternativas.\n\n\n\n¿Es este procedimiento afín al refutacionismo Popperiano?.\nPara interpretar correctamente un valor p se necesita tener claro que se opera dentro de una marco conceptual frecuentista. Esto lleva a que se conciba a los parámetros del modelo estadístico como constantes en la población objetivo (valor fijo que nunca se conoce en realidad).\nAdemás se asume que, al menos conceptualmente, sería posible repetir el experimento un número infinito de veces. También se asume que siempre se está muestreando la misma población objetivo (universo muestral) así que los parámetros tienen el mismo valor, pero las muestras fluctúan aleatoriamente.\nBajo estos supuestos es aceptable considerar que el estadístico de prueba se distribuye de acuerdo con el modelo de probabilidades propuesto para construir el contraste y por lo tanto da cuenta de las variaciones esperadas entre las diferentes repeticiones del experimento.\nEn la aproximación tradicional a la contrastación estadística de hipótesis (frecuentista) se parte de la formulación de proposiciones hipotéticas que son descritas con referencia a alguna distribución de probabilidades.\nEn este marco conceptual, un componente es la llamada hipótesis nula (\\(H_{0}\\)). Se concibe como un planteamiento que asume la ausencia de efecto de los “factores explicativos”.\nEn contraste se propone una o más hipótesis alternativas (\\(H_{1...n}\\)), en las que se valora algún o algunos efectos de los “factores explicativos”. La proposición hipotética que hacemos se traduce en valores que podemos comparar con un conjunto de valores a los que consideramos observados. La diferencia entre estos dos conjuntos de valores nos permiten valorar la factibilidad de nuestra proposición.\n\nEn la práctica, suele ocurrir que se concentre la atención en la hipótesis nula expresada con la gran simplicidad que implica la ausencia de efectos y se proceda con menor rigurosidad el análisis de la hipótesis alternativa, la que suele procesarse en forma más bien exploratoria mediante procedimientos de comparaciones múltiples.\n\n\nCríticas\nEntre las críticas que se han hecho al procedimiento clásico de prueba de hipótesis está la que señala que el valor p, al excluir el valor de cero como valor plausible para el parámetro, no aporta información completa sobre los valores que sí son plausibles. Esto implica que la significancia estadística no implica relevancia práctica.\n\n\n¿Cómo interpretas esta afirmación?\nEn el mismo razonamiento, un “valor de p extremadamente significativo” no hace otra cosa que excluir el cero como valor plausible para el parámetro no precisamente sobre la calidad del hallazgo.\nOtra crítica señala que interpretar el valor p en términos de evidencia en contra de la hipótesis nula (siguiendo el pensamiento de Fisher) o la plausibilidad de que la hipótesis nula sea falsa a veces se expresan equivocadamente como la probabilidad de que la hipótesis nula sea falsa en consideración de la evidencia (E) disponible. Al plantearlo así, formalmente se enuncia como \\(P(H_{0}|E)\\). Pero esto no es apropiado, formalmente resulta ser una inconsistencia en la lógica del planteamiento.\n\n\n¿Puedes reconocer esta inconsistencia?\nLa inconsistencia está en que, en primer lugar como dije arriba, el valor p se define dentro del marco frecuentista y se concibe que los parámetros son valores constantes, aunque desconocidos (¡supuesto estadístico de efectos fijos!). No se trata de los parámetros de alguna distribución de probabilidades (observada o no). Por tanto, no tiene sentido asignar probabilidades a los distintos valores estimados del parámetro.\nAdemás, el valor p se calcula bajo el supuesto de que la hipótesis nula es cierta; esto hace imposible, por construcción, interpretarlo como la probabilidad de que la hipótesis alternativa sea cierta. La probabilidad a la que se refiere el valor p guarda más relación con la probabilidad inversa, \\(P(E|H{0})\\). ¿Qué tan probable sería tener una muestra como la que tenemos enfrente, si la hipótesis considerada fuera cierta?. Esto se conoce como la verosimilitud, es decir, la probabilidad de observar los datos que se han obtenido en un estudio suponiendo que los atributos del modelo fueran ciertos. La verosimilitud valora a la muestra como un resultado condicional a los supuestos hechos en el modelo estadístico y en este caso, la hipótesis nula.\nSin embargo, la probabilidad que realmente interesa -por ejemplo, al investigador de nuestro ejemplo- es la anteriormente mencionada \\(P(H_{0}|E)\\). Aunque no está definida dentro del marco frecuentista, en el marco Bayesiano sí se define. Las probabilidades \\(P(E|H_{0})\\) y \\(P(H_{0}|E)\\) no son iguales.\n\n\n¿Recuerdas qué representa cada uno de ellas? ¿cuál es la relación entre ambas?\nOtra crítica interesante surge de la llamada paradoja de Lindley (1957), quien mostró, con una formulación Bayesiana, que existe la posibilidad de tener datos congruentes con rechazar una hipótesis nula con un bajo valor p y que al mismo tiempo llevan a una probabilidad posterior alta.\nEncontró que es perfectamente posible, a partir de los mismos datos E, obtener al mismo tiempo una \\(P(E|H_{0})\\) = 0.05 (baja probabilidad de obtener una muestra como la que se observó, si \\(H_{0}\\) fuera cierta) y \\(P(H_{0}|E)\\) = 0.95 (fuerte evidencia en favor de \\(H_{0}\\)). Este resultado contradictorio permite ver lo cuestionable que resulta interpretar el valor p como evidencia en contra de la hipótesis nula.\nSe ha contrargumentado que la paradoja requiere muestras grandes para manifestarse, y se oponen a los supuestos adicionales que requiere el análisis Bayesiano. Se ha defendido que bajo condiciones razonables, un bajo valor p generalmente implica una baja probabilidad posterior, es decir, poca evidencia para la hipótesis nula. Sin embargo, a pesar de esta defensa al enfoque clásico, se ha encontrado que los valores p sistemáticamente sobrestiman la evidencia en contra de la hipótesis nula.\nEn resumen, el valor mismo de p, resultado de una prueba clásica de hipótesis, no aporta mucha información de interés para los investigadores. En caso de optar por la hipótesis alternativa con base en la p, no se favorece llegar a ninguna conclusión sustancial sobre posibles explicaciones alternativas, lo único que queda claro es que la nula probablemente es falsa.\nPara que quede claro, hay que insistir en que si el valor p es juzgado significativo, únicamente nos inclina a excluir un solo valor como estimador plausible para el parámetro. Peor aún, el significado de plausible en la última expresión tiene una relación nebulosa con la probabilidad que sí le interesa a los investigadores: la probabilidad posterior de que la hipótesis nula sea cierta a la luz de la evidencia recopilada \\(P(H_{0}|E)\\).\n\n\n\n\n\n\n¿Qué piensas de la paradoja de Lindley y sus implicaciones\n\n\n\n\n\n\n\n\nRemedios y alternativas para la prueba estadística de la hipótesis nula\nPara enfrentar algunos de los inconvenientes del enfoque clásico de prueba de hipótesis se ha recomendado ahora sustituir el valor p por un intervalo de confianza que abarca un conjunto de valores que permiten valorar si es razonable rechazar la hipótesis nula y además, en caso contrario proporciona una gama de valores que caracterizan al parámetro, lo que resulta de mucho interés.\nLa práctica de presentar intervalos de confianza, posiblemente en conjunto con p, constituye una respuesta a la crítica de que sólo se excluye un valor como valor plausible para el parámetro. Además, hacer esto proporciona información sobre significancia. Si el intervalo no incluye el valor de cero, entonces se declararía el resultado como estadísticamente significativo. El intervalo informa también sobre el posible tamaño del efecto.\nA la luz de las críticas, Muchos autores ven necesario actualmente adoptar el marco Bayesiano para enfrentar las deficiencias del enfoque clásico.\n\n\nPotencia de la prueba\nEn la práctica, la potencia de la prueba depende del grado de dispersión en los datos. Si se está asumiendo un modelo de probabilidades Gaussiano (distribución normal), el factor de dispersión o escala se relaciona con la varianza. Por lo tanto, es usual notar que el mismo cálculo del error estandar, \\(s_{e}=\\frac{\\sigma}{\\sqrt{n}}\\), sugiere la solución.\n\n\nSe puede incrementar el tamaño de muestra, n,\n\n\n\n\n\n\n\n¿Por qué funcionaría esto?\n\n\n\n\n\n\n\nAumentar la precisión con la que se estima \\(\\sigma^2\\),\n\n\n\n\n\n\n\n¿Cómo se puede hacer esto?\n\n\n\n\n\n\nEs interesante apreciar, que la búsqueda de un tamaño de muestra apropiado para un estudio que estemos planeando, se puede lograr muy eficazmente haciendo simulaciones como las que hemos estado viendo en este bloque del curso. A través de este camino y haciendo el esfuerzo de especificar hipótesis alternativas relevantes se pueden resolver preguntas como:\n\n¿Cuál es el tamaño de muestra necesario para detectar una cierta diferencia en lo que medimos?\n¿Cuál es la diferencia detectable dada una n o una potencia de la prueba (\\(1-\\beta\\))?\n¿Cuál es la potencia (\\(1-\\beta\\)) dado un n y cierta diferencia con \\(H_{a}\\) de interés?"
  },
  {
    "objectID": "posts/01-concepto-y-modelos-experimentar/index.html#quiz-prueba-estadística-de-hipótesis",
    "href": "posts/01-concepto-y-modelos-experimentar/index.html#quiz-prueba-estadística-de-hipótesis",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "Quiz: Prueba estadística de hipótesis",
    "text": "Quiz: Prueba estadística de hipótesis\nParticipa: vevox.app ID: 125-688-362"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "M3 - Diseño de Experimentos",
    "section": "",
    "text": "Bienvenidos al Módulo 3 de estadística\n\n\n\n\n\n\n\noperación\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Octavio Pérez-Maqueo, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nConceptos y Modelos en la experimentación\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nLeyes de la Ciencia\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nEl Modelo estadístico lineal\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n29 ene 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nDiagramas Causales\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n31 ene 2024\n\n\nMiguel Equihua, Octavio Pérez Maqueo, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nExperimentos completamente aleatorizados\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n1 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nRestricciones a la aleatorización\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n2 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nModelos anidados\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n6 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nModelos de Efectos Mixtos\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n7 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nModelos de medidas repetidas\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n8 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nExperimentación Ecológica\n\n\n\n\n\n\n\ntaller\n\n\n\n\n\n\n\n\n\n\n\n8 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca del módulo 3",
    "section": "",
    "text": "El módulo III se ocupa de las nociones básicas de diseño de experimentos y las técnicas estadísticas utilizadas para analizarlos: El Análisis de Varianza (Andeva o Anova).\nSe reúnen aquí los documentos y código en R utilizados como apoyo audiovisual en clase. Todo está disponile en el repositorio de Github que indica el ícono de abajo y en la arra de navegación del blog."
  },
  {
    "objectID": "ejercicios.html",
    "href": "ejercicios.html",
    "title": "M3-ejercicios",
    "section": "",
    "text": "Tarea de análisis críticos\n\n\n\n\n\n\n\ntaller\n\n\n\n\n\n\n\n\n\n\n\n1 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nPizzas\n\n\n\n\n\n\n\ntaller\n\n\n\n\n\n\n\n\n\n\n\n2 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nEnsayo de antivenenos\n\n\n\n\n\n\n\ntaller\n\n\n\n\n\n\n\n\n\n\n\n2 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nControl de Tareas\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n7 feb 2024\n\n\nMiguel Equihua, Elio Lagunes\n\n\n\n\n\n\n  \n\n\n\n\nMi primer documento r-shinylive en Quarto\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSecure\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPrueba r-shinysurvey en Quarto\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nModelación con Stan\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#objetivos-del-módulo-3",
    "href": "posts/00-Bienvenida/index.html#objetivos-del-módulo-3",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Objetivos del Módulo 3",
    "text": "Objetivos del Módulo 3\nDurante las últimas semanas revisaron conceptos de probabilidad y matemáticas que necesitamos como un lenguaje eficiente de comunicación. También empezaron a explorar como es que se pueden analizar proposiciones sobre la existencia de asociación o incluso relaciones de dependencia entre dos variables: modelos de regresión simple. Ahora vamos aplicar y extender estos aprendizajes para abordar el desafío de producir conocimiento que nos permita comprender como funciona el mundo. Asumir un interés en la comprensión causal del mundo requiere desarrollar las habilidades de pensamiento crítico, lo que constituye por tanto otro de los propósitos del módulo.\nUtilizaremos el lenguaje de programación R como plataforma de cómputo para el análisis de datos. Aspiramos a ofrecerles así un curso introductorio para su uso. También nos interesa acercarnos a los enfoques formales para el análisis causal actual, mediante la formulación de Grafos Acíclicos Dirigidos (DAG). Los invitamos a hacer explícitas y a dibujar las relaciones causales de sus proyectos para comprenderlas, comunicarlas y analizarlas con mayor eficiencia.\nComo ejercicio inicial les pedimos preparen y nos entreguen en una sola cuartilla la descripción de una de las preguntas de investigación que se han planteado en su proyecto de posgrado, con suficiente detalle como para comprender el asunto y la propuesta sobre como poner a prueba la idea planteada. No se trata de todo el protocolo de su proyecto de investigación. Escojan sólo un aspecto de él que deseen compartir y explorar en este curso como oportunidad de aprendizaje."
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#plan-de-clase",
    "href": "posts/00-Bienvenida/index.html#plan-de-clase",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Plan de clase",
    "text": "Plan de clase\n\n\nCódigo\ncontenido &lt;- read_csv(\"contenido.csv\", col_names = TRUE, show_col_types = FALSE)\ncontenido$lectura &lt;- c(\" \", \"debate\")[contenido$lectura + 1]\n\ncontenido %&gt;% flextable(col_keys = c(\"dia\", \"lectura\", \"tema\")) %&gt;% \n  set_header_labels(values = list(dia = \"Día\", \n                                  lectura= \"Lectura\", \n                                  tema = \"Tema\")) %&gt;% \n  autofit() %&gt;% \n  theme_zebra(odd_body = c(\"lightcyan1\")) %&gt;% \n  bold(i = 1:9, j = 1)\n\n\n\nCalendario de actividades del Módulo 3DíaLecturaTemaLunes 29 Un lenguaje para describir modelos (diseño de experimentos y de tratamientos)Martes 30 Causalidad y modelación gráfica: Grafos Acíclicos Dirigidos (DAG)Miércoles 31debateDiseño de experimentos: hipótesis y la modelación estadísticaJueves 1 Efectos fijos y aleatorios sus implicaciones en los modelos estadísticosViernes 2 Evitar confusión por variables conocidas: Bloques aleatorizadosMartes 6debateMuestreo dentro unidades experimentales: Diseños anidadosMiércoles 7 Unidades experimentales múltinivel y anidadas: Diseños de Parcelas divididasJueves 8debateModelos jerárquicos (incluye medidas repetidas)Viernes 9 Feria del diseño para discutir los protocolos de los estudiantes"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#lecturas",
    "href": "posts/00-Bienvenida/index.html#lecturas",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Lecturas",
    "text": "Lecturas\nComo parte de las experiencias de aprendizaje que realizaremos tenemos tres lecturas. Les pedimos que hagan una lectura crítica de los textos propuestos y que preparen un comentario que contenga sus apreciaciones en favor o en contra de los argumentos presentados. También esperamos comenten sobre las implicaciones amplias y para la práctica científica en lo general, de los argumentos que exponen los autores. Sus reacciones tendrán oportunidad de ser expuestas y debatidas en un espacio del programa del módulo 3 a lo largo de 60 minutos.\nlas lecturas son:\n\nbelief in conspiracy theories\nguide to model selection and causal inference\nSame data, different analysts"
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#evaluación",
    "href": "posts/00-Bienvenida/index.html#evaluación",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Evaluación",
    "text": "Evaluación\n\nEl Módulo III será evaluado a través de las tareas y controles de lectura que les pediremos que hagan conforme se desarrolle el curso. La participación en quizes y preguntas en línea será considerada como una oportunidad de mejora, aunque la no participación no se considerará para disminuir la calificación."
  },
  {
    "objectID": "posts/00-Bienvenida/index.html#estudiantes",
    "href": "posts/00-Bienvenida/index.html#estudiantes",
    "title": "Bienvenidos al Módulo 3 de estadística",
    "section": "Estudiantes",
    "text": "Estudiantes\n\n\nCódigo\nestudiantes_2024 &lt;- read_excel(\"Estudiantes Curso Estadística y Diseño Experimental 2024.xlsx\", skip = 6)\n\nestudiantes_2024 %&gt;% \n  arrange(Estudiante) %&gt;% \n  flextable(col_keys = c(\"Matrícula\", \"Estudiante\")) %&gt;% \n  autofit()\n\n\n\nMatrículaEstudianteDD23023Barran Prior Roxana YvetteMM23009Bermúdez Aguas AuroraMM23020Fernandez Ramos LilianaOyente (DD INECOL)López Adame HaydéeDD23025Montiel Hernandez Nestor ManuelMM23002Morales Morales Kenia ElizabethDD23022Pulido Rios LauraMM23018Retavisca Pilonieta Andrea PaolaMM23025Rey Gómez Daniela FernandaMM23019Syro Posada LauraMM23001Sánchez González Ismael EdoardoDD23010Sánchez Hernández GibránDD23004Tepox Vivar Natalia"
  },
  {
    "objectID": "posts/02-leyes-de-la-ciencia/index.html",
    "href": "posts/02-leyes-de-la-ciencia/index.html",
    "title": "Leyes de la Ciencia",
    "section": "",
    "text": "En esta primera sesión les proponemos reflexionar sobre la intención o incluso necesidad de recurrir a enfoques numéricos o matemáticos para hacer ciencia. También, debemos considerar el propósito mismo de la actividad científica en la que estamos involucrados. Cuando hablamos de generación de conocimiento, ¿realmente a qué nos estamos refiriendo?. Podríamos considerar que la producción de conocimiento involucra la formulación de expresiones matemáticas. Con estas expresiones podemos describir la existencia de relaciones específicas entre procesos que observamos. ¿es esto así? Si es el caso, ¿es la única manera de hacerlo?. Si consideramos que nos es la única, entonces cabe preguntarnos ¿es la mejor manera de hacerlo?. Estas y otras inquietudes de este tipo serán el tema de reflexión y hasta debate si quieren en esta primera sesión.\n\nParticipación activa\nHemos previsto tener frecuentes eventos interactivos para dar seguimiento a los temas que iremos tratando o para generar espacios de enfoque que nos ayuden a generar contextos de discusión que nos ayuden a reflexionar sobre cómo es que hacemos ciencia. Para hacer esto utilizaremos la aplicación en línea a la que podrán acceder desde sus computadoras o teléfonos celulares mediante el siguiente vínculo: https://vevox.app/#/m/152551925 o recurriendo al siguiente código QR.\n\n\n\nApoyo audiovisual de la sesión\nA continuación encontraran la presentación que usamos como apoyo audiovisual para conducir la exploración de los temas que discutimos en esta sesión (haz click en la imágen)."
  },
  {
    "objectID": "posts/04-diagramas-causales/index.html",
    "href": "posts/04-diagramas-causales/index.html",
    "title": "Diagramas Causales",
    "section": "",
    "text": "Judea Pearl se ha aproximado a la causalidad desde una perspectiva matemática y computacional. En ese camino retomó y dio un nuevo impulso a los llamados modelos probabilísticos gráficos en su variante de redes Bayesianas. También ha incursionado en los llamados modelos de ecuaciones estructuradas, también de la familia de los modelos gráficos. Todo ello vinculado con los Gráfos Acíclicos Dirigidos, a los que llamaremos DAG (del inglés directed acyclic graphs). Pearl y colaboradores así como otros investigadores ahora, han venido desarrollando la teoría que nos permite analizar tales DAGs para comprender los patrones de dependencia causal así como los de correlación que implica una proposición causal dada. En esta contribución buscamos mostrarles algunos elementos interesantes de esto y con ello, animarlos a estudiar estas ideas con mayor profundidad."
  },
  {
    "objectID": "posts/04-diagramas-causales/index.html#ejemplo-efectos-de-sesgo-en-las-causas",
    "href": "posts/04-diagramas-causales/index.html#ejemplo-efectos-de-sesgo-en-las-causas",
    "title": "Diagramas Causales",
    "section": "Ejemplo: Efectos de sesgo en las causas",
    "text": "Ejemplo: Efectos de sesgo en las causas\nEl primer ejemplo de simulación que haremos parte de la proposición causal:\n\nEl aprendizaje (X) tiene como efecto el conocimiento (C), y conocer provoca la comprensión (Y),\n\nAdemás actúan algunos factores exógenos (U, son el término de error en el modelo estadístico). En la vida real, el aprendizaje, el conocimiento y la comprensión pueden ser operacionalizados por algún cuestionario y estandarizados para dar la precisión necesaria al análisis.\nEl ejemplo consiste ahora en producir un conjunto de datos que cumpla, por diseño, con la descripción que acabo de hacer. En este caso utilizaremos las ecuaciones siguientes.\n\\[\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\\nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n\\]\nen donde N(μ, σ) indica que existen variaciones por causas no observadas que vamos a suponer generan oscilaciones aleatorias o un ruido, cuya distribución es semejante a la que produciría una distribución Normal de probabilidades. Ahora escribimos estas ecuaciones en un escript de R.\n\n\nCódigo\nset.seed(1896) # Si interesa repetir la misma secuencia de numeros aleatorios. Habilita Repetibilidad\nn &lt;- 1000 # Sample Size\n\naprender &lt;- rnorm(n)\nconocer &lt;- 5 * aprender + rnorm(n)  # Conocer depende del comportamiento de aprender\nentender &lt;- 3 * conocer + rnorm(n)  # entender depende del comportamiento de conocer\n\n# Para comodidad de cálculo junto los datos en una tabla, un \"data.frame\"\ndatos &lt;- data.frame(aprender, conocer, entender)\n\n\nEl DAG que describe la situación descrita lo podemos producir en R con ayuda de la biblioteca DAGitty. Con las instrucciones siguentes.\n\n\nCódigo\nlibrary(dagitty)\n\nejemplo_1_DAG &lt;- dagitty('dag{\n                     aprender -&gt; conocer\n                     conocer -&gt; entender\n\n                     aprender[exposure, pos=\"0,0\"]\n                     conocer[pos=\"1,0\"]\n                     entender[outcome, pos=\"2,0\"]}')\noptions(repr.plot.width=10, repr.plot.height=3)\npar(cex=2, lwd = 5)\nplot(ejemplo_1_DAG)\n\n\n\n\n\nSi optamos por no “corregir” la estimación por el efecto del mediador, Supondríamos que el efecto total del aprendizaje sobre el entendimiento no tiene sesgo. La estimación de esta relación la obtenemos con el modelo que calculamos en ejemplo_1_ecuación_1.\n\n\nCódigo\nejemplo_1_ecuacion_1 &lt;- lm(entender ~ aprender)\nsummary(ejemplo_1_ecuacion_1)$coefficients[,1:2]\n\n\n               Estimate Std. Error\n(Intercept) -0.02227676 0.09661146\naprender    15.12087585 0.09781602\n\n\n¿Qué piensas de este resultado? ¿El modelo es congruente con la proposición causal? Si ahora optamos por sí “corregir” los efectos considerando que el conocimiento puede estar interfiriendo la estimación del efecto total del aprendizaje sobre el entendimiento. Ahora, el modelo que da cuenta de esta nueva situación es el que calculamos en ejemplo_1_ecuación_2.\n\n\nCódigo\nejemplo_1_ecuacion_2 &lt;- lm(entender ~ aprender + conocer)\nsummary(ejemplo_1_ecuacion_2)$coefficients[,1:2]\n\n\n                Estimate Std. Error\n(Intercept) -0.004947807 0.03077153\naprender     0.121514701 0.16253665\nconocer      2.981736249 0.03171170\n\n\nLos resultados de esta exploración produce dos ecuaciones:\n\\[\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\\nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n\\]\n\\[\n\\begin{align}\nentender &= -0.022 + 15.12 \\, aprender  + \\varepsilon \\\\\nentender &= -0.005 +  0.122 \\, aprender + 2.98 \\, conocer + \\varepsilon\n\\end{align}\n\\]\n\n¿Puedes explicar qué pasó aquí?\n¿Qué relación tiene esto con lo que cabría esperar de acuerdo con as reglas de la “separación direccional”?\n¿Qué sugieren los datos del ajuste del modelo estadístico lm?\n¿Tienen relevancia el aprendizaje y el conocimiento?\n¿Cuál es el modelo adecuado dada la proposición causal considerada?\n\nPodemos utilizar a dagitty para explorar el DAG directamente de la siguiente manera. Podemos preguntarnos cuales serían las formas de separar el grafo con criterios de independencia condicional. Se trata de aplicar las tres reglas de separación direccional al grafo. Afortunadamente dagitty lo puede hacer por nosotros.\n\n\nCódigo\nimpliedConditionalIndependencies(ejemplo_1_DAG)\n\n\naprn _||_ entn | cncr\n\n\n¿Qué indica este resultado?\n\\[\naprender \\,\\, \\ci \\,\\, entender \\,\\, | \\,\\, conocer\n\\]\nAdemás de hacer esto por nosotros, la biblioteca dagitty nos permite poner a prueba la correspondencia de los datos con estas ideas. Lo hacemos con la función localTests.\nLa función localTests calcula el coeficiente de correlación de Pearson para cada condición considerada. El resultado incluye el valor p y el intervalo de confianza del coeficiente de correlación para cada una de las relaciones de independencias condicionales implicadas por la estructura del modelo.\nEl coeficiente de correlación de Pearson varía entre -1 y 1. El valor 0 implica que no hay correlación, mientras que -1 o 1 implica una correlación lineal perfecta.\nEl valor p de la prueba indica la probabilidad de obtener un conjunto de datos como el que se tiene, asumiendo la hipótesis de que la condición de independencia correspondiente es verdadera.\nPor lo tanto, un coeficiente de correlación cercano a 0 con un valor p alto es sugerente de que la independencia condicional indicada es congruente con el patrón detectable en los datos.\nPor el contrario, un valor alto del coeficiente de correlación con un valor p bajo sugiere que la independencia condicional considerada no es congruente con el conjunto de datos.\nLas columnas etiquetadas com 2.5% y 97,5% contienen el intervalo de confianza del 95% para el coeficiente de correlación.\nCuanto más estrecho sea el intervalo de confianza y alejado de cero resulte, más fuerte será la evidencia de que la independencia condicional que implica el DAG no se mantiene en el conjunto de datos disponible para el ensayo.\n\n\nCódigo\n# El tipo de análisis \"cis\" usa regresión lineal para poner a prueba la correlación\nejemplo_1_analisis_DAG &lt;- localTests(x=ejemplo_1_DAG, data=datos, type=\"cis\") \n\nprint(ejemplo_1_analisis_DAG)\n\n\n                        estimate   p.value        2.5%      97.5%\naprn _||_ entn | cncr 0.02367054 0.4549614 -0.03840997 0.08556934\n\n\nSi lo preferimos, podemos obtener una representación gráfica de estos resultados.\n\n\nCódigo\noptions(repr.plot.width=14, repr.plot.height=5)\npar(cex=1.5, lwd = 3, oma = c(1,2,1,1), mar = (c(4,2,1,1) + 0.5))\nplotLocalTestResults(ejemplo_1_analisis_DAG, col = \"blue\")\n\n\n\n\n\n\n¿Puedes comentar tu interpretación de estos resultados del modelo y los datos sobre aprendizaje y conocimiento?"
  },
  {
    "objectID": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#el-modelo-estadístico-lineal-generalcenter",
    "href": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#el-modelo-estadístico-lineal-generalcenter",
    "title": "Modelo Estadístico Lineal",
    "section": "El modelo estadístico lineal general{center}",
    "text": "El modelo estadístico lineal general{center}\nEstructura general"
  },
  {
    "objectID": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#ejemplo-de-modelo-lineal",
    "href": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#ejemplo-de-modelo-lineal",
    "title": "Modelo Estadístico Lineal",
    "section": "Ejemplo de modelo lineal",
    "text": "Ejemplo de modelo lineal\n\nGanancia de peso en un grupo de orugas que declina conforme se incrementa el contenido de taninos en la dieta.\nEsta condición puede describirse en forma abreviada así:\n\n\n\nganancia de peso de cada oruga=ganancia de peso base en general+efecto del contenido de taninos en la dieta+efecto de otros factores que fluctuan aleatoriamente\n\nComo modelo lineal se puede escribir así :\n\\[\ny_{ij} = \\beta_0 x_0j + \\sum_{i=1}^{k}\\beta_i x_{ij} + \\varepsilon_{j(i)}  \n\\]"
  },
  {
    "objectID": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#modelos-con-variables-explicativas-cualitativas",
    "href": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#modelos-con-variables-explicativas-cualitativas",
    "title": "Modelo Estadístico Lineal",
    "section": "Modelos con variables explicativas cualitativas",
    "text": "Modelos con variables explicativas cualitativas\n\n\n\nUn agrónomo planea estudiar las tasas de producción de cuatro híbridos de trigo en tres regiones geográficas representantes de diferentes condiciones de sequía. Los sitios se escogen según la cantidad de lluvia como normal climatológica y la respuesta es el rendimiento por hectárea. Las semillas de los híbridos son asignadas aleatoriamente a los sitios.\n\n\n¿cómo piensas que se podría hacer esta aleatorización.\n\n\n\n\n¿cual sería el modelo lineal que lo podría describir?\n\n\n\n\\[\ny_{ijk} = \\mu + R_i + H_j + RH_{ij} +  \\varepsilon_{k(ij)}\n\\]"
  },
  {
    "objectID": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#el-modelo-en-todo-su-esplendor",
    "href": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#el-modelo-en-todo-su-esplendor",
    "title": "Modelo Estadístico Lineal",
    "section": "El modelo en todo su esplendor",
    "text": "El modelo en todo su esplendor\n\\[\n\\begin{gather*}\ny_{ijk} = \\mu + \\beta_{1k}R_{1k} + \\beta_{2k}R_{2k} + \\beta_{3k}R_{3k} + \\\\\n          \\beta_{4k}H_{1k}   + \\beta_{5k}H_{2k}   + \\beta_{6k}H_{3k}   + \\beta_{7k}H_{ik} + \\\\\n          \\beta_{8k}RH_{1k}  + \\beta_{9k}RH_{2k}  + \\beta_{10k}RH_{3k} + \\beta_{11k}RH_{ik}+ \\\\\n          \\beta_{12k}RH_{1k} + \\beta_{13k}RH_{2k} + \\beta_{14k}RH_{3k} + \\beta_{15k}RH_{ik}+\\\\\n          \\beta_{16k}RH_{1k} + \\beta_{17k}RH_{2k} + \\beta_{18k}RH_{3k} + \\beta_{19k}RH_{ik}+\n          \\varepsilon_{k(ij)}\n\\end{gather*}\n\\]"
  },
  {
    "objectID": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#qué-valores-toman-las-x-las-r-y-las-h",
    "href": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html#qué-valores-toman-las-x-las-r-y-las-h",
    "title": "Modelo Estadístico Lineal",
    "section": "¿Qué valores toman las X, las R y las H?",
    "text": "¿Qué valores toman las X, las R y las H?\nLa forma más común de modelar datos cualitativos es:\n\n\n\n\nMediante variables usualmente llamadas factores.\nUn factor es una listas de nombres o códigos de identificación de estados o niveles mutuamente excluyentes.\nEn la modelación se requiere convertir el factor a variables indicadoras o dummy.\nHabrá tantas variables dummy como estados o niveles tenga el factor\nCada variable se construye anotando la presencia/ausencia de la condición del factor.\n\n\n\n\n\\[\nH_1 = \\left\\{\n         \\begin{align*}\n           \\text{si } \\color{red}{sí} \\text{ es híbrido del tipo } a &: 1 \\\\\n           \\text{si } \\color{red}{no} \\text{ es híbrido del tipo } a &: 0\n         \\end{align*}\n      \\right\\}\n\\]"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes-fert_dat",
    "href": "posts/05-dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes-fert_dat",
    "title": "Experimentos completamente aleatorizados",
    "section": "Respuesta de Cultivares a fertilizantes (fert_dat)",
    "text": "Respuesta de Cultivares a fertilizantes (fert_dat)\nEjemplo tomado de Crawley (1998). Glim for Ecologists. Oxford. UK.\nEs un experimento en el que se midió el crecimiento (masa seca al cosechar = y) de plantas tratadas con 10 concentraciones diferentes de suplemento mineral como fertilizante, f. El experimento fue realizado con dos cultivares diferentes, g. Uno fue clonado de plantas de un ambiente árido y el otro de uno húmedo. Todas las plantas de cada tipo, sin restricciones, fueron asignadas aleatoriamente a los distintos niveles de fertilizante.\n\nLectura de datos\n\n\nCódigo\nfert_dat &lt;- read.table(\"fertilizante.DAT\",\n                    col.names=c(\"fertilizante\", \"rendimiento_peso\")) \n\nhead(fert_dat)\n\n\n  fertilizante rendimiento_peso\n1            1           2.8215\n2            2           2.3590\n3            3           3.0912\n4            4           2.5297\n5            5           3.4753\n6            6           3.6493\n\n\nA veces hay archivos que contienen datos faltantes o perdidos. Podemos enfrentar eso con la función complete.cases() que revisa linea por linea el archivo y regresa “verdadero” si todas las columnas tienen datos válidos y “falso” si hay huecos. Esta lista de “verdaderos” y “falsos” la podemos usar para elegir que filas del archivo de datos están completas y así podemos eliminarlas del conjunto de datos que vamos a procesar.\nSobre los datos limpios, generamos la variable indicativa del tipo de ambiente del que se tomo la planta que se clonó.\n\n\nCódigo\n# En caso de que haya datos extra, elimino registros leidos como datos erróneos\nfert_dat &lt;- fert_dat[complete.cases(fert_dat), ]\n\n\n\n\nGenera los factores genotipo y fertilizante\n\n\nCódigo\nfert_dat$cultivar &lt;- factor(rep(c(\"seco\",\"humedo\"), each=10))\nfert_dat$fertilizante &lt;- factor(fert_dat$fertilizante) \n\nhead(fert_dat)\n\n\n  fertilizante rendimiento_peso cultivar\n1            1           2.8215     seco\n2            2           2.3590     seco\n3            3           3.0912     seco\n4            4           2.5297     seco\n5            5           3.4753     seco\n6            6           3.6493     seco\n\n\n\n\ngráfica de masa seca contra fertilizante mineral - sin diferenciar tratamientos\nVeamos los datos en una gráfica simple. La función plot hace cosas distintas según el tipo de datos que le demos. Para generar la gráfica simple que queremos aquí, conviene que los valores de fertilizante sean interpretados como valores numéricos. Esto lo logramos con la funnción as.numeric\n\n\nCódigo\nplot(as.numeric(fert_dat$fertilizante), fert_dat$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"p\")\n\n\n\n\n\nPara explorar mejor los datos podemos marcar en la gráfica las obsevaciones que pertenecen a cada condición. En este caso, te propongo poner el nombre que le dimos al “tratamiento”.\nGráfica de masa seca contra fertilizante mineral diferenciando por genotipos\n\n\nCódigo\nplot(as.numeric(fert_dat$fertilizante), \n     fert_dat$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"n\")\ntext (fert_dat$fertilizante, fert_dat$rendimiento_peso, labels=fert_dat$cultivar)\n\n\n\n\n\nPodemos ver las características estadísticas de lo que pasa con la biomasa que produce cada genotipo\n\n\nResumen de los datos de masa por genotipo\n\n\nCódigo\nby (fert_dat, fert_dat$cultivar, summary)\n\n\nfert_dat$cultivar: humedo\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 4.405   humedo:10  \n 2      :1     1st Qu.: 5.617   seco  : 0  \n 3      :1     Median : 8.592              \n 4      :1     Mean   : 8.716              \n 5      :1     3rd Qu.:10.977              \n 6      :1     Max.   :14.502              \n (Other):4                                 \n------------------------------------------------------------ \nfert_dat$cultivar: seco\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 2.359   humedo: 0  \n 2      :1     1st Qu.: 2.889   seco  :10  \n 3      :1     Median : 3.562              \n 4      :1     Mean   : 4.866              \n 5      :1     3rd Qu.: 6.355              \n 6      :1     Max.   :10.130              \n (Other):4                                 \n\n\nAhora podemos realizar el análisis estadístico mediante modelos. Hagamos un análisis con el enfoque “tradicional” en R. Lo primero que haremos es configurar el entorno de análisis, esto significa elegir el tipo de contrastes que queremos operar al ajustar modelos reparametrizados. Haremos esto con opción contrasts en la función options(contrasts=...)\nPara asegurarnos de que los estimadores del modelo toman el primer nivel como referencia hay que usar el modo de reparametrización “treatment”. Hay otras formas de reparametrización, como podrás ver en la ayuda de contr.treatment.\n\n\nCódigo\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\najusta modelo nulo - sólo la media\n\n\nCódigo\naj1 &lt;- lm (rendimiento_peso ~ 1, data = fert_dat)\nsummary(aj1)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ 1, data = fert_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.432 -3.185 -1.006  2.555  7.711 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6.7912     0.8067   8.419 7.79e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.608 on 19 degrees of freedom\n\n\n\n\nCódigo\n# Agregamos el efecto del fertilizante\naj2 &lt;- update(aj1, .~ . + fertilizante)\nanova(aj2)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df Sum Sq Mean Sq F value Pr(&gt;F)\nfertilizante  9 142.75  15.861  1.5174 0.2622\nResiduals    10 104.53  10.453               \n\n\nNótese que el número de niveles de fertilizante es 10, así que los grados de libertad son 10-1=9. De modo semejante el número de observaciones es 20, así que los grados de libertad del residuo descuenta los grados de libertad del fertilizante y 1 (por la estimación de la media general): 20 - 9 - 1 = 10\n\n\nCódigo\n# agregamos el cultivar\naj3 &lt;- update(aj2,  .~ . + cultivar)\nanova(aj3)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df  Sum Sq Mean Sq F value   Pr(&gt;F)   \nfertilizante  9 142.747  15.861  4.6953 0.015392 * \ncultivar      1  74.125  74.125 21.9434 0.001145 **\nResiduals     9  30.402   3.378                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPodemos intentar hacer un modelo completo, es decir con todos los posibles factores y combinaciones que pueden producirse. Sin embargo este modelo consume todos los grados de liberta (observacione) con que contamos pues cada tratamiento fue ensayado una sola vez en este experimento. De todos modos lo podemos intentar para ver que nos dice R.\n\n\nCódigo\n# agregamos una pendiente diferente para cada genotipo\naj4 &lt;- update(aj3,  .~ . + cultivar:fertilizante)\nanova(aj4)\n\n\nWarning in anova.lm(aj4): ANOVA F-tests on an essentially perfect fit are\nunreliable\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n                      Df  Sum Sq Mean Sq F value Pr(&gt;F)\nfertilizante           9 142.747  15.861     NaN    NaN\ncultivar               1  74.125  74.125     NaN    NaN\nfertilizante:cultivar  9  30.402   3.378     NaN    NaN\nResiduals              0   0.000     NaN               \n\n\nLa scuencia de ajustes produce estos cambios en devianza\n\n\nCódigo\nanova(aj1, aj2, aj3)\n\n\nAnalysis of Variance Table\n\nModel 1: rendimiento_peso ~ 1\nModel 2: rendimiento_peso ~ fertilizante\nModel 3: rendimiento_peso ~ fertilizante + cultivar\n  Res.Df     RSS Df Sum of Sq       F   Pr(&gt;F)   \n1     19 247.274                                 \n2     10 104.527  9   142.747  4.6953 0.015392 * \n3      9  30.402  1    74.125 21.9434 0.001145 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nModelo mínimo adecuado\nestos resultados sugieren que el modelo 3 es mínimo adecuado resumen del modelo mínimo adecuado\n\n\nCódigo\nsummary(aj3)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ fertilizante + cultivar, data = fert_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6653 -0.7855  0.0000  0.7855  2.6653 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)      5.9538     1.3630   4.368  0.00180 **\nfertilizante2   -0.1251     1.8379  -0.068  0.94720   \nfertilizante3    0.5784     1.8379   0.315  0.76014   \nfertilizante4   -0.5615     1.8379  -0.305  0.76695   \nfertilizante5    3.1205     1.8379   1.698  0.12376   \nfertilizante6    2.3382     1.8379   1.272  0.23518   \nfertilizante7    3.3713     1.8379   1.834  0.09981 . \nfertilizante8    5.7776     1.8379   3.144  0.01186 * \nfertilizante9    5.8829     1.8379   3.201  0.01082 * \nfertilizante10   7.2434     1.8379   3.941  0.00340 **\ncultivarseco    -3.8503     0.8219  -4.684  0.00115 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.838 on 9 degrees of freedom\nMultiple R-squared:  0.8771,    Adjusted R-squared:  0.7404 \nF-statistic:  6.42 on 10 and 9 DF,  p-value: 0.004992\n\n\nComo un ejercicio haz el cálculo de los valores de y, a parir de los valores estimados por el modelo. Lo puedes hacer a mano, con ayuda de una calculadora del super, en Excel o equivalente, o quizás con ayuda de R mismo. En este último caso te doy como pista la función coef, con la que tendrás acceso a los coeficientes del modelo.\n¿Podrías escribir un programa/función en R para calcular los valores esperados?\nPara comprender con exactitud que es lo que hace exactamente R al ajustar un modelo de regresión o ANDEVA, como este podemos usar la función model.matrix() aplicada al modelo que nos interese analizar. En este caso lo ejemplificaré con el modelo mínimo adecuado aj3. Así podemos ver en acción el uso de las formas de reparametrización\n\n\nCódigo\nmodel.matrix(aj3)\n\n\n   (Intercept) fertilizante2 fertilizante3 fertilizante4 fertilizante5\n1            1             0             0             0             0\n2            1             1             0             0             0\n3            1             0             1             0             0\n4            1             0             0             1             0\n5            1             0             0             0             1\n6            1             0             0             0             0\n7            1             0             0             0             0\n8            1             0             0             0             0\n9            1             0             0             0             0\n10           1             0             0             0             0\n11           1             0             0             0             0\n12           1             1             0             0             0\n13           1             0             1             0             0\n14           1             0             0             1             0\n15           1             0             0             0             1\n16           1             0             0             0             0\n17           1             0             0             0             0\n18           1             0             0             0             0\n19           1             0             0             0             0\n20           1             0             0             0             0\n   fertilizante6 fertilizante7 fertilizante8 fertilizante9 fertilizante10\n1              0             0             0             0              0\n2              0             0             0             0              0\n3              0             0             0             0              0\n4              0             0             0             0              0\n5              0             0             0             0              0\n6              1             0             0             0              0\n7              0             1             0             0              0\n8              0             0             1             0              0\n9              0             0             0             1              0\n10             0             0             0             0              1\n11             0             0             0             0              0\n12             0             0             0             0              0\n13             0             0             0             0              0\n14             0             0             0             0              0\n15             0             0             0             0              0\n16             1             0             0             0              0\n17             0             1             0             0              0\n18             0             0             1             0              0\n19             0             0             0             1              0\n20             0             0             0             0              1\n   cultivarseco\n1             1\n2             1\n3             1\n4             1\n5             1\n6             1\n7             1\n8             1\n9             1\n10            1\n11            0\n12            0\n13            0\n14            0\n15            0\n16            0\n17            0\n18            0\n19            0\n20            0\nattr(,\"assign\")\n [1] 0 1 1 1 1 1 1 1 1 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$fertilizante\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$cultivar\n[1] \"contr.treatment\"\n\n\n\n\nIntervalos de confianza\nComo hemos visto. La valoración del modelos mínimo adecuado es una declaración de una posible hipótesis alternativa, la más cercana a la muestra que, en esta ocasión obtuvimos. Sin embargo, no hay garantía de ningún tipo de que en otra oportunidad los estimadores serán los mismos. Esto es un recordatorio de que la famosa p nos es en lo que debemos centrar nuestras esperanzas. El asunto es la reflexión sobre las hipótesis alternativas, es decir, las que realmente interesan al investigador y ojalá haga los más explícitas posibles. Una manera de ver el ámbito de estados alternativos del sistema la tenemos cuando visualizamos los intervalos de confianza que nuestro modelo mínimo adecuado produce. En el sitio RPub pueden encontrar ayuda para utilizar R en el análisis de sus datos, aquí encontraran un texto sobre intervalos de confianza. No deja de ser un ejercicio exploratorio y algo subjetivo, pero también potencialmente productivo para acercarnos a comprender mejor el comportamiento del sistema de nuestro interés.\nUn primer conjunto de intervalos de confianza son los asociados con los parámetros del modelo, es decir, la gama de valores de los coeficientes de regresión que podríamos esperar tener en el ajuste del modelo. A continuación les muestro como podemos obtener, con la función confint estos intervalos en R.\n¿Como interpretas estos valores\n\n\nCódigo\nconfint(aj3, level = 0.95)\n\n\n                    2.5 %    97.5 %\n(Intercept)     2.8703275  9.037193\nfertilizante2  -4.2828496  4.032550\nfertilizante3  -3.5792496  4.736150\nfertilizante4  -4.7191496  3.596250\nfertilizante5  -1.0371496  7.278250\nfertilizante6  -1.8194496  6.495950\nfertilizante7  -0.7863496  7.529050\nfertilizante8   1.6199004  9.935300\nfertilizante9   1.7252004 10.040600\nfertilizante10  3.0857004 11.401100\ncultivarseco   -5.7096998 -1.990940\n\n\nOtro intervalo de confianza de interés es el que podemos asociar con lo que puede predecir el modelo. En R este intervalo de confianza lo podemos obtener así:\n\n\nCódigo\npredict(aj3, interval = \"confidence\", level = 0.95)\n\n\n        fit        lwr       upr\n1   2.10344 -0.9799925  5.186873\n2   1.97829 -1.1051425  5.061723\n3   2.68189 -0.4015425  5.765323\n4   1.54199 -1.5414425  4.625423\n5   5.22399  2.1405575  8.307423\n6   4.44169  1.3582575  7.525123\n7   5.47479  2.3913575  8.558223\n8   7.88104  4.7976075 10.964473\n9   7.98634  4.9029075 11.069773\n10  9.34684  6.2634075 12.430273\n11  5.95376  2.8703275  9.037193\n12  5.82861  2.7451775  8.912043\n13  6.53221  3.4487775  9.615643\n14  5.39231  2.3088775  8.475743\n15  9.07431  5.9908775 12.157743\n16  8.29201  5.2085775 11.375443\n17  9.32511  6.2416775 12.408543\n18 11.73136  8.6479275 14.814793\n19 11.83666  8.7532275 14.920093\n20 13.19716 10.1137275 16.280593\n\n\n¿Qué muestran estos valores?\n¿Qé se te ocurre para utilizar en tu reporte de resultados este tipo de intervalos de confianza?\n\n\ncrítica al modelo y recursos diagnósticos\n\n\nCódigo\nplot(aj3)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#lectura-ded-datos",
    "href": "posts/05-dis-comp-aleat/index.html#lectura-ded-datos",
    "title": "Experimentos completamente aleatorizados",
    "section": "Lectura ded datos",
    "text": "Lectura ded datos\n\n\nCódigo\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nurl_prot &lt;- \"https://drive.google.com/file/d/1b-1binYTUJotvPWX9sCnImwxPctumezn/view?usp=sharing\"\ndat_alcal_id &lt;- str_extract(url_prot, \"(?&lt;=d/)(.*)(?=/view)\")\nalcal_dat &lt;- read.csv(sprintf(url_drive, dat_alcal_id)) \n\n\n#alcal_dat &lt;- read_excel(\"alcal_dat.xlsx\",\n#    col_types = c(\"numeric\", \"numeric\", \"numeric\"),\n#    col_names = TRUE)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#definición-de-los-factores",
    "href": "posts/05-dis-comp-aleat/index.html#definición-de-los-factores",
    "title": "Experimentos completamente aleatorizados",
    "section": "Definición de los factores",
    "text": "Definición de los factores\nLos datos contienen información cualitativa, así que necesitamos definir esas piezas de información como factores. Aprovecharemos para experimentar con los factores de tipo “ordenado”. Esta variante de factor aprovecha el contenido seminumérico que pudiéramos tener en alguna variable. En este caso lo haremos así para el contenido de proteína.\n\n\nCódigo\n# Uso la función \"ordered\" que genera factores ordenados, \n# útil para aprovechar datos \"semicuantitativos\" y probar polinomios\n\n# Enfoque antiguo con data.frame\n#alcal_dat$proteina &lt;- ordered(alcal_dat$proteina, c(1,2,3), \n#                           c(\"bajo\", \"medio\", \"alto\"))\n#\n#alcal_dat$alcaloide &lt;-factor(alcal_dat$alcaloide, c(1,2), c(\"ausente\", \"presente\"))\n#\n\n# Enfoque actual con tibble\nalcal_dat &lt;- alcal_dat %&gt;% mutate(proteina = ordered(proteina, c(1,2,3), \n                                     c(\"bajo\", \"medio\", \"alto\")),\n                  alcaloide = factor(alcaloide, c(1,2), \n                                      c(\"ausente\", \"presente\")))"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#exploración-de-medias",
    "href": "posts/05-dis-comp-aleat/index.html#exploración-de-medias",
    "title": "Experimentos completamente aleatorizados",
    "section": "exploración de medias",
    "text": "exploración de medias\nSiempre es conveniente hacer una revisión previa de los datos y considerar los patrones que apreciamos en ellos como fuente de ideas o simplemente para verificar que no haya errores de algún tipo.\n\n\nCódigo\n#\n# Enfoque antiguo con data.frame\n# Para simplificar el acceso a los datos uso la función attach\n#attach(alcal_dat)\n#aggregate(list(talla=talla), list(proteina=proteina), mean)\n#aggregate(list(talla=talla), list(alcaloide=alcaloide),mean)\n#tapply(talla, list(proteina, alcaloide), mean)\n\n# Con un tibble es más práctico hacer esto\nalcal_dat %&gt;% group_by(proteina) %&gt;%\n           summarize(promedio = mean(talla, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  proteina promedio\n  &lt;ord&gt;       &lt;dbl&gt;\n1 bajo         5.5 \n2 medio        5.25\n3 alto         4.25\n\n\nCódigo\nalcal_dat %&gt;% group_by(alcaloide) %&gt;%\n           summarize(promedio = mean(talla, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  alcaloide promedio\n  &lt;fct&gt;        &lt;dbl&gt;\n1 ausente        4.5\n2 presente       5.5\n\n\nCódigo\n# Genero una table resumen de promedios. \n# alcal_dat.res&lt;-aggregate(list(talla=alcal_dat$talla), \n#                      list(proteina=alcal_dat$proteina,\n#                           alcaloide=alcal_dat$alcaloide), mean)\n\nalcal_dat %&gt;% group_by(proteina, alcaloide) %&gt;%\n           summarize(promedio = mean(talla, na.rm=TRUE)) %&gt;%\n           pivot_wider(names_from = proteina, values_from = promedio)\n\n\n`summarise()` has grouped output by 'proteina'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n  alcaloide  bajo medio  alto\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ausente     4.5   3.5   5.5\n2 presente    6.5   7     3"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#exploración-de-varianzas",
    "href": "posts/05-dis-comp-aleat/index.html#exploración-de-varianzas",
    "title": "Experimentos completamente aleatorizados",
    "section": "Exploración de varianzas",
    "text": "Exploración de varianzas\n\n\nCódigo\n#aggregate(list(talla=alcal_dat$talla),\n#          list(proteina=alcal_dat$proteina),var) \nalcal_dat %&gt;% group_by(proteina) %&gt;%\n           summarize(var = var(talla, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  proteina   var\n  &lt;ord&gt;    &lt;dbl&gt;\n1 bajo      2.57\n2 medio     4.5 \n3 alto      3.36\n\n\nCódigo\n#aggregate(list(talla=alcal_dat$talla), \n#          list(alcaloide=alcal_dat$alcaloide), var) \nalcal_dat %&gt;% group_by(alcaloide) %&gt;%\n           summarize(var = var(talla, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  alcaloide   var\n  &lt;fct&gt;     &lt;dbl&gt;\n1 ausente    2.09\n2 presente   4.64\n\n\nCódigo\n# tapply(alcal_dat$talla, list(alcal_dat$proteina, alcal_dat$alcaloide), var)\nalcal_dat %&gt;% group_by(proteina, alcaloide) %&gt;%\n           summarize(var = var(talla, na.rm=TRUE)) %&gt;%\n           pivot_wider(names_from = proteina, values_from = var)\n\n\n`summarise()` has grouped output by 'proteina'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n  alcaloide  bajo medio  alto\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ausente    1.67 1.67   1.67\n2 presente   1.67 0.667  2"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#gráficas-exploratorias",
    "href": "posts/05-dis-comp-aleat/index.html#gráficas-exploratorias",
    "title": "Experimentos completamente aleatorizados",
    "section": "Gráficas exploratorias",
    "text": "Gráficas exploratorias\n\n\nCódigo\ninteraction.plot(alcal_dat$proteina, alcal_dat$alcaloide, alcal_dat$talla) \n\n\n\n\n\nCódigo\n#args(interaction.plot)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#ajuste-de-modelos",
    "href": "posts/05-dis-comp-aleat/index.html#ajuste-de-modelos",
    "title": "Experimentos completamente aleatorizados",
    "section": "Ajuste de modelos",
    "text": "Ajuste de modelos\n\n\nCódigo\nlarvas.nulo &lt;- lm(talla ~ 1, data=alcal_dat)\n\n# defino una simple función que extrae devianza y df de un ajuste y lo despliga\n\n# mediante la función \"cat\"\n\ndevianza &lt;- function(x) \n  { cat(\"devianza=\", deviance(x), \"\\ndf=\",x$df.residual,\"\\n\")}\n\n# devianza del modelo nulo\n\ndevianza(larvas.nulo)\n\n\ndevianza= 80 \ndf= 23 \n\n\nCódigo\n# modelo completo\n\nlarvas.completo &lt;- update(larvas.nulo, . ~ . + proteina + alcaloide + proteina:alcaloide) \n\ndevianza(larvas.completo) \n\n\ndevianza= 28 \ndf= 18 \n\n\nCódigo\ncoefficients(larvas.completo)\n\n\n                 (Intercept)                   proteina.L \n                   4.5000000                    0.7071068 \n                  proteina.Q            alcaloidepresente \n                   1.2247449                    1.0000000 \nproteina.L:alcaloidepresente proteina.Q:alcaloidepresente \n                  -3.1819805                   -3.0618622 \n\n\n\nOtra forma de escribir el modelo completo\n\n\nCódigo\nlarvas.completo &lt;- update(larvas.nulo, . ~ . + proteina * alcaloide) \n\ndevianza(larvas.completo) \n\n\ndevianza= 28 \ndf= 18 \n\n\nCódigo\ncoefficients(larvas.completo)\n\n\n                 (Intercept)                   proteina.L \n                   4.5000000                    0.7071068 \n                  proteina.Q            alcaloidepresente \n                   1.2247449                    1.0000000 \nproteina.L:alcaloidepresente proteina.Q:alcaloidepresente \n                  -3.1819805                   -3.0618622 \n\n\n\n\n¿Significancia de los términos?\n\n\nCódigo\nanova(larvas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: talla\n                   Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nproteina            2      7  3.5000  2.2500 0.1342177    \nalcaloide           1      6  6.0000  3.8571 0.0651695 .  \nproteina:alcaloide  2     39 19.5000 12.5357 0.0003888 ***\nResiduals          18     28  1.5556                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nComparaciones múltiples\nEsto es equivalente a una búsqueda, algo exploratoria, para dar respuesta a la pregunta: ¿Son necesarios todos los niveles de los factores?\n\n\nCódigo\nsummary(larvas.completo)\n\n\n\nCall:\nlm(formula = talla ~ proteina + alcaloide + proteina:alcaloide, \n    data = alcal_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.500 -1.000  0.000  0.625  2.000 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    4.5000     0.3600  12.499 2.61e-10 ***\nproteina.L                     0.7071     0.6236   1.134  0.27172    \nproteina.Q                     1.2247     0.6236   1.964  0.06517 .  \nalcaloidepresente              1.0000     0.5092   1.964  0.06517 .  \nproteina.L:alcaloidepresente  -3.1820     0.8819  -3.608  0.00201 ** \nproteina.Q:alcaloidepresente  -3.0619     0.8819  -3.472  0.00272 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.247 on 18 degrees of freedom\nMultiple R-squared:   0.65, Adjusted R-squared:  0.5528 \nF-statistic: 6.686 on 5 and 18 DF,  p-value: 0.001103\n\n\nCódigo\n# Generación de un factor re-codificado: tomaré: bame = bajo y medio, alto=alto\n\n# Por supuesto hay que considerar que esta fusión tenga sentido biológico.\n\n# Así podemos recodificar el factor proteína.\n\nalcal_dat$proteinaBM &lt;- alcal_dat$proteina \nlevels(alcal_dat$proteinaBM) &lt;- c(\"bame\", \"bame\", \"alto\") # cuidar el orden\n\n\n\nnuevo ajuste de modelo completo con el factor proteina recodificado.\n\n\nCódigo\nlarvas.protBM &lt;- lm(talla ~ proteinaBM * alcaloide, data = alcal_dat) \n\nsummary(larvas.protBM)\n\n\n\nCall:\nlm(formula = talla ~ proteinaBM * alcaloide, data = alcal_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n    -2     -1      0      1      2 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      4.7500     0.3781  12.562 6.03e-11 ***\nproteinaBM.L                     1.0607     0.5347   1.984   0.0612 .  \nalcaloidepresente                0.1250     0.5347   0.234   0.8175    \nproteinaBM.L:alcaloidepresente  -3.7123     0.7562  -4.909 8.47e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.235 on 20 degrees of freedom\nMultiple R-squared:  0.6188,    Adjusted R-squared:  0.5616 \nF-statistic: 10.82 on 3 and 20 DF,  p-value: 0.000194\n\n\n\n\n¿qué significancia tiene este cambio en el modelo?\n\n\nCódigo\nanova(larvas.protBM,larvas.completo) \n\n\nAnalysis of Variance Table\n\nModel 1: talla ~ proteinaBM * alcaloide\nModel 2: talla ~ proteina + alcaloide + proteina:alcaloide\n  Res.Df  RSS Df Sum of Sq      F Pr(&gt;F)\n1     20 30.5                           \n2     18 28.0  2       2.5 0.8036 0.4632\n\n\nCódigo\nplot(larvas.protBM) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ntapply(alcal_dat$talla, list(alcal_dat$proteinaBM, alcal_dat$alcaloide), mean) \n\n\n     ausente presente\nbame     4.0     6.75\nalto     5.5     3.00\n\n\nCódigo\nalcal_dat.resBM &lt;- aggregate(list(talla = alcal_dat$talla), \n                          list(proteinaBM= alcal_dat$proteinaBM, \n                               alcaloide = alcal_dat$alcaloide), mean)\n\ninteraction.plot(alcal_dat$proteinaBM, alcal_dat$alcaloide, alcal_dat$talla)"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#conclusiones",
    "href": "posts/05-dis-comp-aleat/index.html#conclusiones",
    "title": "Experimentos completamente aleatorizados",
    "section": "Conclusiones",
    "text": "Conclusiones\nCon base en estos análisis ¿Cual es el modelo mínimo adecuado?. ¿cómo podemos interpretar estos resultados? ¿tienen sentido o relevancia?"
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes",
    "href": "posts/05-dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes",
    "title": "Experimentos completamente aleatorizados",
    "section": "Respuesta de Cultivares a fertilizantes",
    "text": "Respuesta de Cultivares a fertilizantes\nEjemplo tomado de Crawley (1998). Glim for Ecologists. Oxford. UK.\nEs un experimento en el que se midió el crecimiento (masa seca al cosechar = y) de plantas tratadas con 10 concentraciones diferentes de suplemento mineral como fertilizante, f. El experimento fue realizado con dos cultivares diferentes, g. Uno fue clonado de plantas de un ambiente árido y el otro de uno húmedo. Todas las plantas de cada tipo, sin restricciones, fueron asignadas aleatoriamente a los distintos niveles de fertilizante.\n\nLectura de datos\n\n\nCódigo\nlibrary(stringr)\n\nurl_fert &lt;- \"https://drive.google.com/file/d/1_545rzA2TMIB5XPFHhwNzoHl3A8SigMT/view?usp=drive_link\"\ndat_fert_id &lt;- str_extract(url_fert, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nfert_dat &lt;- read.csv(sprintf(url_drive, dat_fert_id), \n                  col.names=c(\"fertilizante\", \"rendimiento_peso\")) \n\nhead(fert_dat)\n\n\n  fertilizante rendimiento_peso\n1            1           2.8215\n2            2           2.3590\n3            3           3.0912\n4            4           2.5297\n5            5           3.4753\n6            6           3.6493\n\n\nA veces hay archivos que contienen datos faltantes o perdidos. Podemos enfrentar eso con la función complete.cases() que revisa linea por linea el archivo y regresa “verdadero” si todas las columnas tienen datos válidos y “falso” si hay huecos. Esta lista de “verdaderos” y “falsos” la podemos usar para elegir que filas del archivo de datos están completas y así podemos eliminarlas del conjunto de datos que vamos a procesar.\nSobre los datos limpios, generamos la variable indicativa del tipo de ambiente del que se tomo la planta que se clonó.\n\n\nCódigo\n# En caso de que haya datos extra, elimino registros leidos como datos erróneos\nfert_dat &lt;- fert_dat[complete.cases(fert_dat), ]\n\n\n\n\nGenera los factores genotipo y fertilizante\n\n\nCódigo\nfert_dat$cultivar &lt;- factor(rep(c(\"seco\",\"humedo\"), each=10))\nfert_dat$fertilizante &lt;- factor(fert_dat$fertilizante) \n\nhead(fert_dat)\n\n\n  fertilizante rendimiento_peso cultivar\n1            1           2.8215     seco\n2            2           2.3590     seco\n3            3           3.0912     seco\n4            4           2.5297     seco\n5            5           3.4753     seco\n6            6           3.6493     seco\n\n\n\n\ngráfica de masa seca contra fertilizante mineral - sin diferenciar tratamientos\nVeamos los datos en una gráfica simple. La función plot hace cosas distintas según el tipo de datos que le demos. Para generar la gráfica simple que queremos aquí, conviene que los valores de fertilizante sean interpretados como valores numéricos. Esto lo logramos con la funnción as.numeric\n\n\nCódigo\nplot(as.numeric(fert_dat$fertilizante), fert_dat$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"p\")\n\n\n\n\n\nPara explorar mejor los datos podemos marcar en la gráfica las obsevaciones que pertenecen a cada condición. En este caso, te propongo poner el nombre que le dimos al “tratamiento”.\nGráfica de masa seca contra fertilizante mineral diferenciando por genotipos\n\n\nCódigo\nplot(as.numeric(fert_dat$fertilizante), \n     fert_dat$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"n\")\ntext (fert_dat$fertilizante, fert_dat$rendimiento_peso, labels=fert_dat$cultivar)\n\n\n\n\n\nPodemos ver las características estadísticas de lo que pasa con la biomasa que produce cada genotipo\n\n\nResumen de los datos de masa por genotipo\n\n\nCódigo\nby (fert_dat, fert_dat$cultivar, summary)\n\n\nfert_dat$cultivar: humedo\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 4.405   humedo:10  \n 2      :1     1st Qu.: 5.617   seco  : 0  \n 3      :1     Median : 8.592              \n 4      :1     Mean   : 8.716              \n 5      :1     3rd Qu.:10.977              \n 6      :1     Max.   :14.502              \n (Other):4                                 \n------------------------------------------------------------ \nfert_dat$cultivar: seco\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 2.359   humedo: 0  \n 2      :1     1st Qu.: 2.889   seco  :10  \n 3      :1     Median : 3.562              \n 4      :1     Mean   : 4.866              \n 5      :1     3rd Qu.: 6.355              \n 6      :1     Max.   :10.130              \n (Other):4                                 \n\n\nAhora podemos realizar el análisis estadístico mediante modelos. Hagamos un análisis con el enfoque “tradicional” en R. Lo primero que haremos es configurar el entorno de análisis, esto significa elegir el tipo de contrastes que queremos operar al ajustar modelos reparametrizados. Haremos esto con opción contrasts en la función options(contrasts=...)\nPara asegurarnos de que los estimadores del modelo toman el primer nivel como referencia hay que usar el modo de reparametrización “treatment”. Hay otras formas de reparametrización, como podrás ver en la ayuda de contr.treatment.\n\n\nCódigo\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\najusta modelo nulo - sólo la media\n\n\nCódigo\naj1 &lt;- lm (rendimiento_peso ~ 1, data = fert_dat)\nsummary(aj1)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ 1, data = fert_dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.432 -3.185 -1.006  2.555  7.711 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6.7912     0.8067   8.419 7.79e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.608 on 19 degrees of freedom\n\n\n\n\nCódigo\n# Agregamos el efecto del fertilizante\naj2 &lt;- update(aj1, .~ . + fertilizante)\nanova(aj2)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df Sum Sq Mean Sq F value Pr(&gt;F)\nfertilizante  9 142.75  15.861  1.5174 0.2622\nResiduals    10 104.53  10.453               \n\n\nNótese que el número de niveles de fertilizante es 10, así que los grados de libertad son 10-1=9. De modo semejante el número de observaciones es 20, así que los grados de libertad del residuo descuenta los grados de libertad del fertilizante y 1 (por la estimación de la media general): 20 - 9 - 1 = 10\n\n\nCódigo\n# agregamos el cultivar\naj3 &lt;- update(aj2,  .~ . + cultivar)\nanova(aj3)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df  Sum Sq Mean Sq F value   Pr(&gt;F)   \nfertilizante  9 142.747  15.861  4.6953 0.015392 * \ncultivar      1  74.125  74.125 21.9434 0.001145 **\nResiduals     9  30.402   3.378                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPodemos intentar hacer un modelo completo, es decir con todos los posibles factores y combinaciones que pueden producirse. Sin embargo este modelo consume todos los grados de liberta (observaciones) con que contamos pues cada tratamiento fue ensayado una sola vez en este experimento. De todos modos lo podemos intentar para ver que nos dice R.\n\n\nCódigo\n# agregamos una pendiente diferente para cada genotipo\naj4 &lt;- update(aj3,  .~ . + cultivar:fertilizante)\nanova(aj4)\n\n\nWarning in anova.lm(aj4): ANOVA F-tests on an essentially perfect fit are\nunreliable\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n                      Df  Sum Sq Mean Sq F value Pr(&gt;F)\nfertilizante           9 142.747  15.861     NaN    NaN\ncultivar               1  74.125  74.125     NaN    NaN\nfertilizante:cultivar  9  30.402   3.378     NaN    NaN\nResiduals              0   0.000     NaN               \n\n\nLa secuencia de ajustes produce estos cambios en devianza\n\n\nCódigo\nanova(aj1, aj2, aj3)\n\n\nAnalysis of Variance Table\n\nModel 1: rendimiento_peso ~ 1\nModel 2: rendimiento_peso ~ fertilizante\nModel 3: rendimiento_peso ~ fertilizante + cultivar\n  Res.Df     RSS Df Sum of Sq       F   Pr(&gt;F)   \n1     19 247.274                                 \n2     10 104.527  9   142.747  4.6953 0.015392 * \n3      9  30.402  1    74.125 21.9434 0.001145 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nModelo mínimo adecuado\nestos resultados sugieren que el modelo 3 es mínimo adecuado resumen del modelo mínimo adecuado\n\n\nCódigo\nsummary(aj3)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ fertilizante + cultivar, data = fert_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6653 -0.7855  0.0000  0.7855  2.6653 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)      5.9538     1.3630   4.368  0.00180 **\nfertilizante2   -0.1251     1.8379  -0.068  0.94720   \nfertilizante3    0.5784     1.8379   0.315  0.76014   \nfertilizante4   -0.5615     1.8379  -0.305  0.76695   \nfertilizante5    3.1205     1.8379   1.698  0.12376   \nfertilizante6    2.3382     1.8379   1.272  0.23518   \nfertilizante7    3.3713     1.8379   1.834  0.09981 . \nfertilizante8    5.7776     1.8379   3.144  0.01186 * \nfertilizante9    5.8829     1.8379   3.201  0.01082 * \nfertilizante10   7.2434     1.8379   3.941  0.00340 **\ncultivarseco    -3.8503     0.8219  -4.684  0.00115 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.838 on 9 degrees of freedom\nMultiple R-squared:  0.8771,    Adjusted R-squared:  0.7404 \nF-statistic:  6.42 on 10 and 9 DF,  p-value: 0.004992\n\n\nComo un ejercicio haz el cálculo de los valores de y, a parir de los valores estimados por el modelo. Lo puedes hacer a mano, con ayuda de una calculadora del super, en Excel o equivalente, o quizás con ayuda de R mismo. En este último caso te doy como pista la función coef, con la que tendrás acceso a los coeficientes del modelo.\n¿Podrías escribir un programa/función en R para calcular los valores esperados?\nPara comprender con exactitud que es lo que hace exactamente R al ajustar un modelo de regresión o ANDEVA como este, podemos usar la función model.matrix() aplicada al modelo que nos interese analizar. En este caso lo ejemplificaré con el modelo mínimo adecuado aj3. Así podemos ver en acción el uso de las formas de reparametrización\n\n\nCódigo\nmodel.matrix(aj3)\n\n\n   (Intercept) fertilizante2 fertilizante3 fertilizante4 fertilizante5\n1            1             0             0             0             0\n2            1             1             0             0             0\n3            1             0             1             0             0\n4            1             0             0             1             0\n5            1             0             0             0             1\n6            1             0             0             0             0\n7            1             0             0             0             0\n8            1             0             0             0             0\n9            1             0             0             0             0\n10           1             0             0             0             0\n11           1             0             0             0             0\n12           1             1             0             0             0\n13           1             0             1             0             0\n14           1             0             0             1             0\n15           1             0             0             0             1\n16           1             0             0             0             0\n17           1             0             0             0             0\n18           1             0             0             0             0\n19           1             0             0             0             0\n20           1             0             0             0             0\n   fertilizante6 fertilizante7 fertilizante8 fertilizante9 fertilizante10\n1              0             0             0             0              0\n2              0             0             0             0              0\n3              0             0             0             0              0\n4              0             0             0             0              0\n5              0             0             0             0              0\n6              1             0             0             0              0\n7              0             1             0             0              0\n8              0             0             1             0              0\n9              0             0             0             1              0\n10             0             0             0             0              1\n11             0             0             0             0              0\n12             0             0             0             0              0\n13             0             0             0             0              0\n14             0             0             0             0              0\n15             0             0             0             0              0\n16             1             0             0             0              0\n17             0             1             0             0              0\n18             0             0             1             0              0\n19             0             0             0             1              0\n20             0             0             0             0              1\n   cultivarseco\n1             1\n2             1\n3             1\n4             1\n5             1\n6             1\n7             1\n8             1\n9             1\n10            1\n11            0\n12            0\n13            0\n14            0\n15            0\n16            0\n17            0\n18            0\n19            0\n20            0\nattr(,\"assign\")\n [1] 0 1 1 1 1 1 1 1 1 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$fertilizante\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$cultivar\n[1] \"contr.treatment\"\n\n\n\n\nIntervalos de confianza\nComo hemos visto. La valoración del modelos mínimo adecuado es una declaración de una posible hipótesis alternativa, la más cercana a la muestra que, en esta ocasión obtuvimos. Sin embargo, no hay garantía de ningún tipo de que en otra oportunidad los estimadores serán los mismos. Esto es un recordatorio de que la famosa p nos es en lo que debemos centrar nuestras esperanzas. El asunto es la reflexión sobre las hipótesis alternativas, es decir, las que realmente interesan al investigador y ojalá haga los más explícitas posibles. Una manera de ver el ámbito de estados alternativos del sistema la tenemos cuando visualizamos los intervalos de confianza que nuestro modelo mínimo adecuado produce. En el sitio RPub pueden encontrar ayuda para utilizar R en el análisis de sus datos, aquí encontraran un texto sobre intervalos de confianza. No deja de ser un ejercicio exploratorio y algo subjetivo, pero también potencialmente productivo para acercarnos a comprender mejor el comportamiento del sistema de nuestro interés.\nUn primer conjunto de intervalos de confianza son los asociados con los parámetros del modelo, es decir, la gama de valores de los coeficientes de regresión que podríamos esperar tener en el ajuste del modelo. A continuación les muestro como podemos obtener, con la función confint estos intervalos en R.\n¿Como interpretas estos valores\n\n\nCódigo\nconfint(aj3, level = 0.95)\n\n\n                    2.5 %    97.5 %\n(Intercept)     2.8703275  9.037193\nfertilizante2  -4.2828496  4.032550\nfertilizante3  -3.5792496  4.736150\nfertilizante4  -4.7191496  3.596250\nfertilizante5  -1.0371496  7.278250\nfertilizante6  -1.8194496  6.495950\nfertilizante7  -0.7863496  7.529050\nfertilizante8   1.6199004  9.935300\nfertilizante9   1.7252004 10.040600\nfertilizante10  3.0857004 11.401100\ncultivarseco   -5.7096998 -1.990940\n\n\nOtro intervalo de confianza de interés es el que podemos asociar con lo que puede predecir el modelo. En R este intervalo de confianza lo podemos obtener así:\n\n\nCódigo\npredict(aj3, interval = \"confidence\", level = 0.95)\n\n\n        fit        lwr       upr\n1   2.10344 -0.9799925  5.186873\n2   1.97829 -1.1051425  5.061723\n3   2.68189 -0.4015425  5.765323\n4   1.54199 -1.5414425  4.625423\n5   5.22399  2.1405575  8.307423\n6   4.44169  1.3582575  7.525123\n7   5.47479  2.3913575  8.558223\n8   7.88104  4.7976075 10.964473\n9   7.98634  4.9029075 11.069773\n10  9.34684  6.2634075 12.430273\n11  5.95376  2.8703275  9.037193\n12  5.82861  2.7451775  8.912043\n13  6.53221  3.4487775  9.615643\n14  5.39231  2.3088775  8.475743\n15  9.07431  5.9908775 12.157743\n16  8.29201  5.2085775 11.375443\n17  9.32511  6.2416775 12.408543\n18 11.73136  8.6479275 14.814793\n19 11.83666  8.7532275 14.920093\n20 13.19716 10.1137275 16.280593\n\n\n¿Qué muestran estos valores?\n¿Qé se te ocurre para utilizar en tu reporte de resultados este tipo de intervalos de confianza?\n\n\ncrítica al modelo y recursos diagnósticos\n\n\nCódigo\nplot(aj3)"
  },
  {
    "objectID": "posts/06-Restringir-aleatorizacion/index.html#manos",
    "href": "posts/06-Restringir-aleatorizacion/index.html#manos",
    "title": "Restricciones a la aleatorización",
    "section": "Manos",
    "text": "Manos\nConsidera que estamos midiendo la mano izquierda y la derecha de varios individuos, las medidas están emparejadas dentro de cada individuo. Es decir, queremos controlar estadísticamente las diferencias entre individuos, así nos aseguramos que la mano izquierda del individuo A sea analizada en conjunto con la mano derecha del individuo A, ya que suponemos que alguien con una mano izquierda grande tendrá una mano derecha grande. Por lo tanto, la variable Individuo se incluirá en el modelo como una variable aleatoria. Se podría pensar que cada Individuo representa un bloque que incluye una medida para la mano izquierda y una medida para la mano derecha.\n\n\nCódigo\nlibrary(stringr)\nurl_manos &lt;- \"https://drive.google.com/file/d/1GSQMbbX7szydnIMDkWYDBlFBWqTdkC4k/view?usp=drive_link\"\ndat_manos_id &lt;- str_extract(url_manos, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nmanos &lt;- read.csv(sprintf(url_drive, dat_manos_id)) \n\n\n#manos &lt;- read.table(\"manos.dat\", sep = \",\", header = T, stringsAsFactors = T)\nhead(manos)\n\n\n  Individual Hand Length\n1          A Left   17.5\n2          B Left   18.4\n3          C Left   16.2\n4          D Left   14.5\n5          E Left   13.5\n6          F Left   18.9\n\n\n\nInspección de los datos\n\n\nCódigo\ntapply(manos$Length, list(manos$Hand, manos$Individual), mean)\n\n\n         A    B    C    D    E    F    G    H    I    J    K    L    M    N\nLeft  17.5 18.4 16.2 14.5 13.5 18.9 19.5 21.1 17.8 16.8 18.4 17.3 18.9 16.4\nRight 17.6 18.5 15.9 14.9 13.7 18.9 19.5 21.5 18.5 17.1 18.9 17.5 19.5 16.5\n         O    P\nLeft  17.5 15.0\nRight 17.4 15.6\n\n\n\n\nCódigo\ninteraction.plot(manos$Individual,manos$Hand, manos$Length)\n\n\n\n\n\n\n\nCódigo\nmanos_modelo_1 &lt;- lm(Length ~ 1, data = manos)\nsummary(manos_modelo_1)\n\n\n\nCall:\nlm(formula = Length ~ 1, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.975 -1.125  0.025  1.425  4.025 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.4750     0.3415   51.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.932 on 31 degrees of freedom\n\n\n\n\nCódigo\nmanos_modelo_2 &lt;- lm(Length ~ Hand, data = manos)\nsummary(manos_modelo_2)\n\n\n\nCall:\nlm(formula = Length ~ Hand, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.894 -1.109  0.075  1.306  3.906 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  17.3562     0.4900  35.418   &lt;2e-16 ***\nHandRight     0.2375     0.6930   0.343    0.734    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.96 on 30 degrees of freedom\nMultiple R-squared:  0.003899,  Adjusted R-squared:  -0.0293 \nF-statistic: 0.1174 on 1 and 30 DF,  p-value: 0.7342\n\n\n\n\nCódigo\nmanos_modelo_3 &lt;- lm(Length ~ Hand + Individual, data = manos)\nsummary(manos_modelo_3)\n\n\n\nCall:\nlm(formula = Length ~ Hand + Individual, data = manos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26875 -0.09062  0.00000  0.09062  0.26875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 17.43125    0.14440 120.714  &lt; 2e-16 ***\nHandRight    0.23750    0.07004   3.391 0.004034 ** \nIndividualB  0.90000    0.19812   4.543 0.000389 ***\nIndividualC -1.50000    0.19812  -7.571 1.69e-06 ***\nIndividualD -2.85000    0.19812 -14.386 3.50e-10 ***\nIndividualE -3.95000    0.19812 -19.938 3.30e-12 ***\nIndividualF  1.35000    0.19812   6.814 5.85e-06 ***\nIndividualG  1.95000    0.19812   9.843 6.15e-08 ***\nIndividualH  3.75000    0.19812  18.928 7.00e-12 ***\nIndividualI  0.60000    0.19812   3.029 0.008466 ** \nIndividualJ -0.60000    0.19812  -3.029 0.008466 ** \nIndividualK  1.10000    0.19812   5.552 5.54e-05 ***\nIndividualL -0.15000    0.19812  -0.757 0.460699    \nIndividualM  1.65000    0.19812   8.328 5.23e-07 ***\nIndividualN -1.10000    0.19812  -5.552 5.54e-05 ***\nIndividualO -0.10000    0.19812  -0.505 0.621065    \nIndividualP -2.25000    0.19812 -11.357 9.14e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1981 on 15 degrees of freedom\nMultiple R-squared:  0.9949,    Adjusted R-squared:  0.9895 \nF-statistic: 183.3 on 16 and 15 DF,  p-value: 2.887e-14\n\n\n\n\nCódigo\nanova(manos_modelo_3)\n\n\nAnalysis of Variance Table\n\nResponse: Length\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nHand        1   0.451  0.4513  11.497  0.004034 ** \nIndividual 15 114.680  7.6453 194.786 2.089e-14 ***\nResiduals  15   0.589  0.0392                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEs cierto que el efecto de individuo queda raro en este modelo, pes nos lo reporta en estimadores que tienen sentido como si se tratara de un factor de efectos fijos, es decir que nos interesa decir algo específico sobre esos individuos y ningún otro. Esto obviamente nos es así. El factor individuo es de efectos aleatorios, simplemente que lm` no prevé esta situación. Los resultados apuntan en la dirección correcta y los valores del factor Hand son válidos. Lo podemos manejar razonablemente simplemente recordando que el individuo es de efectos aleatorios y que por tanto no tienen mucho sentido, generalmente, hacer referencia a los estimadores puntuales que produce la regresión. Lo que sí tiene interés es la estimación de las varianzas, que permite así corregir e idealmente lograr mayor precisión en la estimación en los tratamientos de interés. En este caso habría que notar que la varianza estimada en el residuo da cuenta tanto de la variación aleatoria que tenemos al medir las unidades experimentales como la del error de restricción asociado con las peculiaridades de, en este caso, cada persona que se midió: \\(\\sigma^{2} + t \\sigma^{2}_{\\delta}\\) . La medición de esta varianza combinada, persona + sus peculiaridades = 7.6453, sugiere que es buena idea controlar su efecto. En esto mismos términos la varianza del factor hand es \\(\\sigma + t\\sigma\\^{2}_{\\delta} + r\\sigma^{2}_{H}\\), lo qe hace válido probar el efecto fijo de hand.\n\\[\nF = \\frac {Mean Sq Hand} {Mn Sq error} = \\frac {0.4513}{0.0392} = 11.497\n\\] con 1 y 15 grados de libertad. En R tenemos acceso a la distribbución de F con la función qfque calcula la probabilidad acumulada entre el dato q que le doy, así como los grados de libertad asociados.\n\n\nCódigo\nvarianza &lt;- anova(manos_modelo_3)\n\npf(q = varianza$`F value`[1], df1 = 1, df2 = 15, lower.tail = FALSE)\n\n\n[1] 0.004034071\n\n\nAunque la forma como analizamos estos datos no es la ideal para el caso, podemos ver que produce resultados perfectamente adecuados para la variable de interés, siempre y cuando seamos cocientes de que la función usada aquí en R, no maneja apropiadamente los factores de efectos aleatorios y por lo tanto no debemos hacer mayores interpretaciones de los términos correspondientes a esos factores."
  },
  {
    "objectID": "posts/06-Restringir-aleatorizacion/index.html#qué-tanto-tiempo-puede-correr-un-experimento",
    "href": "posts/06-Restringir-aleatorizacion/index.html#qué-tanto-tiempo-puede-correr-un-experimento",
    "title": "Restricciones a la aleatorización",
    "section": "Qué tanto tiempo puede “correr” un experimento",
    "text": "Qué tanto tiempo puede “correr” un experimento\nCuando Fisher concibió hacer experimentos en la estación experimental de Rothamsted en Inglaterra, recurriendo al auxilio del enfoque estadístico que él y otros investigadores de la época idearon, pensaban a largo plazo. Encontré este documento que podría ser de su interés. La estación experimental tiene disponiible los datos de estos experimentos. Por ejemplo Este “dataset” son los rendimientos anuales de trigo de “parcelas selectas” del experimento de trigo que aún hoy corren en Broadbalk . La serie tiene los datos de 1852-1918, tal y como los usó R.A. Fisher para su artículo de 1921 ‘Studies in crop variation’."
  },
  {
    "objectID": "posts/05-dis-comp-aleat/index.html#lectura-de-datos-1",
    "href": "posts/05-dis-comp-aleat/index.html#lectura-de-datos-1",
    "title": "Experimentos completamente aleatorizados",
    "section": "Lectura de datos",
    "text": "Lectura de datos\n\n\nCódigo\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nurl_prot &lt;- \"https://drive.google.com/file/d/1b-1binYTUJotvPWX9sCnImwxPctumezn/view?usp=sharing\"\ndat_alcal_id &lt;- str_extract(url_prot, \"(?&lt;=d/)(.*)(?=/view)\")\nalcal_dat &lt;- read.csv(sprintf(url_drive, dat_alcal_id)) \n\n\n#alcal_dat &lt;- read_excel(\"alcal_dat.xlsx\",\n#    col_types = c(\"numeric\", \"numeric\", \"numeric\"),\n#    col_names = TRUE)"
  },
  {
    "objectID": "ejercicios/pizzas/index.html",
    "href": "ejercicios/pizzas/index.html",
    "title": "Pizzas",
    "section": "",
    "text": "Para encontrar una mejor manera de hacer su pizza favorita, Marcelo se propuso reducir el tiempo que tarda en preparar la masa. Para hacerlo siguió el camino de la ciencia y diseñó un experimento para poner a prueba el efecto de la cantidad de azúcar y de leche en los tiempos de activación de la levadura. En concreto, probó cuatro recetas diferentes y midió cuántos segundos tardaba la misma cantidad de masa en llenar un recipiente hasta una marca que fijo como referencia. Aleatorizó el orden de las recetas y repitió cada tratamiento 4 veces.\nPara este ejercicio utiliza por favor la opción de crear tu reporte como un Quarto Document. Propongo esto como un ejercicio introductorio, pero considera el gran potencial que esto está adquiriendo, pues como puedes ver aquí, podrías escribir tus artículos directamente con Quarto. Pero para empezar, te podría interesar más bien este tutorial introductorio\n\n\n\nDescargar los datos en formato de texto simple o Utiliza este vínculo para otenerlo de Google Drive\nRecuerda que puedes usar estas instrucciones para leer los datos en R.\n\nurl_datos &lt;- \"URL de los datos\"\ndat_datos_id &lt;- str_extract(url_datos, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \ndatos &lt;- read.csv(sprintf(url_drive, dat_datos_id)) \n\n\n\n¿Diseño experimental?\n¿Arreglo de tratamientos?\n¿Modelo que corresponde a este experimento?\n¿Supuestos qe harás para apoyar tu análisis estadístico?\n¿Define tu criterio o nivel de significancia?\nRealiza una exploración de los datos, numérica y gráfica, comenta\nConstruye los modelos necesarios y selecciona el mínimo adecuado\nValora la calidad del modelo, incluyendo el análisis de los residuos\nResuelve que tratamientos difieren de los demás\nArgumenta tus conclusiones"
  },
  {
    "objectID": "ejercicios/pizzas/index.html#preparación-de-la-masa",
    "href": "ejercicios/pizzas/index.html#preparación-de-la-masa",
    "title": "Pizzas",
    "section": "",
    "text": "Para encontrar una mejor manera de hacer su pizza favorita, Marcelo se propuso reducir el tiempo que tarda en preparar la masa. Para hacerlo siguió el camino de la ciencia y diseñó un experimento para poner a prueba el efecto de la cantidad de azúcar y de leche en los tiempos de activación de la levadura. En concreto, probó cuatro recetas diferentes y midió cuántos segundos tardaba la misma cantidad de masa en llenar un recipiente hasta una marca que fijo como referencia. Aleatorizó el orden de las recetas y repitió cada tratamiento 4 veces.\nPara este ejercicio utiliza por favor la opción de crear tu reporte como un Quarto Document. Propongo esto como un ejercicio introductorio, pero considera el gran potencial que esto está adquiriendo, pues como puedes ver aquí, podrías escribir tus artículos directamente con Quarto. Pero para empezar, te podría interesar más bien este tutorial introductorio\n\n\n\nDescargar los datos en formato de texto simple o Utiliza este vínculo para otenerlo de Google Drive\nRecuerda que puedes usar estas instrucciones para leer los datos en R.\n\nurl_datos &lt;- \"URL de los datos\"\ndat_datos_id &lt;- str_extract(url_datos, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \ndatos &lt;- read.csv(sprintf(url_drive, dat_datos_id)) \n\n\n\n¿Diseño experimental?\n¿Arreglo de tratamientos?\n¿Modelo que corresponde a este experimento?\n¿Supuestos qe harás para apoyar tu análisis estadístico?\n¿Define tu criterio o nivel de significancia?\nRealiza una exploración de los datos, numérica y gráfica, comenta\nConstruye los modelos necesarios y selecciona el mínimo adecuado\nValora la calidad del modelo, incluyendo el análisis de los residuos\nResuelve que tratamientos difieren de los demás\nArgumenta tus conclusiones"
  },
  {
    "objectID": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html",
    "href": "presentaciones/03-modelo-lineal/pres-modelo-lineal.html",
    "title": "Modelo Estadístico Lineal",
    "section": "",
    "text": "¿Descriptivo o comparativo?\n¿Cómo se miden las variables (escalas)?\n¿Cómo se definen los tratamientos?\n¿Cómo se asignan los tratamientos a las unidades de observación?\n¿Procesos de confusión?\n¿Se usó aleatorización en algún punto?"
  },
  {
    "objectID": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html",
    "href": "presentaciones/02-leyes-de-la-ciencia/pres-leyes-ciencia.html",
    "title": "Leyes de la Ciencia",
    "section": "",
    "text": "lo que hay que hacer es\n\n\n\n\nEn tu computadora ir vevox.app\nPara usar el celular instala Vevox desde la tienda de apps"
  },
  {
    "objectID": "presentaciones/04-diagramas-causales/Diagramas Causales.html",
    "href": "presentaciones/04-diagramas-causales/Diagramas Causales.html",
    "title": "Introducción a Diagramas Causales",
    "section": "",
    "text": "Pearl, Judea. The Book of Why: The New Science of Cause and Effect (p. 28). Basic Books."
  },
  {
    "objectID": "ejercicios/venenos/index.html#planteamiento",
    "href": "ejercicios/venenos/index.html#planteamiento",
    "title": "Ensayo de antivenenos",
    "section": "Planteamiento",
    "text": "Planteamiento\n\nEl archivo Excel que se adjunta muestra el tiempo de sobrevivencia, en unidades de 10 horas, de animales a los que se administró uno de tres tipos de veneno (I II, III), seguido de uno de cuatro antídotos (A, B, C y D). Se usaron cuatro animales asignados al azar a las combinación de veneno y antídoto ¿Alguno de los antídotos es más eficaz que los otros?\n\n\n¿Diseño experimental?\n¿Arreglo de tratamientos?\n¿Modelo que corresponde a este experimento?\n¿Supuestos qe harás para apoyar tu análisis estadístico?\n¿Define tu criterio o nivel de significancia?\nRealiza una exploración de los datos, numérica y gráfica, comenta\nConstruye los modelos necesarios y selecciona el mínimo adecuado\nValora la calidad del modelo, incluyendo el análisis de los residuos\nResuelve que tratamientos difieren de los demás\nArgumenta tus conclusiones\n\n\nDescargar los datos como un libro Excel"
  },
  {
    "objectID": "posts/07-experimentos-anidados/index.html#ejemplo-control-del-glucógeno-en-hígados-de-rata",
    "href": "posts/07-experimentos-anidados/index.html#ejemplo-control-del-glucógeno-en-hígados-de-rata",
    "title": "Modelos anidados",
    "section": "Ejemplo: Control del glucógeno en hígados de rata",
    "text": "Ejemplo: Control del glucógeno en hígados de rata\nEste ejemplo presentado originalmente en Sokal & Rohlf (1981). Se trata de un experimento con un solo factor con tres dietas: 1 = “control”, 2 = “compuesto 217”, 3 = “compuesto 217 + azúcar”. Fueron administrados a seis ratas, dos por tratamiento. El análisis se complica por el hecho de que, para el análisis, se tomaron tres muestras del hígado de cada rata y se hicieron dos determinaciones de contenido de glucógeno en cada muestra. Así, hay seis parcelas chicas (lo que a algunos les gusta llamar pseudorréplicas) en cada rata, para finalmente dar 36 lecturas en total.\nDatos del experimento\n\n\nCódigo\nglucog_rata &lt;- dagitty('dag {bb=\"-5,-5, 5, 5\"\n                             trat [exposure, pos=\"-4, 0\"]\n                             rat  [pos=\"-2, 0\"]\n                             hig  [pos=\"0, 0\"]\n                             mues [pos=\"2, 0\"]\n                             gluc [outcome, pos=\"4, 0\"]\n                             hig -&gt; mues\n                             mues -&gt; gluc\n                             rat -&gt; hig\n                             trat -&gt; rat}')\n\n\npar(cex = 1, lwd  = 1)\nplot(glucog_rata)\n\n\n\n\n\nArreglé el código para incorporar la versión con la tubo-metáfora. haciendo esto me encontré este artículo quejoso al respecto. Ni modo, comparto algo del punto de vista de ese autor.\n\n\nCódigo\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nratas &lt;- as_tibble(read.table(\"hígados-rata.DAT\",                 \n                    col.names=\"glucogeno\"))\n\nratas &lt;- ratas %&gt;% \n               mutate(tratamiento = factor(rep(1:3,each=12), levels=c(1:3)),\n                      rata = factor(rep(1:2,times=3, each=6), levels=c(1,2)),\n                      muestraH = factor(rep(1:3,times=6, each=2), levels=c(1:3)))\n\nhead(ratas)\n\n\n# A tibble: 6 × 4\n  glucogeno tratamiento rata  muestraH\n      &lt;int&gt; &lt;fct&gt;       &lt;fct&gt; &lt;fct&gt;   \n1       131 1           1     1       \n2       130 1           1     1       \n3       131 1           1     2       \n4       125 1           1     2       \n5       136 1           1     3       \n6       142 1           1     3"
  },
  {
    "objectID": "posts/07-experimentos-anidados/index.html#inspección-de-los-datos",
    "href": "posts/07-experimentos-anidados/index.html#inspección-de-los-datos",
    "title": "Modelos anidados",
    "section": "inspección de los datos",
    "text": "inspección de los datos\n\n\nCódigo\ntapply (ratas$glucogeno, list(ratas$tratamiento), mean)\n\n\n       1        2        3 \n140.5000 151.0000 135.1667 \n\n\nQuizás es mala idea etiquetar a los factores en forma numérica cuando hay la posibilidad de darles un nombre que nos facilite interpretar los resultados, especialmente para los efectos fijos. Cambiemos eso para los tratamientos. Hay varias formas de hacer esto, unas más seguras que otras, pero en este caso el cambio es muy sencillo y lo podemos hacer con suficiente seguridad como lo hemos venido haciendo con la función levels. Pero para atender casos más complejos sugiero usar la biblioteca tidyverse así.\n\n\nCódigo\nratas &lt;- ratas %&gt;% mutate(trat_txt=recode(tratamiento, \n                                          \"1\"=\"trat_1\", \n                                          \"2\"=\"trat_2\", \n                                          \"3\"=\"trat_3\"))\n\nhead(ratas)\n\n\n# A tibble: 6 × 5\n  glucogeno tratamiento rata  muestraH trat_txt\n      &lt;int&gt; &lt;fct&gt;       &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;   \n1       131 1           1     1        trat_1  \n2       130 1           1     1        trat_1  \n3       131 1           1     2        trat_1  \n4       125 1           1     2        trat_1  \n5       136 1           1     3        trat_1  \n6       142 1           1     3        trat_1"
  },
  {
    "objectID": "posts/07-experimentos-anidados/index.html#ajuste-de-modelo",
    "href": "posts/07-experimentos-anidados/index.html#ajuste-de-modelo",
    "title": "Modelos anidados",
    "section": "Ajuste de modelo",
    "text": "Ajuste de modelo\nEn este caso tengo una estructura anidada, así que podemos usar el operador de anidación %in%. Sin embargo, hay que tener cuidado, pues esto sólo añade el efecto de anidamiento especificado, no los términos principales u otros niveles de anidamiento que pudieran estar presentes. También hay que notar que un anidamiento equivale en el modelo estadístico lineal a la presencia de términos de interacción sin su contraparte de términos en la jerarquía. En este caso, no aparece ninguna interacción tratamiento:rata o tratamiento:muestraHígado, etc., pero sí aparecen las interacciones más complejas: rata:muestraHígado:tratamiento por ejemplo.\n\n\nCódigo\nratas.completo &lt;- lm(glucogeno ~ trat_txt + rata %in% trat_txt + muestraH %in% rata %in% trat_txt, data=ratas)\nsummary(ratas.completo)\n\n\n\nCall:\nlm(formula = glucogeno ~ trat_txt + rata %in% trat_txt + muestraH %in% \n    rata %in% trat_txt, data = ratas)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.00  -2.25   0.00   2.25   6.00 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     130.500      3.253  40.114  &lt; 2e-16 ***\ntrat_txttrat_2                   20.500      4.601   4.456 0.000305 ***\ntrat_txttrat_3                   -1.000      4.601  -0.217 0.830375    \ntrat_txttrat_1:rata2             18.500      4.601   4.021 0.000801 ***\ntrat_txttrat_2:rata2              2.000      4.601   0.435 0.668937    \ntrat_txttrat_3:rata2              9.500      4.601   2.065 0.053645 .  \ntrat_txttrat_1:rata1:muestraH2   -2.500      4.601  -0.543 0.593526    \ntrat_txttrat_2:rata1:muestraH2   -3.000      4.601  -0.652 0.522595    \ntrat_txttrat_3:rata1:muestraH2    8.500      4.601   1.848 0.081172 .  \ntrat_txttrat_1:rata2:muestraH2   -7.500      4.601  -1.630 0.120438    \ntrat_txttrat_2:rata2:muestraH2   -6.000      4.601  -1.304 0.208616    \ntrat_txttrat_3:rata2:muestraH2   -0.500      4.601  -0.109 0.914660    \ntrat_txttrat_1:rata1:muestraH3    8.500      4.601   1.848 0.081172 .  \ntrat_txttrat_2:rata1:muestraH3   -1.000      4.601  -0.217 0.830375    \ntrat_txttrat_3:rata1:muestraH3    6.000      4.601   1.304 0.208616    \ntrat_txttrat_1:rata2:muestraH3    6.000      4.601   1.304 0.208616    \ntrat_txttrat_2:rata2:muestraH3    4.000      4.601   0.869 0.396059    \ntrat_txttrat_3:rata2:muestraH3   -8.500      4.601  -1.848 0.081172 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.601 on 18 degrees of freedom\nMultiple R-squared:  0.8856,    Adjusted R-squared:  0.7775 \nF-statistic: 8.196 on 17 and 18 DF,  p-value: 2.508e-05\n\n\n\n\nCódigo\n#tapply (ratas$glucogeno, list(ratas$trat_txt), mean)\nratas %&gt;% group_by(trat_txt) %&gt;% summarise(media = mean(glucogeno))\n\n\n# A tibble: 3 × 2\n  trat_txt media\n  &lt;fct&gt;    &lt;dbl&gt;\n1 trat_1    140.\n2 trat_2    151 \n3 trat_3    135.\n\n\nCódigo\nanova(ratas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                       Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ntrat_txt                2 1557.56  778.78 36.7927 4.375e-07 ***\ntrat_txt:rata           3  797.67  265.89 12.5617 0.0001143 ***\ntrat_txt:rata:muestraH 12  594.00   49.50  2.3386 0.0502907 .  \nResiduals              18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n¿Cómo interpretas estos resultados?\n\n\n\nRecuerda que las pruebas omnibus del ANOVA de arriba sólo tienen sentido en cuanto a comparación de medias, para los términos de efectos fijos.\n\n\nConviene saber que hay muchas maneras de hacer lo mismo en R. esta es otra forma de lograr exactamente lo mismo, pero utilizando otra notación en la forma de escribir las ecuaciones al utilizar la función de ajuste de modelos lineales.\n\n\nCódigo\nratas.nulo &lt;- lm(glucogeno~1, data=ratas)\nratas.completo &lt;- lm(glucogeno ~ trat_txt/rata/muestraH, data=ratas)\nanova(ratas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                       Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ntrat_txt                2 1557.56  778.78 36.7927 4.375e-07 ***\ntrat_txt:rata           3  797.67  265.89 12.5617 0.0001143 ***\ntrat_txt:rata:muestraH 12  594.00   49.50  2.3386 0.0502907 .  \nResiduals              18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCódigo\nsummary(ratas.completo)\n\n\n\nCall:\nlm(formula = glucogeno ~ trat_txt/rata/muestraH, data = ratas)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.00  -2.25   0.00   2.25   6.00 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     130.500      3.253  40.114  &lt; 2e-16 ***\ntrat_txttrat_2                   20.500      4.601   4.456 0.000305 ***\ntrat_txttrat_3                   -1.000      4.601  -0.217 0.830375    \ntrat_txttrat_1:rata2             18.500      4.601   4.021 0.000801 ***\ntrat_txttrat_2:rata2              2.000      4.601   0.435 0.668937    \ntrat_txttrat_3:rata2              9.500      4.601   2.065 0.053645 .  \ntrat_txttrat_1:rata1:muestraH2   -2.500      4.601  -0.543 0.593526    \ntrat_txttrat_2:rata1:muestraH2   -3.000      4.601  -0.652 0.522595    \ntrat_txttrat_3:rata1:muestraH2    8.500      4.601   1.848 0.081172 .  \ntrat_txttrat_1:rata2:muestraH2   -7.500      4.601  -1.630 0.120438    \ntrat_txttrat_2:rata2:muestraH2   -6.000      4.601  -1.304 0.208616    \ntrat_txttrat_3:rata2:muestraH2   -0.500      4.601  -0.109 0.914660    \ntrat_txttrat_1:rata1:muestraH3    8.500      4.601   1.848 0.081172 .  \ntrat_txttrat_2:rata1:muestraH3   -1.000      4.601  -0.217 0.830375    \ntrat_txttrat_3:rata1:muestraH3    6.000      4.601   1.304 0.208616    \ntrat_txttrat_1:rata2:muestraH3    6.000      4.601   1.304 0.208616    \ntrat_txttrat_2:rata2:muestraH3    4.000      4.601   0.869 0.396059    \ntrat_txttrat_3:rata2:muestraH3   -8.500      4.601  -1.848 0.081172 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.601 on 18 degrees of freedom\nMultiple R-squared:  0.8856,    Adjusted R-squared:  0.7775 \nF-statistic: 8.196 on 17 and 18 DF,  p-value: 2.508e-05\n\n\nuso de la función de análisis de la varianza de R\n\n\nCódigo\nratas.aov &lt;- aov(glucogeno ~ tratamiento/rata/muestraH, data=ratas)\nsummary(ratas.aov)\n\n\n                          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamiento                2 1557.6   778.8  36.793 4.38e-07 ***\ntratamiento:rata           3  797.7   265.9  12.562 0.000114 ***\ntratamiento:rata:muestraH 12  594.0    49.5   2.339 0.050291 .  \nResiduals                 18  381.0    21.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCódigo\nanova(ratas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                       Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ntrat_txt                2 1557.56  778.78 36.7927 4.375e-07 ***\ntrat_txt:rata           3  797.67  265.89 12.5617 0.0001143 ***\ntrat_txt:rata:muestraH 12  594.00   49.50  2.3386 0.0502907 .  \nResiduals              18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo hemos dicho, en realidad la estructura de estos datos es mixta en cuanto a que incluye efectos fijos de los tratamientos y efectos aleatorios. Contiene los efectos aleatorios de la muestra que constituyen las ratas y dentro de ellas el muestreo de porciones de hígado. Así, la prueba F para el efecto de tratamientos es de interés pero, en el caso de los factores aleatorios puede valer la pena estimar los componentes de varianza asociados con cada etapa de muestreo. Una manera de hacer esto es mediante la función aov de R, dentro de la cual sólo es necesario designar las columnas que corresponden con efectos aleatorios mediante la función Error(). Estto funciona bien si el experimento es completo y balanceado.\n\n\nCódigo\nratas.aov &lt;- aov(glucogeno ~ tratamiento/rata/muestraH + \n                 Error(rata + muestraH + rata/muestraH), data=ratas)\nsummary(ratas.aov)\n\n\n\nError: rata\n                 Df Sum Sq Mean Sq\ntratamiento:rata  1  413.4   413.4\n\nError: muestraH\n                          Df Sum Sq Mean Sq\ntratamiento:rata:muestraH  2  113.6   56.78\n\nError: rata:muestraH\n                          Df Sum Sq Mean Sq\ntratamiento:rata:muestraH  2  50.89   25.44\n\nError: Within\n                          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntratamiento                2 1557.6   778.8  36.793 4.38e-07 ***\ntratamiento:rata           2  384.2   192.1   9.076  0.00188 ** \ntratamiento:rata:muestraH  8  429.6    53.7   2.537  0.04813 *  \nResiduals                 18  381.0    21.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "ejercicios/crittico/critico.html",
    "href": "ejercicios/crittico/critico.html",
    "title": "Ejercicios críticos",
    "section": "",
    "text": "library(skimr) # para echar un ojito a las bases de datos\nlibrary(sf)    # para trabajo geoespacial con vectores"
  },
  {
    "objectID": "ejercicios/crittico/critico.html#serie-temporal-de-temperatura-y-humedad-relativa",
    "href": "ejercicios/crittico/critico.html#serie-temporal-de-temperatura-y-humedad-relativa",
    "title": "Ejercicios críticos",
    "section": "Serie temporal de temperatura y humedad relativa",
    "text": "Serie temporal de temperatura y humedad relativa\nLos datos de esta serie fueron tomados con un termo-higrómetro con registro automático (logger) “Hygrochron Temperature and Humidity Data Logger” de la marca ibuttonlink, en el periodo comprendido entre: 2016-02-08 19:00:00 y 2017-05-31 12:01:00, en la localidad Tapachapa del Municipio Coatepec, Veracruz (lon: -96.98109; lat: 19.45871). Consta de 11,045 registros, en formato csv (comma separated value). El termo-higrómetro fue colocado en un vivero de producción de árboles nativos para restauración de ecosistemas en bosques mesófilos de montaña y bosques templados.\n\nObjetivos del monitoreo\n\nTener un registro meteorológico de la temperatura y la humedad relativa, que son de las principales variables ambientales que pueden afectar el crecimiento de las plantas.\nCubrir el vacío de estaciones meteorológicas en la zona.\n\nFuente de los datos: Pronatura Veracruz, 2017. CC-by-SA\n\n\nDescripción de las bases de datos\narchivo Gavilanes_Temperatura.csv\n\n\n\nColumna\ndatatype\nDescripción\n\n\n\n\nDate.Time\ndatetime\nfecha-hora, formato día/mes/año hora:minuto\n\n\nUnit\nchr\nUnidad, (°C para todo el dataset)\n\n\nValue\ndbl\nValor de temperatura leído\n\n\n\n\nread.csv(\"https://gitlab.com/datamarindo/datasets/-/raw/master/Gavilanes_Temperatura.csv?inline=false\") |&gt; skimr::skim()\n\n\nData summary\n\n\nName\nread.csv(“https://gitlab….\n\n\nNumber of rows\n11045\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nDate.Time\n0\n1\n16\n16\n0\n11044\n0\n\n\nUnit\n0\n1\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nValue\n0\n1\n20.01\n6.44\n3.51\n15.54\n18.55\n24.55\n39.04\n▁▇▆▃▁\n\n\n\n\n\narchivo Gavilanes_rh.csv\n\n\n\nColumna\ndatatype\nDescripción\n\n\n\n\nDate.Time\ndatetime\nfecha-hora, formato día/mes/año hora:minuto\n\n\nUnit\nchr\nUnidad, (%RH para todo el dataset)\n\n\nValue\ndbl\nValor de humedad relativa leído\n\n\n\n\nread.csv(\"https://gitlab.com/datamarindo/datasets/-/raw/master/Gavilanes_rh.csv?inline=false\") |&gt; skimr::skim()\n\n\nData summary\n\n\nName\nread.csv(“https://gitlab….\n\n\nNumber of rows\n11045\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nDate.Time\n0\n1\n16\n16\n0\n11044\n0\n\n\nUnit\n0\n1\n3\n3\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nValue\n0\n1\n88.32\n22.59\n10.81\n72.28\n101.82\n104.69\n111.17\n▁▁▂▁▇\n\n\n\n\n\n\n\n\nubicación del ibutton"
  },
  {
    "objectID": "ejercicios/crittico/critico.html#serie-espacio-temporal-de-nivel-de-inundación-en-el-sistema-lagunar-de-alvarado-veracruz.",
    "href": "ejercicios/crittico/critico.html#serie-espacio-temporal-de-nivel-de-inundación-en-el-sistema-lagunar-de-alvarado-veracruz.",
    "title": "Ejercicios críticos",
    "section": "Serie espacio-temporal de nivel de inundación en el Sistema Lagunar de Alvarado, Veracruz.",
    "text": "Serie espacio-temporal de nivel de inundación en el Sistema Lagunar de Alvarado, Veracruz.\nLos piezómetros utilizados para este monitoreo consisten en un tubo de PVC de 2.0 a 2.1 m de largo y 2 pulgadas de diámetro, abierto por ambos lados, enterrado parado en el suelo. Cada lectura fue tomada manualmente con una cinta métrica, midiendo la diferencia del nivel del agua y la parte alta del tubo de PVC.\n\nObjetivos del monitoreo\n\nComparar las características hidrológicas entre zonas restauradas y manglares maduros (protección) a lo largo del tiempo, a través del monitoreo del hidroperiodo (tiempo en meses en que permanece inundada una zona) diferenciado por zonas destinadas a restauración ecológica de manglar y a protección legal de tierras (valores RE****** y PR****** de la variable clave_punt, respectivamente.\nComparación con los niveles de mareas de la red mareográfica nacional\n\nFuente de los datos: Pronatura Veracruz, 2017. CC-by-SA\n\n\nDescripción de las bases de datos\narchivo Gavilanes_Temperatura.csv\n\n\n\n\n\n\n\n\nColumna\ndatatype\nDescripción\n\n\n\n\nclave_punt\nchr\nclave del piezómetro\n\n\nlatitud\ndbl\nlatitud en grados del piezómetro\n\n\nlongitud\ndbl\nlongitud en grados del piezómetro\n\n\npredio_sit\nchr\nNombre del predio\n\n\nfecha\nchr\nfecha, formato día/mes/año\n\n\nhora\nchr\nhora de toma de muestra (solo en algunos piezómetros)\n\n\nht_m\ndbl\naltura del piezómetro, centímetros\n\n\nmedida_cm\ndbl\nmedición desde lo alto del piezómetro hasta el nivel del agua\n\n\ninundación\ndbl\nnivel sobre el suelo de inundación (altura del piezómetro sobre el suelo menos la medida_cm )\n\n\ncomentario\nchr\nobservaciones\n\n\ngeom\ngeom\ncoordenadas UTM Zona 15 N (EPSG:32615) del piezómetro\n\n\n\n\nread_sf(\"https://gitlab.com/datamarindo/datasets/-/raw/master/piezometros_pver.gpkg?inline=false\") |&gt; skimr::skim()\n\nWarning: Couldn't find skimmers for class: sfc_POINT, sfc; No user-defined\n`sfl` provided. Falling back to `character`.\n\n\n\nData summary\n\n\nName\nread_sf(“https://gitlab.c…\n\n\nNumber of rows\n1115\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nclave_punt\n0\n1.00\n8\n9\n0\n34\n0\n\n\npredio_sit\n0\n1.00\n8\n22\n0\n15\n0\n\n\nfecha\n0\n1.00\n10\n10\n0\n248\n0\n\n\nhora\n849\n0.24\n5\n5\n0\n167\n0\n\n\ncomentario\n1032\n0.07\n9\n126\n0\n30\n0\n\n\ngeom\n0\n1.00\n18\n18\n0\n34\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlatitud\n0\n1.00\n18.65\n0.04\n18.59\n18.62\n18.66\n18.70\n18.72\n▅▂▇▁▆\n\n\nlongitud\n0\n1.00\n-95.77\n0.04\n-95.83\n-95.80\n-95.77\n-95.74\n-95.71\n▅▇▆▅▇\n\n\nht_m\n267\n0.76\n204.33\n1.75\n200.00\n203.00\n205.00\n205.30\n210.00\n▂▂▇▁▁\n\n\nmedida_cm\n1\n1.00\n101.55\n31.20\n13.00\n83.00\n97.75\n117.00\n205.50\n▁▆▇▂▁\n\n\ninundaci\n1\n1.00\n2.94\n31.10\n-100.00\n-12.15\n7.00\n22.00\n87.00\n▁▂▇▆▁\n\n\n\n\n\n\n\n\nubicación de los piezómetros en el Sistema Lagunar de Alvarado\n\n\nComic de la portada: https://xkcd.com"
  },
  {
    "objectID": "ejercicios/ejercicio-critico/index.html",
    "href": "ejercicios/ejercicio-critico/index.html",
    "title": "Tarea de análisis críticos",
    "section": "",
    "text": "Fuente: xkcd.com\nlibrary(skimr) # para echar un ojito a las bases de datos\nlibrary(sf)    # para trabajo geoespacial con vectores"
  },
  {
    "objectID": "ejercicios/ejercicio-critico/index.html#serie-temporal-de-temperatura-y-humedad-relativa",
    "href": "ejercicios/ejercicio-critico/index.html#serie-temporal-de-temperatura-y-humedad-relativa",
    "title": "Tarea de análisis críticos",
    "section": "Serie temporal de temperatura y humedad relativa",
    "text": "Serie temporal de temperatura y humedad relativa\nLos datos de esta serie fueron tomados con un termo-higrómetro con registro automático (logger) “Hygrochron Temperature and Humidity Data Logger” de la marca ibuttonlink, en el periodo comprendido entre: 2016-02-08 19:00:00 y 2017-05-31 12:01:00, en la localidad Tapachapa del Municipio Coatepec, Veracruz (lon: -96.98109; lat: 19.45871). Consta de 11,045 registros, en formato csv (comma separated value). El termohigrómetro fue colocado en un vivero de producción de árboles nativos para restauración de ecosistemas en bosques mesófilos de montaña y bosques templados.\n\nObjetivos del monitoreo\n\nTener un registro meteorológico de la temperatura y la humedad relativa, que son de las principales variables ambientales que pueden afectar el crecimiento de las plantas.\nCubrir el vacío de estaciones meteorológicas en la zona.\n\nFuente de los datos: Pronatura Veracruz, 2017. (Licencia de uso: CC-by-SA)\n\n\nDescripción de las bases de datos\narchivo Gavilanes_Temperatura.csv\n\n\n\nColumna\ndatatype\nDescripción\n\n\n\n\nDate.Time\ndatetime\nfecha-hora, formato día/mes/año hora:minuto\n\n\nUnit\nchr\nUnidad, (°C para todo el dataset)\n\n\nValue\ndbl\nValor de temperatura leído\n\n\n\n\nread.csv(\"https://gitlab.com/datamarindo/datasets/-/raw/master/Gavilanes_Temperatura.csv?inline=false\") |&gt; skimr::skim()\n\n\nData summary\n\n\nName\nread.csv(“https://gitlab….\n\n\nNumber of rows\n11045\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nDate.Time\n0\n1\n16\n16\n0\n11044\n0\n\n\nUnit\n0\n1\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nValue\n0\n1\n20.01\n6.44\n3.51\n15.54\n18.55\n24.55\n39.04\n▁▇▆▃▁\n\n\n\n\n\narchivo Gavilanes_rh.csv\n\n\n\nColumna\ndatatype\nDescripción\n\n\n\n\nDate.Time\ndatetime\nfecha-hora, formato día/mes/año hora:minuto\n\n\nUnit\nchr\nUnidad, (%RH para todo el dataset)\n\n\nValue\ndbl\nValor de humedad relativa leído\n\n\n\n\nread.csv(\"https://gitlab.com/datamarindo/datasets/-/raw/master/Gavilanes_rh.csv?inline=false\") |&gt; skimr::skim()\n\n\nData summary\n\n\nName\nread.csv(“https://gitlab….\n\n\nNumber of rows\n11045\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nDate.Time\n0\n1\n16\n16\n0\n11044\n0\n\n\nUnit\n0\n1\n3\n3\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nValue\n0\n1\n88.32\n22.59\n10.81\n72.28\n101.82\n104.69\n111.17\n▁▁▂▁▇\n\n\n\n\n\n\n\n\n\n\n\nEjercicios para este conjunto de datos\n\n\n\n\nHacer un análisis exploratorio gráfico de ambas variables (temperatura y humedad relativa)\nComentar la relación entre ambas variables\nComparar los resultados de este monitoreo con la información a nivel local\nComentar si los resultados de este monitoreo sirven para los objetivos propuestos\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n \n\n\nUbicación del ibutton"
  },
  {
    "objectID": "ejercicios/ejercicio-critico/index.html#serie-espacio-temporal-de-nivel-de-inundación-en-el-sistema-lagunar-de-alvarado-veracruz.",
    "href": "ejercicios/ejercicio-critico/index.html#serie-espacio-temporal-de-nivel-de-inundación-en-el-sistema-lagunar-de-alvarado-veracruz.",
    "title": "Tarea de análisis críticos",
    "section": "Serie espacio-temporal de nivel de inundación en el Sistema Lagunar de Alvarado, Veracruz.",
    "text": "Serie espacio-temporal de nivel de inundación en el Sistema Lagunar de Alvarado, Veracruz.\nLos piezómetros utilizados para este monitoreo consisten en un tubo de PVC de 2.0 a 2.1 m de largo y 2 pulgadas de diámetro, abierto por ambos lados, enterrado parado en el suelo. Cada lectura fue tomada manualmente con una cinta métrica, midiendo la diferencia del nivel del agua y la parte alta del tubo de PVC.\n\nObjetivos del monitoreo\n\nComparar las características hidrológicas entre zonas restauradas y manglares maduros (protección) a lo largo del tiempo, a través del monitoreo del hidroperiodo (tiempo en meses en que permanece inundada una zona) diferenciado por zonas destinadas a restauración ecológica de manglar y a protección legal de tierras (valores RE****** y PR****** de la variable clave_punt, respectivamente.\nComparación con los niveles de mareas de la red mareográfica nacional\n\nFuente de los datos: Pronatura Veracruz, 2017. CC-by-SA\n\n\nDescripción de las bases de datos\narchivo Gavilanes_Temperatura.csv\n\n\n\n\n\n\n\n\nColumna\ndatatype\nDescripción\n\n\n\n\nclave_punt\nchr\nclave del piezómetro\n\n\nlatitud\ndbl\nlatitud en grados del piezómetro\n\n\nlongitud\ndbl\nlongitud en grados del piezómetro\n\n\npredio_sit\nchr\nNombre del predio\n\n\nfecha\nchr\nfecha, formato día/mes/año\n\n\nhora\nchr\nhora de toma de muestra (solo en algunos piezómetros)\n\n\nht_m\ndbl\naltura del piezómetro, centímetros\n\n\nmedida_cm\ndbl\nmedición desde lo alto del piezómetro hasta el nivel del agua\n\n\ninundación\ndbl\nnivel sobre el suelo de inundación (altura del piezómetro sobre el suelo menos la medida_cm )\n\n\ncomentario\nchr\nobservaciones\n\n\ngeom\ngeom\ncoordenadas UTM Zona 15 N (EPSG:32615) del piezómetro\n\n\n\n\nread_sf(\"https://gitlab.com/datamarindo/datasets/-/raw/master/piezometros_pver.gpkg?inline=false\") |&gt; skimr::skim()\n\nWarning: Couldn't find skimmers for class: sfc_POINT, sfc; No user-defined\n`sfl` provided. Falling back to `character`.\n\n\n\nData summary\n\n\nName\nread_sf(“https://gitlab.c…\n\n\nNumber of rows\n1115\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nclave_punt\n0\n1.00\n8\n9\n0\n34\n0\n\n\npredio_sit\n0\n1.00\n8\n22\n0\n15\n0\n\n\nfecha\n0\n1.00\n10\n10\n0\n248\n0\n\n\nhora\n849\n0.24\n5\n5\n0\n167\n0\n\n\ncomentario\n1032\n0.07\n9\n126\n0\n30\n0\n\n\ngeom\n0\n1.00\n18\n18\n0\n34\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlatitud\n0\n1.00\n18.65\n0.04\n18.59\n18.62\n18.66\n18.70\n18.72\n▅▂▇▁▆\n\n\nlongitud\n0\n1.00\n-95.77\n0.04\n-95.83\n-95.80\n-95.77\n-95.74\n-95.71\n▅▇▆▅▇\n\n\nht_m\n267\n0.76\n204.33\n1.75\n200.00\n203.00\n205.00\n205.30\n210.00\n▂▂▇▁▁\n\n\nmedida_cm\n1\n1.00\n101.55\n31.20\n13.00\n83.00\n97.75\n117.00\n205.50\n▁▆▇▂▁\n\n\ninundaci\n1\n1.00\n2.94\n31.10\n-100.00\n-12.15\n7.00\n22.00\n87.00\n▁▂▇▆▁\n\n\n\n\n\n\n\n\n\n\n\nEjercicios para este set de datos\n\n\n\n\nHacer un análisis exploratorio de la variable inundación\nComparar la inundación entre los dos tratamientos (PRotección y REstauración)\nAplicar un modelo lineal a la variable inundación, dependiente de la variable tiempo\nComentar si los resultados de este monitoreo sirven para los objetivos.\nComparar estos datos con información a nivel mundial\nOpcional Hacer un análisis de serie de tiempo: descomponer tendencia y estacionalidad y hacer un pronóstico\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n \n\n\nUbicación de los piezómetros en el Sistema Lagunar de Alvarado"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#ejemplo-de-rieles",
    "href": "posts/08-modelos-mixtos/index.html#ejemplo-de-rieles",
    "title": "Modelos de Efectos Mixtos",
    "section": "Ejemplo de rieles",
    "text": "Ejemplo de rieles\n\n\n\n\n\n\nCalidad de rieles de ferrocarril\n\n\n\n\n\nUno de los principales problemas que enfrentan los ferrocarriles es la falla en las vías. Los defectos en los raíles, como parte básica de la vía, pueden provocar accidentes graves. La inspección de los rieles es crítica, considerando el enorme tráfico que soportan actualmente, la mayor velocidad y las cargas más pesadas. La inspección visual sólo puede detectar defectos superficiales y, a veces, signos evidentes de problemas internos, la defectoscopia ultrasónica desempeña un papel insustituible en la inspección de los rieles durante su funcionamiento.\n\nEste ejemplo se explica en este libro.\n\n\n\nEl estudio de las fuerzas y tensiones no destructivas en los materiales proporciona información importante para un diseño de ingeniería eficaz. El artículo Zero-Force Travel-Time Parameters for Ultrasonic Head-Waves in Railroad (Materials Evaluation, 1985: 854-858) reporta un estudio del tiempo de tránsito de un cierto tipo de onda que se obtiene al someter rieles de ferrocarril a esfuerzos de tensión longitudinal. Se realizaron tres mediciones en cada uno de seis rieles seleccionados aleatoriamente de una población más amplia de ellos. Los investigadores buscaban caracterizar la variación en el tiempo de viaje como referencia para describir la variabilidad típica entre los rieles que estaban adquiriendo y usando. Los ingenieros se interesaban en precisar la variabilidad atribuible al ejercicio de realizar las mediciones en un mismo riel y la variailidad que expresan los distintos rieles. Los datos son valores en nanosegundos, resultado de restar 36.1 \\(\\mu s\\) a cada observación.\nEste ejemplo es un caso simple de efectos aleatorios. En resumen, seis rieles fueron tomados al azar y sometidos a prueba tres veces cada uno mediante la medición del tiempo que le toma a cierto tipo de ondas ultrasónicas viajar a lo largo del riel. La Única condición experimental que cambia entre observaciones es el riel.\nClaramente el estudio tiene un solo criterio de clasificación, como posible condición de contraste. La intención del estudio fue la determinación de:\n\nTiempo de tránsito “típico” de un riel (tiempo esperado de tránsito)\nVariación en el tiempo de tránsito promedio entre los rieles (variabilidad entre rieles)\nVariación al medir el tiempo observado de tránsito en un mismo riel (variabilidad dentro de rieles)\n\n\\[\ny_{ij} = \\mu + \\beta_{1} R_{i} + \\varepsilon_{i(j)}\n\\]\nUtilizaremos la biblioteca nlme (Linear and Nonlinear Mixed Effects Models, de tipo Gausiano o normal) para ajustar los modelos de efectos mixtos y aprovecharé para que veamos dos bibliotecas de graficación de calidad publicación: lattice y ggplot2 .\nLattice contiene estas opciones:\n\n\n\ntipo de gráfica\ndescripción\nejemplo de fórmula\n\n\n\n\nbarchart\nbar chart\nx~A or A~x\n\n\nbwplot\nboxplot\nx~A or A~x\n\n\ncloud\n3D scatterplot\nz~x*y|A\n\n\ncontourplot\n3D contour plot\nz~x*y\n\n\ndensityplot\nkernal density plot\n~x|A*B\n\n\ndotplot\ndotplot\n~x|A\n\n\nhistogram\nhistogram\n~x\n\n\nlevelplot\n3D level plot\nz~y*x\n\n\nparallel\nparallel coordinates plot\ndata frame\n\n\nsplom\nscatterplot matrix\ndata frame\n\n\nstripplot\nstrip plots\nA~x or x~A\n\n\nxyplot\nscatterplot\ny~x|A\n\n\nwireframe\n3D wireframe graph\nz~y*x\n\n\n\nLas gráficas con lattice tienen todo un entorno de soporte. Por ejemplo los aspectos que pueden ajustarse se pueden ver con trellis.par.get() y se ajustan con trellis.par.set(). Se trata de una aproximación a la visualización de datos muy interesante que se desarrolló en la época en la que los lenguajes de programación S y más adelante R, estaban apareciendo. Quizás popr eso encontramos algo de lattice contruido dentro de nlme.\nActualmente, resulta quizás más práctico el enfoque que ha desarrollado ggplot2, basada en una semántica de graficación que Hadley Wickham explica originamente en su libro publicado en 2009. Actualmente Hadley trabaja con otros dos coautores (Danielle Navarro y Thomas Lin Pedersen) en al 3ra. edición, lo hacen como un preprint que pueden encontrar aquí. La gran influencia de este planteamiento a la producción de gráficas de datos ha dado lugar a muchas ideas y recursos de ayuda que fácilmente se pueden encontrar en la Web\nlos datos con los que trabajaremos en esta sesión están en la tabla Rail de la biblioteca nlme. Para acomodarlos a mis propósitos los copie a mi espacio de trabajo y los guardé en una variable con un nombre de mi gusto. Los datos de los rieles están ordenados según fueron ensayados.\n\n\nCódigo\nlibrary(nlme)\nlibrary(lattice)\nlibrary(ggplot2)\n\nrieles &lt;- Rail\nnames(rieles) &lt;- c(\"riel\", \"viaje\")\nstr(rieles)\n\n\nClasses 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"&lt;\"5\"&lt;\"1\"&lt;\"6\"&lt;..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n - attr(*, \"labels\")=List of 1\n  ..$ y: chr \"Zero-force travel time\"\n - attr(*, \"units\")=List of 1\n  ..$ y: chr \"(nanoseconds)\"\n - attr(*, \"formula\")=Class 'formula'  language travel ~ 1 | Rail\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"order.groups\")= logi TRUE\n\n\nLa tabla rieles fue creada como una estructura agrupada con la función groupeData de la biblioteca nlme. Veremos más adelante como usar esta función. Esta función agrega metadatos a la tabla. Si interesa hacer cambios a los metadatos de la tabla agrupada hay que usar la función update que ejemplificaré a continuación. Lo primero es explorar los atributos asignados.\n\n\nCódigo\nattributes(rieles)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$labels\n$labels$y\n[1] \"Zero-force travel time\"\n\n\n$units\n$units$y\n[1] \"(nanoseconds)\"\n\n\n$formula\ntravel ~ 1 | Rail\n\n$order.groups\n[1] TRUE\n\n\nAhora cambiemos estos atributos para que todo esté expresado en español y de paso corregir la fórmula, que tal como está, pierde la referencia adecuada a las variables que contiene la tabla, pues yo cambié los nombres de las variables.\n\n\nCódigo\nrieles  &lt;- update(rieles, formula = viaje ~ 1 | riel, FUN = mean,\n                  labels = list(y = \"Tiempo de viaje con fuerza cero\"),\n                  units = list(y = \"(nano segundos)\"))\n\n# Encontré un detallito raro de atributos que se quedan con basura. \n# Aunque no parecen producir ningún problema, esta es una manera de limpiarla.\nattributes(attributes(rieles)$formula)$\".Environment\" &lt;- environment()\nenvironment(attributes(rieles)$FUN) &lt;- environment()\nattributes(rieles)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$formula\nviaje ~ 1 | riel\n\n$labels\n$labels$y\n[1] \"Tiempo de viaje con fuerza cero\"\n\n\n$units\n$units$y\n[1] \"(nano segundos)\"\n\n\n$FUN\nfunction (x, ...) \nUseMethod(\"mean\")\n\n$order.groups\n[1] TRUE\n\n\nA esta tabla se le ha aplicado la función groupedData con la fórmula:\nviaje ~ 1| riel\nEsta estrategia permite darle mantenimiento a los metadatos, que incluyen indicaciones sobre el agrupamiento de los datos en la tablas. Para aprovechar esta estructura podemos usar funciones especiales, por cierto, dentro del paquete nmle, la función plo ha sido diseñada para usar opciones de graficación de lattice, puedes averiguar un poco más al respecto con help(plot.nmGroupedData):\n\ngapply - aplica funciones por grupos\ngsummary - calcula los resúmenes de datos por grupos\n\nPor lo pronto veamos los datos, con la función de graficación de lattice stripplot, que toma el factor riel, por lo tanto se trata de renglones cualitativos sobre los que se grafican los datos de velocidad de viaje.\n\n\nCódigo\noptions(repr.plot.width=10, repr.plot.height=6)\n\nstripplot(rieles$riel ~ rieles$viaje, pch = 19, col = \"red\", cex = 1.25,\n          main = list(label = \"Análisis de integridad estructural de rieles\", cex =2),\n          xlab = list(label = \"tiempo de viaje (ns)\", cex = 2),\n          ylab =  list(label = \"riel\", cex = 2), \n          scales = list(tck = c(2,0), x = list(cex = 2), y = list(cex = 2)))\n\n\n\n\n\n¿Cómo se ven estos datos? ¿qué piensas que habría que hacer?\n\n\nCódigo\nggplot(rieles, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 4, color = \"blue\") +\n       labs(title = \"Análisis de integridad estructural de rieles\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size=26), \n             axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\n\n\nCódigo\ngsummary(rieles)\n\n\n  riel    viaje\n2    2 31.66667\n5    5 50.00000\n1    1 54.00000\n6    6 82.66667\n3    3 84.66667\n4    4 96.00000\n\n\n¿Cómo se asigna la estructura de agrupación a una tabla de datos? Como dije al principio, se puede usar la función groupedData de la biblioteca nlme. Hagamos un ahora un ensayo de este proceso.\n\n\nCódigo\nrieles.sg &lt;- as.data.frame(rieles)\n\n\nEstructura de la tabla sin información de agrupamiento:\n\n\nCódigo\nstr(rieles.sg) \n\n\n'data.frame':   18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"&lt;\"5\"&lt;\"1\"&lt;\"6\"&lt;..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n\n\nLos atributos quue contiene este objeto son estos:\n\n\nCódigo\nattributes(rieles.sg)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"data.frame\"\n\n\nTomo los datos sin agrupamiento y proporciono los metadatos que definen la estructura de agrupamiento que caracterizan a la tabla :\n\n\nCódigo\nrieles.g &lt;- groupedData (viaje ~ 1 | riel, data = rieles.sg, \n                         FUN = mean,\n                         units = list( x = \"(ns)\"),\n                         labels = list(x = \"riel\", \n                                       y = \"tiempo de tránsito de fuerza cero\"),\n                         )\nstr(rieles.g)\n\n\nClasses 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"&lt;\"5\"&lt;\"1\"&lt;\"6\"&lt;..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n - attr(*, \"formula\")=Class 'formula'  language viaje ~ 1 | riel\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"riel\"\n  ..$ y: chr \"tiempo de tránsito de fuerza cero\"\n - attr(*, \"units\")=List of 1\n  ..$ x: chr \"(ns)\"\n - attr(*, \"FUN\")=function (x, ...)  \n - attr(*, \"order.groups\")= logi TRUE\n\n\n\n\nCódigo\ndata.frame(sg=rieles.sg, g=rieles.g)\n\n\n   sg.riel sg.viaje g.riel g.viaje\n1        1       55      1      55\n2        1       53      1      53\n3        1       54      1      54\n4        2       26      2      26\n5        2       37      2      37\n6        2       32      2      32\n7        3       78      3      78\n8        3       91      3      91\n9        3       85      3      85\n10       4       92      4      92\n11       4      100      4     100\n12       4       96      4      96\n13       5       49      5      49\n14       5       51      5      51\n15       5       50      5      50\n16       6       80      6      80\n17       6       85      6      85\n18       6       83      6      83\n\n\n\n\nCódigo\ngsummary(rieles.sg)\n\n\n    riel viaje\n26     2    26\n32     2    32\n37     2    37\n49     5    49\n50     5    50\n51     5    51\n53     1    53\n54     1    54\n55     1    55\n78     3    78\n80     6    80\n83     6    83\n85     3    85\n91     3    91\n92     4    92\n96     4    96\n100    4   100\n\n\n\n\nCódigo\ngsummary(rieles.g)\n\n\n  riel    viaje\n2    2 31.66667\n5    5 50.00000\n1    1 54.00000\n6    6 82.66667\n3    3 84.66667\n4    4 96.00000\n\n\n\n\nCódigo\nggplot(rieles.g, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 4, color = \"blue\") +\n       labs(title = \"Análisis de integridad estructural de rieles (rieles.g)\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size=26), \n             axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\nComo hemos visto, cambiar los metadatos de la tabla se hace con la función update().\nComo una demostración simple de esto, le cambiaré la etiqueta asociada a la variable de respuesta en la estructura de agrupamiento. Con esto.\n\n\nCódigo\nrieles.g1 &lt;- update(rieles.g, labels = list(y=\"tiempo (ns)\"))\nplot(rieles.g1)\n\n\n\n\n\nPrimera posibilidad de análisis. Modelo lineal simple. Es una elección natural en este caso, pues estima la media general. Hay que recordar seleccionar contrastes de tipo “tratamiento” aun para factores ordenados.\n¿Cómo representamos al riel en el modelo?\n\n\nCódigo\noptions ()$contrasts\n\n\n        unordered           ordered \n\"contr.treatment\"      \"contr.poly\" \n\n\nEmpecemos por construir el modelo nulo. ¿qué resultados nos ofrece este modelo?.\n\n\nCódigo\nrieles.m1 &lt;- lm(viaje ~ 1, data =rieles.g)\nsummary(rieles.m1)\n\n\n\nCall:\nlm(formula = viaje ~ 1, data = rieles.g)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-40.50 -16.25   0.00  18.50  33.50 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   66.500      5.573   11.93  1.1e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.65 on 17 degrees of freedom\n\n\nAsí, tengo una estimación del tiempo promedio de tránsito de: 66.5. El error estándar que estimo es: 5.573\n¿cómo quedan los residuos de este modelo?\nEl gráfico de cajas y bigotes o cajas y alambres es interesante para explorar lo que está pasando con los rieles. La versión que produce la función bwplot() de la biblioteca lattice es un buen recurso.\n¿Qué piensas de esta gráfica? ¿Te gusta lo que ves?\n\n\nCódigo\nbwplot(rieles.g$riel ~ resid(rieles.m1))\n\n\n\n\n\n\n\nCódigo\nggplot(rieles.g, aes(x = viaje, y = riel, group = riel)) + \n       stat_boxplot(geom='errorbar', linetype=2, width=0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\") +\n       labs(title = \"Análisis de integridad estructural de rieles (rieles.g)\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size=26), \n             axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\nAl ignorar el efecto de los rieles, dentro de los que repito la prueba para obtener las medidas de interés se produce un defecto que se ve claramente en esta gráfica de residuos.\nLos residuos de cada riel tienen todos el mismo signo. Es decir se mantiene un efecto sistemático importante en ellos.\nTe parecería buena idea agregar el término que representa al riel para resolver este problema?\n¿Es fijo o aleatorio?\nEste nuevo modelo permite que cada riel sea representado por una media diferente. Suponiendo efectos fijos, la estimación del parámetro de interés es esta.\n\n\nCódigo\nrieles.m2 &lt;- lm(viaje ~ riel - 1, data =rieles.g)\nrieles.m2\n\n\n\nCall:\nlm(formula = viaje ~ riel - 1, data = rieles.g)\n\nCoefficients:\nriel2  riel5  riel1  riel6  riel3  riel4  \n31.67  50.00  54.00  82.67  84.67  96.00  \n\n\n\n\nCódigo\nanova(rieles.m2)\n\n\nAnalysis of Variance Table\n\nResponse: viaje\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nriel       6  88911 14818.5  916.61 2.971e-15 ***\nResiduals 12    194    16.2                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCódigo\nsummary(rieles.m2)\n\n\n\nCall:\nlm(formula = viaje ~ riel - 1, data = rieles.g)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6667 -1.0000  0.1667  1.0000  6.3333 \n\nCoefficients:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nriel2   31.667      2.321   13.64 1.15e-08 ***\nriel5   50.000      2.321   21.54 5.86e-11 ***\nriel1   54.000      2.321   23.26 2.37e-11 ***\nriel6   82.667      2.321   35.61 1.54e-13 ***\nriel3   84.667      2.321   36.47 1.16e-13 ***\nriel4   96.000      2.321   41.35 2.59e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.021 on 12 degrees of freedom\nMultiple R-squared:  0.9978,    Adjusted R-squared:  0.9967 \nF-statistic: 916.6 on 6 and 12 DF,  p-value: 2.971e-15\n\n\n¿interpretación de este nuevo resultado?\n……….. ¿y los residuos? ¿cómo se ven ahora?\n\n\nCódigo\nbwplot(rieles.g$riel ~ resid(rieles.m2))\n\n\n\n\n\n\n\nCódigo\nres.m2 &lt;- data.frame(resid = resid(rieles.m2), riel = rieles.g$riel)\nggplot(res.m2, aes(x = resid, y = riel, group = riel)) + \n       stat_boxplot(geom='errorbar', linetype=2, width=0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\") \n\n\n\n\n\nA pesar de que el modelo remueve los efectos sistemáticos asociados a las características particulares de los distintos rieles, no proporciona una representación satisfactoria del problema.\nsi los rieles fueran de efectos fijos ¿qué implicaría este modelo? ¿cuál sería una interpretación razonable del tratamiento riel?\nAl suponer efectos fijos surge el problema de que se modelan de algún modo variantes individuales de los rieles que se usaron para realizar las pruebas. Desafortunadamente, tal clasificación no tiene ningún sentido en el contexto. Lo que interesa es estimar el tiempo de tránsito típico de cualquier riel en la población de rieles de la que se tomó la muestra.\nAdemás, la misma falta de correspondencia conceptual entre el modelo y la estimación que interesa, hace que este nuevo modelo no proporcione una clara estimación de la variación (componente de varianza), entre rieles, que es otra de las preguntas centrales de este estudio. Otro problema de este modelo de efectos fijos es que el número de parámetros crece linealmente con el número de rieles que se usan para realizar la prueba, generando un comportamiento extraño en el modelo respecto de la pregunta.\n\nEl Modelo de efectos aleatorios ¿resuelves estos problemas?.\nEn este enfoque se considera a los rieles como un efecto aleatorio sobre la media general. Hay principalmente dos métodos para ajustar este tipo de modelos el de máxima verosimilitud (ML) y el de máxima verosimilitud restringida (REML, default). La función que utilizaremos para el caso lineal es lme() que se usa de modo muy semejante a lm() y glm(). Sin embargo, nótese que ahora el modelo tiene dos grupos de fórmulas, una para describir los efectos fijos (opción fixed) y otra para describir los aleatorios (opción random). Esté último es siempre una fórmula que tiene sólo el lado derecho (no hay interés en predecir medias, ¿recuerdas?) y da cuenta de los efectos aleatorios y de la estructura de agrupamiento de los datos. Un agrupamiento se representa mediante el símbolo de barra vertical: |. Ahora, ajustemos un modelo de este tipo para obtener la estimación de máxima verosimilitud restringida para los rieles.\n\n\nCódigo\nrieles.m3 &lt;- lme(fixed = viaje ~ 1, \n                 random = ~ 1 | riel, \n                 data = rieles.g)\nrieles.m3\n\n\nLinear mixed-effects model fit by REML\n  Data: rieles.g \n  Log-restricted-likelihood: -61.0885\n  Fixed: viaje ~ 1 \n(Intercept) \n       66.5 \n\nRandom effects:\n Formula: ~1 | riel\n        (Intercept) Residual\nStdDev:    24.80547 4.020779\n\nNumber of Observations: 18\nNumber of Groups: 6"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#ayúdame-a-comentar-estos-resultados-qué-te-llama-la-atención",
    "href": "posts/08-modelos-mixtos/index.html#ayúdame-a-comentar-estos-resultados-qué-te-llama-la-atención",
    "title": "Modelos de Efectos Mixtos",
    "section": "Ayúdame a comentar estos resultados ¿qué te llama la atención?",
    "text": "Ayúdame a comentar estos resultados ¿qué te llama la atención?\n\n\nCódigo\nsummary (rieles.m3)\n\n\nLinear mixed-effects model fit by REML\n  Data: rieles.g \n      AIC      BIC   logLik\n  128.177 130.6766 -61.0885\n\nRandom effects:\n Formula: ~1 | riel\n        (Intercept) Residual\nStdDev:    24.80547 4.020779\n\nFixed effects:  viaje ~ 1 \n            Value Std.Error DF  t-value p-value\n(Intercept)  66.5  10.17104 12 6.538173       0\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-1.61882658 -0.28217671  0.03569328  0.21955784  1.61437744 \n\nNumber of Observations: 18\nNumber of Groups: 6"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#el-modelo-de-glucógeno-en-ratas-revisitado",
    "href": "posts/08-modelos-mixtos/index.html#el-modelo-de-glucógeno-en-ratas-revisitado",
    "title": "Modelos de Efectos Mixtos",
    "section": "El modelo de glucógeno en ratas revisitado",
    "text": "El modelo de glucógeno en ratas revisitado\nVolvamos a ver el ejemplo GLEX38 (Crawley p. 149) de Hígados de rata en el ejemplo presentado originalmente en Sokal & Rohlf (1981). Te recuerdo que se trata de un experimento con un solo factor con tres tratamientos administrados a seis ratas, dos por tratamiento. El análisis se complica por el hecho de que, para el an?lisis, se tomaron tres muestras del hígado de cada rata y se hicieron dos determinaciones de contenido de glucógeno en cada muestra. Así, podríamos decir, un tanto derogativamente, que hay seis pseudoréplicas por rata para dar un total de 36 lecturas en total. Pero quizás en lugar de hablar en estos términos deberíamos simmplemente reconocer que lo que estamos haciendo es organizar un muestreao para obtener el dato de la variable de respuesta en el experimento, en lugar de hacer una “cosecha total”, que es la práctica ideal (pues evita introducir un fuente de “ruido” adicional).\n\n\nCódigo\nratas_g &lt;- read.table(\"hígados-rata.DAT\", col.names=\"glucogeno\")\nratas_g$tratamiento &lt;- factor(rep(c(\"t1\",\"t2\",\"t3\"),each=12))\nratas_g$rata &lt;- factor(rep(paste(\"r\", 1:6, sep=\"\"), each=6))\nratas_g$muestraH &lt;- factor(rep(c(\"m1\", \"m2\", \"m3\"), times=6, each=2))\n\n\nLe doy estructura de grupos a la tabla\n\n\nCódigo\nratas_g &lt;- groupedData(glucogeno ~  1 | ordered(rata) / muestraH,\n                       data = ratas_g,\n                       labels= list(x = \"rata\", y = \"contenido de glucógeno\" ),\n                       FUN = mean)\nstr(ratas_g)\n\n\nClasses 'nmGroupedData', 'groupedData' and 'data.frame':    36 obs. of  4 variables:\n $ glucogeno  : int  131 130 131 125 136 142 150 148 140 143 ...\n $ tratamiento: Factor w/ 3 levels \"t1\",\"t2\",\"t3\": 1 1 1 1 1 1 1 1 1 1 ...\n $ rata       : Factor w/ 6 levels \"r1\",\"r2\",\"r3\",..: 1 1 1 1 1 1 2 2 2 2 ...\n $ muestraH   : Factor w/ 3 levels \"m1\",\"m2\",\"m3\": 1 1 2 2 3 3 1 1 2 2 ...\n - attr(*, \"formula\")=Class 'formula'  language glucogeno ~ 1 | ordered(rata)/muestraH\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"formulaList\")=List of 2\n  ..$ ordered(rata):Class 'formula'  language ~ordered(rata)\n  .. .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n  ..$ muestraH     :Class 'formula'  language ~muestraH\n  .. .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"rata\"\n  ..$ y: chr \"contenido de glucógeno\"\n - attr(*, \"order.groups\")=List of 2\n  ..$ ordered(rata): logi TRUE\n  ..$ muestraH     : logi TRUE\n - attr(*, \"FUN\")=function (x, ...)  \n\n\n\nExploración de los datos\nAprovechando las opciones de estructura de grupos puedo obtener resumenes exploratorios de manera muy simple.\n\n\nCódigo\ndata.frame(promedio = tapply (ratas_g$glucogeno, ratas_g$rata, function(x) round(mean(x), 2)))\n\n\n   promedio\nr1   132.50\nr2   148.50\nr3   149.67\nr4   152.33\nr5   134.33\nr6   136.00\n\n\nGraficación de los datos aprovechando la estructura agrupada que hemos adoptado.\n\n\nCódigo\nplot(ratas_g, inner =  ~ tratamiento, displayLeve=2)\n\n\n\n\n\n\n\nCódigo\nbwplot(glucogeno ~ tratamiento, boxmeans=T, data=ratas_g, \n     boxcol=14, xlab = \"Tratamiento\", ylab = \"Contenido de glucógeno\")\n\n\n\n\n\n\n\nModelación\nVeamos el enfoque con un modelo lineal de efectos mixtos."
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#cual-es-la-estructura-fija-me-puedes-decir-cuál-es-la-ecuación-correspondiente",
    "href": "posts/08-modelos-mixtos/index.html#cual-es-la-estructura-fija-me-puedes-decir-cuál-es-la-ecuación-correspondiente",
    "title": "Modelos de Efectos Mixtos",
    "section": "¿Cual es la estructura fija?, me puedes decir cuál es la ecuación correspondiente",
    "text": "¿Cual es la estructura fija?, me puedes decir cuál es la ecuación correspondiente"
  },
  {
    "objectID": "posts/08-modelos-mixtos/index.html#modelo-de-efectos-mixtos-lme",
    "href": "posts/08-modelos-mixtos/index.html#modelo-de-efectos-mixtos-lme",
    "title": "Modelos de Efectos Mixtos",
    "section": "Modelo de efectos mixtos: lme",
    "text": "Modelo de efectos mixtos: lme\n\n\nCódigo\nratas.lme4.ic &lt;- predict(ratas.lme.m4, level = 0, type = \"predict\")\n\n\n\n\nCódigo\nratas.lme4.ic  &lt;- data.frame(ajustado=as.numeric(ratas.lme4.ic), tratamiento=ratas_g$tratamiento)\n\n\n\n\nCódigo\nintervals(ratas.lme.m4)$fixed\n\n\n                   lower       est.      upper\n(Intercept)   133.507297 140.500000 147.492703\ntratamientot2  -4.479979  10.500000  25.479979\ntratamientot3 -20.313312  -5.333333   9.646646\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\nModelo de regresión convencional: lm\n\n\nCódigo\nratas.lm.ic &lt;- as.data.frame(predict(ratas.completo.lm, interval = 'confidence',\n                                     conf.level=0.95, ci.fit=TRUE))\n\n\n\n\nCódigo\nratas.lm.ic$tratamiento &lt;- ratas_g$tratamiento\n\n\n\n\nCódigo\ndata.frame(min=tapply(ratas.lm.ic$lwr, ratas.lm.ic$tratamiento, mean),\n           media=tapply(ratas.lm.ic$fit, ratas.lm.ic$tratamiento, mean),\n           max=tapply(ratas.lm.ic$upr, ratas.lm.ic$tratamiento, mean))\n\n\n        min    media      max\nt1 133.6653 140.5000 147.3347\nt2 144.1653 151.0000 157.8347\nt3 128.3319 135.1667 142.0014\n\n\nBueno, veamos los residuos!!!\n\n\nCódigo\nplot(ratas.lme.m4, rata ~ resid(.) | tratamiento, xlab=\"residuos\")\n\n\n\n\n\n\n\nCódigo\nplot(ratas.lme.m4)\n\n\n\n\n\n\n\nComparaciones múltiples\nVeamos qué está pasando con los efectos de los tratamientos una vez que hemos resuelto con la prueba omnibus que hay algún efecto de tratamiento.\nEl modelo completo, ¿cambia significativamente al recodifcar los tratamientos de manera que supongamos que el t1 no difiere del t2? Esto equivale a comparar los dos mmodelos respectivos.\n\n\nCódigo\nlibrary(tidyverse, warn.conflicts = FALSE)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::collapse() masks nlme::collapse()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nratas_g$trat_v1 &lt;-recode_factor(ratas_g$tratamiento, \"t2\"=\"t1\")\nratas.lme.m4A &lt;- lme(fixed=glucogeno ~ trat_v1, data=ratas_g, \n                     random=~1|rata/muestraH, method=\"ML\") \n\nratas_g$trat_v2 &lt;-recode_factor(ratas_g$tratamiento, \"t3\"=\"t2\")\nratas.lme.m4B &lt;- lme(fixed=glucogeno ~ trat_v2, data=ratas_g, \n                     random=~1|rata/muestraH, method=\"ML\") \n\nratas_g$trat_v3 &lt;-recode_factor(ratas_g$tratamiento, \"t3\"=\"t1\")\nratas.lme.m4C &lt;- lme(fixed=glucogeno ~ trat_v3, data=ratas_g, \n                     random=~1|rata/muestraH, method=\"ML\") \nhead(ratas_g)\n\n\nGrouped Data: glucogeno ~ 1 | ordered(rata)/muestraH\n  glucogeno tratamiento rata muestraH trat_v1 trat_v2 trat_v3\n1       131          t1   r1       m1      t1      t1      t1\n2       130          t1   r1       m1      t1      t1      t1\n3       131          t1   r1       m2      t1      t1      t1\n4       125          t1   r1       m2      t1      t1      t1\n5       136          t1   r1       m3      t1      t1      t1\n6       142          t1   r1       m3      t1      t1      t1\n\n\n¿Qué sugieren estos resultados estadísticos?\n\n\nCódigo\nanova(ratas.lme.m4A, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test L.Ratio p-value\nratas.lme.m4A     1  5 246.8941 254.8117 -118.4471                       \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 3.62358   0.057\n\n\nPreguntémonos lo mismo respecto de los tratamientos t2 y t3. Veamos lo que resulta al comparar los modelos\n\n\nCódigo\nanova(ratas.lme.m4B, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4B     1  5 249.6292 257.5467 -119.8146                        \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 6.358622  0.0117\n\n\nAhora los tratamientos t1 y t3. ¿qué resulta al comparar los modelos?\n\n\nCódigo\nanova(ratas.lme.m4C, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4C     1  5 244.4339 252.3514 -117.2169                        \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 1.163313  0.2808\n\n\n\n##¿Qué decisión tomarás?\n\n\nCódigo\nanova(ratas.lme.m4C)\n\n\n            numDF denDF  F-value p-value\n(Intercept)     1    18 4261.316  &lt;.0001\ntrat_v3         1     4    8.116  0.0464\n\n\n\n\nCódigo\nintervals(ratas.lme.m4)$fixed\n\n\n                   lower       est.      upper\n(Intercept)   133.507297 140.500000 147.492703\ntratamientot2  -4.479979  10.500000  25.479979\ntratamientot3 -20.313312  -5.333333   9.646646\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\nQuizás es más interesante ver los resultados en términos de los valores estimados para cada tratamiento, en lugar de sobre sus diferencias.\n\n\nCódigo\nt(data.frame(trat_1 = intervals(ratas.lme.m4)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4)$fixed[1:2,]),\n             trat_3 = colSums(intervals(ratas.lme.m4)$fixed[1:3,])))\n\n\n          lower     est.    upper\ntrat_1 133.5073 140.5000 147.4927\ntrat_2 129.0273 151.0000 172.9727\ntrat_3 108.7140 145.6667 182.6193\n\n\nSi optáramos por tomar al modelo C como nuestro modelo mínimo adecuado para describir el experimento de glucógeno, los resultados se verían así:\n\n\nCódigo\nanova(ratas.lme.m4C)\n\n\n            numDF denDF  F-value p-value\n(Intercept)     1    18 4261.316  &lt;.0001\ntrat_v3         1     4    8.116  0.0464\n\n\nEste modelo sugiere que es posible argumentar que el tratamiento combinando t1 y t3 difiere en forma apreciable o significativa con respecto del t2. Esto se aprecia al considerar los valores promedio de los tratamientos, pero no es realmente muy evidente. La forma como estoy calculando los valores tiene que considerar el tipo de reparametrización y la configuración del modelo, no olvides eso.\n\n\nCódigo\nnivel_confianza &lt;- 0.90\nt(data.frame(trat_1 = intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1:2,]),\n                 trat_3 = colSums(intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1:3,])))\n\n\n          lower     est.    upper\ntrat_1 134.7283 140.5000 146.2717\ntrat_2 134.1509 151.0000 167.8491\ntrat_3 117.7401 145.6667 173.5932\n\n\n\n\nCódigo\nt(data.frame(trat_1_y_3 = intervals(ratas.lme.m4C, level = nivel_confianza)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4C, level = nivel_confianza)$fixed[1:2,])))\n\n\n              lower     est.    upper\ntrat_1_y_3 133.3366 137.8333 142.3300\ntrat_2     136.9281 151.0000 165.0719"
  },
  {
    "objectID": "ejercicios/tareas/index.html",
    "href": "ejercicios/tareas/index.html",
    "title": "Control de Tareas",
    "section": "",
    "text": "Esta es la lista de tareas que hemos recibido y reunido en la carpeta que tenemos en Google Drive."
  },
  {
    "objectID": "ejercicios/tareas/index.html#registro-de-tareas-en-google-drive",
    "href": "ejercicios/tareas/index.html#registro-de-tareas-en-google-drive",
    "title": "Tareas",
    "section": "",
    "text": "Esta es la lista de tareas que hemos recibido hemos reunido en la carpeta de tareas que tenemos en Google Drive."
  },
  {
    "objectID": "ejercicios/tareas/index.html#lecturas",
    "href": "ejercicios/tareas/index.html#lecturas",
    "title": "Control de Tareas",
    "section": "Lecturas",
    "text": "Lecturas\n\n\n\nEsta es la colección de controles de lectura que hemos recibido."
  },
  {
    "objectID": "posts/09-medidas-repetidas/index.html",
    "href": "posts/09-medidas-repetidas/index.html",
    "title": "Modelos de medidas repetidas",
    "section": "",
    "text": "El tiempo es una variable problemática en el análisis estadístico, sobre todo por la necesidad de postular el supuesto de independencia entre las observaciones, lo que solemos asegurar aleatorizando las unidades experimentales. Las observaciones arregladas a lo largo del tiempo comúnmente no pueden aleatorizarse, por ejemplo cuando estamos dando seguimiento al crecimiento de un organismo. Por otro lado, también puede ocurrir esta falta de independencia por cercanía geográfica, así que el espacio comparte desafíos estadísticos con el tiempo."
  },
  {
    "objectID": "posts/09-medidas-repetidas/index.html#ejemplo-con-árboles-de-sitka",
    "href": "posts/09-medidas-repetidas/index.html#ejemplo-con-árboles-de-sitka",
    "title": "Modelos de medidas repetidas",
    "section": "Ejemplo con árboles de Sitka",
    "text": "Ejemplo con árboles de Sitka\nFuente: Venables y Ripley (1999, p.206), tabla Sitka de la biblioteca MASS. Datos de Diggle, Liang y Zeger (1994).\nSe trata de mediciones del tamaño-log (que se define como el logaritmo de la altura más dos veces el logaritmo del diámetro), de 79 árboles de Sitka spruce.\nA 54 de ellos se les hizo crecer en cámaras con atmósfera enriquecida con ozono y otros 25 fueron controles. La talla fue medida cinco veces en 1988 a intervalos de aproximadamente un mes (el tiempo se da en días a partir del 1 de enero de 1998). En 1989 se tomaron otras ocho mediciones (que se incluyen en una tabla aparte: Sitka89).\n\n\nCódigo\nlibrary(MASS)\nlibrary(nlme)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::collapse() masks nlme::collapse()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dplyr::select()   masks MASS::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCódigo\nsitka88 &lt;- Sitka\n\n\n\n\nCódigo\nstr(sitka88)\n\n\n'data.frame':   395 obs. of  4 variables:\n $ size : num  4.51 4.98 5.41 5.9 6.15 4.24 4.2 4.68 4.92 4.96 ...\n $ Time : num  152 174 201 227 258 152 174 201 227 258 ...\n $ tree : int  1 1 1 1 1 2 2 2 2 2 ...\n $ treat: Factor w/ 2 levels \"control\",\"ozone\": 2 2 2 2 2 2 2 2 2 2 ...\n\n\nLa estructura de grupos podemos usarla para representar una curva de crecimiento por árbol. Los 79 árboles en los datos “sitka” son demasiados para el ejemplo que quiero ilustrar. Mostraré sólo dos árboles: el 64 y 24.\n\nExploración de los datos de Sitka\n\n\nCódigo\nsitka88 &lt;-groupedData(size ~ Time | tree, data=sitka88)\nplot(sitka88[sitka88$tree == 64 | sitka88$tree == 24, ])\n\n\n\n\n\n¿Cómo se ven los número de resumen de los datos en general?\n\n\nCódigo\nformula(sitka88)\n\n\nsize ~ Time | tree\n\n\n\n\nCódigo\nhead(gsummary(sitka88[, c(\"size\",\"Time\")], groups=sitka88$size, omit=TRUE))\n\n\n     size Time\n2.23 2.23  152\n2.79 2.79  152\n2.84 2.84  152\n2.89 2.89  174\n2.96 2.96  152\n2.99 2.99  152\n\n\n\n\nCódigo\nplot.design(size ~ treat, data=sitka88)\n\n\n\n\n\nPongo una línea de tendencia en la gráfica con la opción geom_smooth. Tengo multiples opciones, ve la ayuda, pero aquí consideré dos opciones loess con el parámetro span = 1. La otra opción que consideré fue el método gam. Esta solución es demandante en cuanto a número de datos necesarios. En este caso tuve que ajustar el parámetro de número de nudos (knots), pues la aproximación a una curva suave por el método aditivo generalizado usado, gam, requiere por defecto datos para por lo menos calcular 10 nudos y esto no se logra en este conjunto de datos. Usualmente funciona sin mayores problemas cuando se tienen más de 1000 puntos. Para tener una representación un poco más simple opté por eliminar los intervalos de confianza, eso lo controla el parámetro se.\n\n\nCódigo\noptions(repr.plot.width=12, repr.plot.height=6)\nlibrary(ggplot2)\nggplot(sitka88, aes(x=Time, y=size, color = tree)) + \n       geom_smooth(method = \"loess\", span = 1, formula = y ~ x, se = FALSE, show.legend = FALSE) +\n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n\n\n\n\n\n\n\nCódigo\nggplot(sitka88, aes(x=Time, y=size, color = tree)) + \n       geom_smooth(method = \"gam\", span = 1, formula = y ~ s(x, bs = \"cs\", k = 5), \n                   se = FALSE, show.legend = FALSE) +\n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n\n\n\n\n\nAhora ajusto el modelo completo con el tiempo. Fuerzo a que el tiempo sea tratado como un factor ordenado, lo que junto con la opción de contraste usada ajusta polinomios ortogonales en este caso.\n\n\nCódigo\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\nCódigo\nsitka.lme1 &lt;- lme(fixed = size ~ treat * ordered(Time),\n                  random = ~ 1 | tree,\n                  data = sitka88)\nsummary(sitka.lme1)$tTable\n\n\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12286970 308 40.5724123 1.332276e-125\ntreatozone                 -0.21115704 0.14861459  77 -1.4208365  1.594013e-01\nordered(Time).L             1.19711183 0.03221011 308 37.1657221 7.430810e-116\nordered(Time).Q            -0.13405824 0.03221011 308 -4.1619932  4.098121e-05\nordered(Time).C            -0.04085663 0.03221011 308 -1.2684413  2.055983e-01\nordered(Time)^4            -0.02729902 0.03221011 308 -0.8475297  3.973580e-01\ntreatozone:ordered(Time).L -0.17856562 0.03895909 308 -4.5834135  6.656627e-06\ntreatozone:ordered(Time).Q -0.02644698 0.03895909 308 -0.6788399  4.977491e-01\ntreatozone:ordered(Time).C -0.01424899 0.03895909 308 -0.3657423  7.148084e-01\ntreatozone:ordered(Time)^4  0.01240293 0.03895909 308  0.3183578  7.504293e-01\n\n\n\n\nCódigo\nintervals(sitka.lme1, level = 0.95)$fixed\n\n\n                                 lower        est.       upper\n(Intercept)                 4.74334979  4.98512000  5.22689021\ntreatozone                 -0.50708650 -0.21115704  0.08477242\nordered(Time).L             1.13373214  1.19711183  1.26049153\nordered(Time).Q            -0.19743793 -0.13405824 -0.07067854\nordered(Time).C            -0.10423632 -0.04085663  0.02252307\nordered(Time)^4            -0.09067872 -0.02729902  0.03608067\ntreatozone:ordered(Time).L -0.25522527 -0.17856562 -0.10190597\ntreatozone:ordered(Time).Q -0.10310663 -0.02644698  0.05021266\ntreatozone:ordered(Time).C -0.09090864 -0.01424899  0.06241066\ntreatozone:ordered(Time)^4 -0.06425672  0.01240293  0.08906258\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\n\nAnaliizando la interección\nNotando la significancia de los términos de interacción: ¿podría simplificar el modelo limitando el ajuste a un efecto lineal de crecimiento que distingue entre los tratamiento? Veamos, calculo un nuevo vector que me permite hacer el ajuste de un efecto lineal a la diferencia entre tratamientos (que es la interacción).\n\n\nCódigo\nsitka88$tratGrad &lt;- sitka88$Time * (sitka88$treat==\"ozone\")\n\n\n\n\nCódigo\ntapply(sitka88$Time,list(sitka88$treat, sitka88$Time), FUN=mean)\n\n\n        152 174 201 227 258\ncontrol 152 174 201 227 258\nozone   152 174 201 227 258\n\n\nCódigo\ntapply(sitka88$tratGrad,list(sitka88$treat, sitka88$Time), FUN=mean)\n\n\n        152 174 201 227 258\ncontrol   0   0   0   0   0\nozone   152 174 201 227 258\n\n\nAhora ajusto un modelo en el que elimino la interacción de tratamiento con tiempo. Al mismo tiempo substituyo este efecto por el modelo con tiempo lineal en interacción con el tratamiento ozono (la variable que acabo de construir).\n\n\nCódigo\nsitka.lme2 &lt;- update(sitka.lme1, \n                     fixed = size ~ ordered(Time) + treat + tratGrad)\nsummary(sitka.lme2)$tTable\n\n\n                      Value    Std.Error  DF    t-value       p-value\n(Intercept)      4.98512000 0.1228696967 311 40.5724123 2.952779e-126\nordered(Time).L  1.19755089 0.0320437966 311 37.3723158 4.821617e-117\nordered(Time).Q -0.14549447 0.0181029428 311 -8.0370620  1.933996e-14\nordered(Time).C -0.05059644 0.0180459272 311 -2.8037597  5.368534e-03\nordered(Time)^4 -0.01672449 0.0180516171 311 -0.9264818  3.549141e-01\ntreatozone       0.22167749 0.1756140543  77  1.2622992  2.106510e-01\ntratGrad        -0.00213851 0.0004622668 311 -4.6261386  5.473912e-06\n\n\nEl resumen del ajuste muestra dos criterios que no hemos comentado mayormente antes. Son útiles para comparar y evaluar modelos. Estas medidas son resultado de la búsqueda de alternativas para valorar modelos que no se centre en el famoso valor de p.\n\nAIC - Criterio de información de Akaike = -2 * logVerosimilitud + 2 numParámetros\nBIC - Criterio de información bayesiano = -2 * logVerosimilitud + numParámetros * log(N)\n\nEs bueno contar con ellos para comparar la calidad general de los modelos ajustados, pero no olvides que centrar nuestra atención en los intervalos de confianza es más informativo y potencialmente interesante.\nEn cualquier caso, “entre más pequeño el valor del criterio, mejor”.\n\n\nCódigo\ndata.frame(AICmodelo_red=summary(sitka.lme2)$AIC, AICmodelo_comp=summary(sitka.lme1)$AIC)\n\n\n  AICmodelo_red AICmodelo_comp\n1       69.2691       79.90098\n\n\nCódigo\ndata.frame(BICmodelo_red=summary(sitka.lme2)$BIC, BICmodelo_comp=summary(sitka.lme1)$BIC)\n\n\n  BICmodelo_red BICmodelo_comp\n1      104.9181       127.3399\n\n\nTanto el criterio AIC como el BIC sugieren que el modelo reducido es preferible al modelo completo inicial. ¿Qué sugiere la comparación, en devianzas, de ambos modelo?\n\n\nCódigo\nanova(sitka.lme1, sitka.lme2)\n\n\nWarning in anova.lme(sitka.lme1, sitka.lme2): fitted objects with different\nfixed effects. REML comparisons are not meaningful.\n\n\n           Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nsitka.lme1     1 12 79.90098 127.3399 -27.95049                        \nsitka.lme2     2  9 69.26910 104.9181 -25.63455 1 vs 2 4.631882  0.2008\n\n\nNotese la advertencia que aparece al intentar esta comparación. Para resolverla, hay que volver a ajustar los modelos de interés, pero ahora con el método “ML”, que si me permite hacer comparaciones entre modelos.\n\n\nCódigo\nsitka.lme1.ML &lt;- lme(fixed = size ~ treat * ordered(Time),\n                 random = ~ 1 | tree,\n                 data = sitka88, method=\"ML\")\n\nsitka.lme2.ML &lt;- update(sitka.lme1.ML, \n                     fixed = size ~ ordered(Time) + treat + tratGrad, method=\"ML\")\n\n\nComparemos los resultados obtenidos hasta aquí\n\n\nCódigo\nanova(sitka.lme1.ML, sitka.lme2.ML)\n\n\n              Model df      AIC      BIC    logLik   Test   L.Ratio p-value\nsitka.lme1.ML     1 12 30.94633 78.69296 -3.473163                         \nsitka.lme2.ML     2  9 25.43446 61.24443 -3.717228 1 vs 2 0.4881304  0.9215\n\n\n\n\nCódigo\nsummary(sitka.lme2.ML)\n\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: sitka88 \n       AIC      BIC    logLik\n  25.43446 61.24443 -3.717228\n\nRandom effects:\n Formula: ~1 | tree\n        (Intercept)  Residual\nStdDev:    0.602333 0.1591217\n\nFixed effects:  size ~ ordered(Time) + treat + tratGrad \n                    Value  Std.Error  DF  t-value p-value\n(Intercept)      4.985120 0.12239376 311 40.73018  0.0000\nordered(Time).L  1.197551 0.03207475 311 37.33625  0.0000\nordered(Time).Q -0.145494 0.01812043 311 -8.02931  0.0000\nordered(Time).C -0.050596 0.01806336 311 -2.80105  0.0054\nordered(Time)^4 -0.016724 0.01806906 311 -0.92559  0.3554\ntreatozone       0.221677 0.17517548  77  1.26546  0.2095\ntratGrad        -0.002139 0.00046271 311 -4.62167  0.0000\n Correlation: \n                (Intr) o(T).L o(T).Q o(T).C o(T)^4 tretzn\nordered(Time).L  0.000                                   \nordered(Time).Q  0.000  0.066                            \nordered(Time).C  0.000  0.000  0.000                     \nordered(Time)^4  0.000  0.021  0.002  0.000              \ntreatozone      -0.699  0.442  0.042  0.000  0.013       \ntratGrad         0.000 -0.826 -0.079  0.000 -0.025 -0.535\n\nStandardized Within-Group Residuals:\n         Min           Q1          Med           Q3          Max \n-2.631308932 -0.525058743  0.009619032  0.514425152  5.968135202 \n\nNumber of Observations: 395\nNumber of Groups: 79"
  },
  {
    "objectID": "posts/09-medidas-repetidas/index.html#selección-del-polinomio",
    "href": "posts/09-medidas-repetidas/index.html#selección-del-polinomio",
    "title": "Modelos de medidas repetidas",
    "section": "Selección del polinomio",
    "text": "Selección del polinomio\nAhora veamos un poco más de cerca el modelo y veamos si la respuesta muestra una curvatura que pueda ser aproximada entonces por un polinomio y en ese caso identificar el polinomio de menor grado que podríamos usar.\nRecuerden que al utilizar factores ordenados le estamos indicando a R que optaremos por contrastes polinomiales ortogonales. Otra manera de obtener estos contrastes es con la función poly. Para ver como funciona esto usemos este comando los datos de tiempo. Del vector Time poly produce cuatro columnas nuevas, que dan cuenta de la tendencia lineal, cuadrática, cúbica, etc., con la peculiaridad de que cada columna es ortogonal a las demás.\n\n\nCódigo\nhead(poly(sitka88$Time, 4))\n\n\n                1           2           3            4\n[1,] -0.067556996  0.05935630 -0.04131435  0.018236996\n[2,] -0.038067831 -0.01959476  0.06928561 -0.059101377\n[3,] -0.001876583 -0.05989079  0.01348825  0.079713367\n[4,]  0.032974248 -0.03974302 -0.07127418 -0.048782834\n[5,]  0.074527162  0.05987226  0.02981468  0.009933848\n[6,] -0.067556996  0.05935630 -0.04131435  0.018236996\n\n\nEl Modelo 2 que hemos ajustado consumió todos los grados de libertad posible y estimó un polinomio de grado 4. Consideremos sólo el polinomio cúbico.\n\n\nCódigo\nsitka.lme3.ML &lt;- lme(fixed = size ~ treat + poly(Time, 3) + tratGrad,\n                 random = ~ 1 | tree,\n                 data = sitka88, method =\"ML\")\n\n\n\n\nCódigo\nsummary(sitka.lme3.ML)$tTable\n\n\n                     Value    Std.Error  DF    t-value       p-value\n(Intercept)     4.98512000 0.1222363435 312  40.782634 4.608733e-127\ntreatozone      0.22167749 0.1752587841  77   1.264858  2.097370e-01\npoly(Time, 3)1 10.55436327 0.2867893021 312  36.801803 1.551949e-115\npoly(Time, 3)2 -1.90581863 0.1613315870 312 -11.813053  7.256641e-27\npoly(Time, 3)3 -0.25924189 0.1613315870 312  -1.606889  1.090903e-01\ntratGrad       -0.00213851 0.0004649641 312  -4.599303  6.169978e-06\n\n\nAhora podemos compararlo con el modelo “2” que ajustamos antes, para explorar si el nuevo modelo pierde una grado importante de capacidad explicativa.\n\n\nCódigo\nanova(sitka.lme2.ML, sitka.lme3.ML)\n\n\n              Model df      AIC      BIC    logLik   Test L.Ratio p-value\nsitka.lme2.ML     1  9 25.43446 61.24443 -3.717228                       \nsitka.lme3.ML     2  8 27.31449 59.14557 -5.657243 1 vs 2 3.88003  0.0489\n\n\nEl crecimiento promedio de los árboles a lo largo del tiempo se puede ver así, aunque esto no considera la variación debida a los árboles en lo individual. No obstante veamos el resultado general.\n\n\nCódigo\ntapply(fitted(sitka.lme3.ML), list(sitka88$treat, sitka88$Time), mean)\n\n\n             152      174      201      227      258\ncontrol 4.169687 4.602721 5.075958 5.427362 5.649872\nozone   4.066311 4.452297 4.867795 5.163598 5.319814\n\n\nMás adecuado es utilizar la función predict() para considerar las particularidades del modelo para hacer las predicciones. Estos resultados los pondremos en una gráfica para ver de mejor manera los resultados.\n\n\nCódigo\nsitka88$ajus &lt;- predict(sitka.lme3.ML)\n\n\n\n\nCódigo\nggplot(sitka88, aes(x=Time, y=ajus, color = tree)) + \n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       geom_line(show.legend = FALSE) + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n\n\n\n\n\n\nComponente aleatorio\nPodemos ahora explorar como mejorar la modelación de los componentes aleatorios en este modelo.\n\n\nCódigo\nVarCorr(sitka.lme1)\n\n\ntree = pdLogChol(1) \n            Variance   StdDev   \n(Intercept) 0.37223660 0.6101120\nResidual    0.02593727 0.1610505\n\n\nLos modelos pueden incorporar una estructura de modelación de los patrones de correlación entre las observaciones. En este caso derivadas del hecho de que las mediciones se realizan a lo largo del tiempo, en intervalos relativamente cortos, sobre el mismo sujeto. Haremos esto aquí solo para ejemplificar el tema, que es amplio. Mi recomendación es más bien recurrir a la literatura existente para profundizar en el tema. Nótese que para la comparación de modelos en donde no estamos cambiando los componentes fijo, puede hacerse aún cuando el método de ajuste sea el REML. Usamos una opción del patrón de correlación que estamos asumiendo mediante la opción cor que recibe una estructura que da cuenta del patrón de correlación que se asume afecta a la forma como se producen las observaciones. En este caso optamos por un proceso de autocorrelación de orden 1 en las observaciones con correlación de 70%, derivado de medir a lo largo del tiempo cada árbol. Esto es lo que hace la función corCAR1, sobre la que pueden encontrar más información en la ayuda de R.\n\n\nCódigo\nsitka.lme4 &lt;- lme(size~ treat * ordered(Time), random = ~ 1 | tree,\n                  data = sitka88, corr=corCAR1(0.7, ~ Time | tree))\n\n\nVeamos como cambian los estadísticos de los modelos. Comparemos el modelo completo inicial, contra el completo considerando la nueva información sobre la correlación que hemos agregado en el modelo 4.\n\n\nCódigo\nanova(sitka.lme1,sitka.lme4)\n\n\n           Model df       AIC      BIC    logLik   Test  L.Ratio p-value\nsitka.lme1     1 12  79.90098 127.3399 -27.95049                        \nsitka.lme4     2 13 -63.17167 -11.7795  44.58583 1 vs 2 145.0727  &lt;.0001\n\n\nSe ve raro que haya AIC y BIC negativos, pero pasa, sí los consideraríamos como valores más pequeños que los positivos, así que aquí, el modelo 4 parece tener un ajuste bastante mejor que el 1.\n¿cómo se ve el modelo ajustado finalmente?\n\n\nCódigo\nsummary(sitka.lme4)$tTable\n\n\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12635223 308 39.4541523 1.827148e-122\ntreatozone                 -0.21115704 0.15282682  77 -1.3816753  1.710673e-01\nordered(Time).L             1.19711183 0.04907128 308 24.3953674  6.282539e-74\nordered(Time).Q            -0.13405824 0.02642497 308 -5.0731653  6.774439e-07\nordered(Time).C            -0.04085663 0.01978964 308 -2.0645467  3.980280e-02\nordered(Time)^4            -0.02729902 0.01672573 308 -1.6321568  1.036684e-01\ntreatozone:ordered(Time).L -0.17856562 0.05935318 308 -3.0085264  2.841806e-03\ntreatozone:ordered(Time).Q -0.02644698 0.03196179 308 -0.8274562  4.086192e-01\ntreatozone:ordered(Time).C -0.01424899 0.02393616 308 -0.5952914  5.520859e-01\ntreatozone:ordered(Time)^4  0.01240293 0.02023028 308  0.6130875  5.402709e-01\n\n\nCódigo\nsummary(sitka.lme1)$tTable\n\n\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12286970 308 40.5724123 1.332276e-125\ntreatozone                 -0.21115704 0.14861459  77 -1.4208365  1.594013e-01\nordered(Time).L             1.19711183 0.03221011 308 37.1657221 7.430810e-116\nordered(Time).Q            -0.13405824 0.03221011 308 -4.1619932  4.098121e-05\nordered(Time).C            -0.04085663 0.03221011 308 -1.2684413  2.055983e-01\nordered(Time)^4            -0.02729902 0.03221011 308 -0.8475297  3.973580e-01\ntreatozone:ordered(Time).L -0.17856562 0.03895909 308 -4.5834135  6.656627e-06\ntreatozone:ordered(Time).Q -0.02644698 0.03895909 308 -0.6788399  4.977491e-01\ntreatozone:ordered(Time).C -0.01424899 0.03895909 308 -0.3657423  7.148084e-01\ntreatozone:ordered(Time)^4  0.01240293 0.03895909 308  0.3183578  7.504293e-01\n\n\nAunque hay obviamente una importante correlaciónn entre observaciones, el efecto de considerar esto en el modelo es mínimo en términos de los valores de los coeficientes, aunque la significación valorada en términos de p cambia un poco, pero nada que nos haga modificar la apreciación del modelo. No parece valer la pena incorporar este aspecto de autocorrelación en el ajuste final, si nos atenemos a preferir el modelo más simple. Por otro lado, el asunto de considerar un efecto de autocorrelación en las observaciones parece exigir ser considerado. Tomemos este último camino\nLos intervalos de confianza de los coeficientes del modelo 4 son estos:\n\n\nCódigo\nintervals(sitka.lme4, which = \"fixed\", level = 0.95)$fixed\n\n\n                                 lower        est.        upper\n(Intercept)                 4.73649723  4.98512000  5.233742772\ntreatozone                 -0.51547411 -0.21115704  0.093160032\nordered(Time).L             1.10055448  1.19711183  1.293669187\nordered(Time).Q            -0.18605455 -0.13405824 -0.082061932\nordered(Time).C            -0.07979661 -0.04085663 -0.001916640\nordered(Time)^4            -0.06021018 -0.02729902  0.005612139\ntreatozone:ordered(Time).L -0.29535464 -0.17856562 -0.061776597\ntreatozone:ordered(Time).Q -0.08933808 -0.02644698  0.036444111\ntreatozone:ordered(Time).C -0.06134807 -0.01424899  0.032850096\ntreatozone:ordered(Time)^4 -0.02740411  0.01240293  0.052209970\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\n\nCódigo\nsitka.fin &lt;- aggregate(list(ajustado=fitted(sitka.lme4)), \n                       list(tiempo=sitka88$Time, trat=sitka88$treat), FUN=mean)\n\n\n\n\nCódigo\nsitka.fin$tiempo &lt;- as.numeric(sitka.fin$tiempo)\n\n\nUna gráfica de los resultados podría ser así. Ilustra la regresión obtenida para cada tratamiento y añado los puntos observados ( para que se vean un poco mejor use el geoma “jitter” que grafica los puntos pero procurando que no se sobrepongan. Le pedí que lo hicieran en “bandas” de ancho 2.\n\n\nCódigo\nggplot(sitka.fin, aes(x=tiempo, y=ajustado, color = trat)) + \n       geom_line(show.legend = TRUE) + \n       geom_point(show.legend = FALSE) + \n       xlab(label = \"tamaño-log\") +\n       ylab(label = \"tiempo (días)\") + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20)) +\n\n       # componente que agrega los datos a la gráfica\n       geom_jitter(data = sitka88, width = 2, \n                   mapping = aes(x = Time, y = size, color = treat)) \n\n\n\n\n\nConstruir los intervalos de confianza a partir del modelo de efectos mixtos puede ser un poco más elaborado, así que a continuación muestro como pueden hacerse. Una posibilidad es usar la función intervalscon la opción which = “fixed” para recuperar los resultados que implica sólo a los componentes de efectos fijos del modelo, que son los que se involucran en la predicción (los aleatorios participan en las varianzas).\n\n\nCódigo\nlibrary(tidyverse, warn.conflicts = FALSE)\nsitka_intconf &lt;- tibble(Time = sitka88$Time, treat = sitka88$treat)\nsitka_intconf &lt;- sitka_intconf %&gt;% add_column(ajus = fitted(sitka.lme4, level = 0))\nhead(sitka_intconf)\n\n\n# A tibble: 6 × 3\n   Time treat  ajus\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n1   152 ozone  4.06\n2   174 ozone  4.47\n3   201 ozone  4.85\n4   227 ozone  5.18\n5   258 ozone  5.31\n6   152 ozone  4.06\n\n\nNecesitaremos la matriz de diseño para calcular los intervalos de confianza asociados con el mmodelo.\n\n\nCódigo\nDesignmat &lt;- model.matrix(eval(eval(sitka.lme4$call$fixed)[-2]), \n                          sitka_intconf[-ncol(sitka_intconf)])\n\n\nAhora calculamos los errores estándar de las predicciones. La matriz diseño contiene las variables indicadoras de todos los términos en el modelo. Al multiplicarla por la matriz de varianzas y covarianzas del modelo (la que está en el componente sitka.lme4$varFix del modelo ajustado), produce los estimadores de varianza requeridos\n\n\nCódigo\npredvar &lt;- diag(Designmat %*% sitka.lme4$varFix %*% t(Designmat))\nsitka_intconf$SE &lt;- sqrt(predvar) \n\n\n\n\nCódigo\nhead(sitka_intconf)\n\n\n# A tibble: 6 × 4\n   Time treat  ajus     SE\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   152 ozone  4.06 0.0880\n2   174 ozone  4.47 0.0880\n3   201 ozone  4.85 0.0880\n4   227 ozone  5.18 0.0880\n5   258 ozone  5.31 0.0880\n6   152 ozone  4.06 0.0880\n\n\nSolo resta agregar las bandas de confianza en torno a la egresión. Esto lo haré con el geoma “ribbon” de ggplot2. Esta será una gráfica compleja que se elabora a partir de tres tablas de datos.\n\n\nCódigo\nggplot(sitka.fin, aes(x=tiempo, y=ajustado, color = trat)) + \n       geom_line(show.legend = TRUE) + \n\n       # Etiquetas y formato de despliegue\n       xlab(label = \"tamaño-log\") +\n       ylab(label = \"tiempo (días)\") + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20)) +\n\n       # bandas de confianza\n       geom_ribbon(data = sitka_intconf, aes(x = Time, y = ajus, color = treat,\n                                             ymin = ajus - 2 * SE,\n                                             ymax = ajus + 2 * SE),\n                   alpha=0.2, fill = \"blue\") +       \n\n       # componente que agrega los datos a la gráfica\n       geom_jitter(data = sitka88, width = 2, \n                   mapping = aes(x = Time, y = size, color = treat))"
  },
  {
    "objectID": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#un-ejemplo-sencillo",
    "href": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#un-ejemplo-sencillo",
    "title": "Medidas Repetidas",
    "section": "Un ejemplo sencillo",
    "text": "Un ejemplo sencillo\n\nSe trata de un estudio con dos tratamientos T , cuatro períodos P y seis animales para cada tratamientos en un diseño completamente al azar.\nEl modelo matricial correspondiente es:\n\n\\[~~~~~Y~~~~~~=~~~~~~X~~~~~~~~~~~~~ M~~~~~+~~~~~~ \\varepsilon \\\\\n~~~~~~~~~12×4~~~~~~~~~~12×2~~~~~~~~2×4~~~~~~~~~~12×4~~~~~\n\\]\n\nPara que este modelo pueda ser estimado es necesario que haya al menos \\(t+p\\) sujetos: 2+4 =6 en este caso."
  },
  {
    "objectID": "presentaciones/11-experimentar/experimentar.html#free-air-carbon-dioxide-enrichment",
    "href": "presentaciones/11-experimentar/experimentar.html#free-air-carbon-dioxide-enrichment",
    "title": "Infraestructura de Experimentación",
    "section": "Free-Air Carbon Dioxide Enrichment",
    "text": "Free-Air Carbon Dioxide Enrichment\n\nEs un estudio multidisciplinar para evaluar los efectos del aumento de los niveles de ozono troposférico y dióxido de carbono en la estructura y función de los ecosistemas forestales del norte.\nDispone de doce anillos de 30 m en los que se pueden controlar las concentraciones de dióxido de carbono y ozono troposférico.\nEl diseño permite evaluar los efectos de estos gases solos y combinados en muchos atributos del ecosistema, como el crecimiento, el desarrollo de las hojas, las características de las raíces y el carbono del suelo. Al no haber confinamiento, no se produce ningún cambio significativo en el entorno natural, aparte de la elevación de las concentraciones de los gases traza añadidos.\nAspenFACE Home Page (mtu.edu)"
  },
  {
    "objectID": "presentaciones/11-experimentar/experimentar.html#instituto-bermuda-de-ciencias-oceánicas",
    "href": "presentaciones/11-experimentar/experimentar.html#instituto-bermuda-de-ciencias-oceánicas",
    "title": "Infraestructura de Experimentación",
    "section": "Instituto Bermuda de Ciencias Oceánicas",
    "text": "Instituto Bermuda de Ciencias Oceánicas\n\nSus experimentos se preguntan:\n\n¿Desarrollará la generación actual de corales mayor capacidad para hacer frente al estrés en respuesta al que experimenta?\n¿Se adaptará mejor la próxima generación de corales a las condiciones ambientales experimentadas por sus progenitores?.\n\n\nThe Next Generation of Coral: What Can It Teach Us? | Currents | BIOS - Bermuda Institute of Ocean Sciences"
  },
  {
    "objectID": "presentaciones/11-experimentar/experimentar.html#centro-de-recursos-naturales",
    "href": "presentaciones/11-experimentar/experimentar.html#centro-de-recursos-naturales",
    "title": "Infraestructura de Experimentación",
    "section": "Centro de Recursos Naturales",
    "text": "Centro de Recursos Naturales\nMediante la recopilación y el examen de pruebas de la eficacia de distintos enfoques de gestión forestal, los responsables de la toma de decisiones, los científicos y las partes interesadas pueden conocer las opciones que determinarán la sostenibilidad de estos ecosistemas críticos.\nEl objetivo del estudio es examinar cómo los ecosistemas sostenibles pueden tener en cuenta tanto el bienestar del entorno forestal como el de las comunidades humanas\nT3 Watershed Experiment | Olympic Natural Resources Center (washington.edu)"
  },
  {
    "objectID": "presentaciones/11-experimentar/experimentar.html#qué-alternativas-hay-a-esto",
    "href": "presentaciones/11-experimentar/experimentar.html#qué-alternativas-hay-a-esto",
    "title": "Infraestructura de Experimentación",
    "section": "¿Qué alternativas hay a esto?",
    "text": "¿Qué alternativas hay a esto?"
  },
  {
    "objectID": "presentaciones/11-experimentar/experimentar.html#section-9",
    "href": "presentaciones/11-experimentar/experimentar.html#section-9",
    "title": "Infraestructura de Experimentación",
    "section": "",
    "text": "M3-Causalidad"
  },
  {
    "objectID": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#casos-familiares-en-ecología",
    "href": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#casos-familiares-en-ecología",
    "title": "Medidas Repetidas",
    "section": "",
    "text": "\\[  \n\\begin{align*}\nn_{t+1} &= rn_t \\\\\nn_{t+1} &= rn_t (1 - \\alpha n_t) \\\\\n\\end{align*}\n\\]\n\nEsta última versión de crecimiento logístico se ve así arreglando un poco los términos \\[  \nn_{t-1} = rn_t - r \\alpha n_t^2\n\\]\nOtra forma de incorporar densodependencia\n\n\\[\nn_{t+1} = rn_t e^{-an_t}\n\\]\n\n¿se puede arreglar ésta de alguna forma conveniente?"
  },
  {
    "objectID": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#ventajas-de-los-diseños-con-medidas-repetidas",
    "href": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#ventajas-de-los-diseños-con-medidas-repetidas",
    "title": "Medidas Repetidas",
    "section": "Ventajas de los diseños con medidas repetidas",
    "text": "Ventajas de los diseños con medidas repetidas\n\nSe obtiene más información de cada sujeto comparada con la que normalmente se obtiene en los diseños convencionales.\nEl número de sujetos necesarios para el estudio, dentro de un nivel dado de potencia estadística, tiende a ser mucho menor.\nComo las observaciones son hechas dentro de los sujetos, la variabilidad debida a las diferencias individuales entre los sujetos se elimina del término de error.\nCada sujeto actúa como su propio control, incrementando la potencia estadística del estudio."
  },
  {
    "objectID": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#qué-ocurre-con-el-supuesto-anterior",
    "href": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#qué-ocurre-con-el-supuesto-anterior",
    "title": "Medidas Repetidas",
    "section": "¿Qué ocurre con el supuesto anterior?",
    "text": "¿Qué ocurre con el supuesto anterior?\n\\[\n\\sigma_{y_1-y_m}^2 = \\sigma_{y_1}^2 + \\sigma_{y_m}^2 - 2cov(y_1, y_m)\n\\]\n\nQue podemos arreglar así si incorporamos el supuesto de homogeneidad de varianzas llamamos a la covarianza \\(\\rho\\):\n\n\\[\n\\sigma_{y_1-y_m}^2 = 2\\sigma^2 + \\rho\\sigma^2= 2\\sigma^2(1-\\rho)\n\\]"
  },
  {
    "objectID": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#y-claro-la-solución-con-modelos-mixtos",
    "href": "presentaciones/09-medidas-repetidas/medidas-repetidas.html#y-claro-la-solución-con-modelos-mixtos",
    "title": "Medidas Repetidas",
    "section": "…y claro, la solución con modelos mixtos",
    "text": "…y claro, la solución con modelos mixtos\n\nComo hemos visto, para estimar el “valor típico” de algo midiendo repetidamente podríamos intentar este modelo aproximado:\n\n\\[\ny_{ij} = \\beta + \\varepsilon_{j(i)}\n\\]\n\n\\(\\beta\\) es el “valor típico” en la población, pero como sabemos, en este caso habría dos componentes de varianza involucrados: variación entre sujetos y variación en las mediciones que realizamos en cada uno de ellos.\nEl modelo es más adecuadamente representado así:\n\n\\[\ny_{ij}=\\beta + \\eta_i + \\varepsilon_{j(i)}\n\\]\n\n\n\nM3-Causalidad"
  },
  {
    "objectID": "posts/10-experimentar/index.html",
    "href": "posts/10-experimentar/index.html",
    "title": "Experimentación Ecológica",
    "section": "",
    "text": "La experimentación con diseños adecuadamente aleatorizados es la norma de referencia científica para la exploración de proposiciones causales. Preguntas de gran envergadura para los intereses humanos se resuelven mediante esta aproximación. La experimentación desafía la imaginación y las capacidades materiales y humanas. Exige ingenio y creatividad, pero también está acotada por el marco ético que nos exige evitar dañar a otros seres humanos, así como también evitar hacerlo a otras especies o a la naturaleza misma."
  },
  {
    "objectID": "posts/10-experimentar/index.html#ciencia-abierta",
    "href": "posts/10-experimentar/index.html#ciencia-abierta",
    "title": "Experimentación Ecológica",
    "section": "Ciencia Abierta",
    "text": "Ciencia Abierta\nCentro de Ciencia Abierta\nCiecia abierta - UNESCO\nCiencia Abierta - CEPAL"
  },
  {
    "objectID": "ejercicios/shinylive/index.html",
    "href": "ejercicios/shinylive/index.html",
    "title": "Mi primer documento r-shinylive en Quarto",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\nui &lt;- page_fillable(\n  card(\n    card_header(\n      \"Masa corporal de pingüinos\",\n      tooltip(\n        bsicons::bs_icon(\"question-circle\"),\n        \"Masa (g)\",\n        placement = \"right\"\n      ),\n      popover(\n        bsicons::bs_icon(\"gear\", class = \"ms-auto\"),\n        tags$style(type='text/css', \".selectize-input { font-size: 12px; line-height: 12px;} .selectize-dropdown { font-size: 12px; line-height: 12px; }\"),\n        selectInput(\"yvar\", \"Separar por\", c(\"sexo\" = \"sex\", \"especie\" = \"species\",\n                                             \"isla\" = \"island\")),\n        selectInput(\"color\", \"Colorear por\", c(\"especie\" = \"species\", \n                                               \"isla\" = \"island\", \"sexo\" = \"sex\"),\n                    \"island\"),\n        title = \"Ajustes para la gráficación\",\n      ),\n      class = \"d-flex align-items-center gap-1\"\n    ),\n    plotOutput(\"plt\"),\n    card_footer(\n      \"Fuente: Gorman KB, Williams TD, Fraser WR (2014).\",\n      popover(\n        a(\"Para saber más\", href = \"#\"),\n        markdown(\n          \"Originalmente publicado en: Gorman KB, Williams TD, Fraser WR (2014) Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis). PLoS ONE 9(3): e90081. [doi:10.1371/journal.pone.0090081](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081)\"\n        )\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  output$plt &lt;- renderPlot({\n    ggplot(penguins, aes(x = body_mass_g, y = !!sym(input$yvar), \n                         fill = !!sym(input$color))) +\n      ggridges::geom_density_ridges(scale = 0.9, alpha = 0.5) +\n      coord_cartesian(clip = \"off\") +\n      labs(x = NULL, y = NULL) +\n      ggokabeito::scale_fill_okabe_ito() +\n      theme_minimal(base_size = 18) +\n      theme(legend.position = \"top\")\n  })\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "ejercicios/shinysurvey/index.html",
    "href": "ejercicios/shinysurvey/index.html",
    "title": "Prueba r-shinysurvey en Quarto",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(shinysurveys)\n\ndf &lt;- data.frame(question = \"¿Cuál es tu comida favorita?\",\n                 option = \"Tu respuesta\",\n                 input_type = \"text\",\n                 input_id = \"favorite_food\",\n                 dependence = NA,\n                 dependence_value = NA,\n                 required = F)\n\nui &lt;- fluidPage(\n  surveyOutput(df = df,\n               survey_title = \"Hola, ¡comida favorita!\",\n               survey_description = \"¡Bienvenido! Esta es una encuesta de prueba con el paquete {shinysurveys}.\")\n)\n\nserver &lt;- function(input, output, session) \n  {\n    renderSurvey()\n    \n    observeEvent(input$submit, \n                 {showModal(modalDialog(\n                    title = \"Felicidades, ¡completaste tu primera encuesta!\",\n                    respuesta &lt;- getSurveyData()))\n                 })\n  }\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "ejercicios/tareas/index.html#tareas",
    "href": "ejercicios/tareas/index.html#tareas",
    "title": "Control de Tareas",
    "section": "",
    "text": "Esta es la lista de tareas que hemos recibido y reunido en la carpeta que tenemos en Google Drive."
  },
  {
    "objectID": "ejercicios/stan-model/index.html",
    "href": "ejercicios/stan-model/index.html",
    "title": "Modelación con Stan",
    "section": "",
    "text": "library(rstan) library(tidyverse) rstan_options(auto_write = TRUE)\nLa modelación estadística tiene múltiples opciones actualmente. Señaladamente R, Python, Julia, Matlab, Stata y Stan que de acuerdo con su propia apreciación “es una plataforma de última generación para el modelado estadístico y el cálculo estadístico de alto rendimiento en la que confían miles de usuarios”. Stan es básicamente un lenguaje para la programación de modelos probabilísticos que permite:\nStan tiene su motor de cálculo propio, pero interactúa muy bien con los lenguajes de análisis de datos más populares (R, Python, MATLAB, etc.) y en los sistemas operativos comunes (Linux, Mac, Windows). Puedes obtener más información sobre esta propuesta de modelación estadística en la página de Stan."
  },
  {
    "objectID": "ejercicios/stan-model/index.html#preparación",
    "href": "ejercicios/stan-model/index.html#preparación",
    "title": "Modelación con Stan",
    "section": "Preparación",
    "text": "Preparación\nEl concepto que utiliza Stan parte de la especificación de las funciones de densidad que le interesan al usuario para enseguida ajustar los modelos a los datos. Un ejemplo trivial es el siguiente, en el que sólo nos proponemos estimar la media de una muestra de datos que asumiremos se distribuyen normalmente. Lo primero que hay que hacer es crear un archivo que especifique el modelo en los términos que Stan requiere. La especificación básica es la siguiente (se pueden agregar comentarios con un doble diagonal). Primero una definición del tipo de datos que requiere el modelo.\n// The input data is a vector 'y' of length 'N'.\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nEn seguida se detallan los parámetros que definen el modelo.\n// The parameters accepted by the model. Our model\n// accepts two parameters 'mu' and 'sigma'.\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nFinalmente, se especifica el modelo. El modelo completo se guarda como un archivo stan al que se llamará cuando se busque realizar el ajuste.\n// The model to be estimated. We model the output\n// 'y' to be normally distributed with mean 'mu'\n// and standard deviation 'sigma'.\nmodel {\n  y ~ normal(mu, sigma);\n}\nPara ejemplificar el uso del modelo stan ya definido arriba, sólo nos resta preparar algunos datos de prueba, activar la biblioteca rstan y realizar el ajuste, que básicamente consiste en generar un muestreo de la distribución de probabilidades. Al invocar la función stan se compila la especificación del modelo para que Stan lo pueda procesar. Una vez hecho eso, se realiza un proceso de muestreo de las distribución conjunta especificada, lo qe equivale a ajustar el modelo en Stan.\n\nlibrary(rstan)\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\nDo not specify '-march=native' in 'LOCAL_CPPFLAGS' or a Makevars file\n\nlibrary(tibble)\n\ndatos &lt;-  list(N = 1000, \n               y = rnorm(1000, 10, 2))\n               \nnorm_fit &lt;- stan(file = 'modelo.stan', data = datos)\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.027 seconds (Warm-up)\nChain 1:                0.02 seconds (Sampling)\nChain 1:                0.047 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.024 seconds (Warm-up)\nChain 2:                0.025 seconds (Sampling)\nChain 2:                0.049 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.021 seconds (Warm-up)\nChain 3:                0.022 seconds (Sampling)\nChain 3:                0.043 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 9e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.026 seconds (Warm-up)\nChain 4:                0.026 seconds (Sampling)\nChain 4:                0.052 seconds (Total)\nChain 4: \n\n\nUn objeto stanfit en R contiene los resultados derivados de ajustar (muestrear) un modelo Stan utilizando métodos Monte Carlo para cadenas de Markov (es la que se usa por default) o alguna de las aproximaciones variacionales que es capaz de procesar Stan.\nAhora podemos ver los resultados del ajuste del modelo y explorar los resultados que arroja.\n\nsummary(norm_fit)\n\n$summary\n             mean      se_mean         sd         2.5%          25%\nmu       10.00715 0.0010823094 0.06259940     9.885830     9.964565\nsigma     1.98806 0.0008053769 0.04390406     1.903333     1.958116\nlp__  -1185.62720 0.0226066435 0.95996358 -1188.252152 -1186.020689\n               50%          75%        97.5%    n_eff     Rhat\nmu       10.007650    10.049439    10.126832 3345.318 1.000056\nsigma     1.987118     2.017638     2.073372 2971.742 1.000714\nlp__  -1185.342088 -1184.931678 -1184.665979 1803.173 1.000981\n\n$c_summary\n, , chains = chain:1\n\n         stats\nparameter         mean         sd         2.5%          25%          50%\n    mu       10.009292 0.06462158     9.885574     9.964409    10.007514\n    sigma     1.988837 0.04469425     1.906092     1.957088     1.988281\n    lp__  -1185.675957 1.01096714 -1188.555107 -1186.072256 -1185.395078\n         stats\nparameter         75%        97.5%\n    mu       10.05237    10.134115\n    sigma     2.01758     2.076156\n    lp__  -1184.96437 -1184.673308\n\n, , chains = chain:2\n\n         stats\nparameter         mean         sd         2.5%          25%         50%\n    mu       10.007985 0.06337539     9.878524     9.966922    10.00983\n    sigma     1.985124 0.04435463     1.900153     1.955863     1.98428\n    lp__  -1185.653177 0.99197788 -1188.289180 -1186.040635 -1185.32826\n         stats\nparameter         75%        97.5%\n    mu       10.05028    10.133403\n    sigma     2.01586     2.069756\n    lp__  -1184.92578 -1184.668563\n\n, , chains = chain:3\n\n         stats\nparameter         mean         sd         2.5%          25%          50%\n    mu       10.005230 0.06140149     9.894950     9.962999    10.005714\n    sigma     1.990681 0.04292141     1.906485     1.962357     1.989058\n    lp__  -1185.587749 0.91275489 -1187.942888 -1186.000487 -1185.329031\n         stats\nparameter          75%        97.5%\n    mu       10.047160    10.124695\n    sigma     2.020434     2.070265\n    lp__  -1184.935847 -1184.655129\n\n, , chains = chain:4\n\n         stats\nparameter         mean         sd         2.5%          25%          50%\n    mu       10.006094 0.06094157     9.889566     9.963208    10.007646\n    sigma     1.987597 0.04350370     1.901386     1.958270     1.986921\n    lp__  -1185.591914 0.91860329 -1188.077693 -1185.943862 -1185.334421\n         stats\nparameter          75%        97.5%\n    mu       10.047540    10.120106\n    sigma     2.015515     2.075409\n    lp__  -1184.916989 -1184.668750\n\najuste &lt;- as_tibble(rstan::extract(norm_fit))\n\nhead(ajuste)\n\n# A tibble: 6 × 3\n         mu     sigma      lp__\n  &lt;dbl[1d]&gt; &lt;dbl[1d]&gt; &lt;dbl[1d]&gt;\n1      9.84      2.02    -1189.\n2      9.99      1.94    -1185.\n3     10.0       1.96    -1185.\n4     10.0       2.01    -1185.\n5      9.94      1.95    -1186.\n6      9.93      2.01    -1186.\n\nas.data.frame(norm_fit)\n\n            mu    sigma      lp__\n1    10.042354 1.940295 -1185.344\n2     9.996919 2.045284 -1185.521\n3    10.017279 2.069464 -1186.326\n4    10.013119 2.041197 -1185.401\n5    10.002930 1.980037 -1184.654\n6    10.079808 1.993329 -1185.321\n7    10.075864 1.975370 -1185.272\n8    10.042561 1.963870 -1184.925\n9     9.968702 1.973999 -1184.869\n10   10.056284 1.936298 -1185.602\n11   10.056284 1.936298 -1185.602\n12   10.049147 1.940204 -1185.415\n13   10.042377 1.921574 -1185.902\n14    9.973035 1.928917 -1185.651\n15    9.955008 2.059048 -1186.260\n16    9.938548 2.065831 -1186.732\n17    9.934025 2.045715 -1186.162\n18   10.109386 2.031405 -1186.423\n19    9.977150 2.024037 -1185.121\n20   10.081685 2.016285 -1185.560\n21   10.081685 2.016285 -1185.560\n22   10.056859 1.929668 -1185.800\n23   10.036059 1.981779 -1184.753\n24   10.067815 2.015949 -1185.325\n25    9.977008 2.051372 -1185.797\n26   10.126826 1.986404 -1186.455\n27    9.879177 1.966670 -1186.857\n28   10.208116 1.953476 -1190.194\n29   10.072222 2.009435 -1185.309\n30    9.964269 1.978329 -1184.893\n31   10.035445 1.977066 -1184.763\n32   10.123851 2.022961 -1186.650\n33   10.052554 2.018031 -1185.158\n34   10.046848 2.005762 -1184.942\n35    9.964627 1.983592 -1184.876\n36   10.086434 2.003748 -1185.508\n37    9.888988 2.003330 -1186.468\n38   10.042592 2.034629 -1185.384\n39   10.202374 2.013688 -1189.534\n40    9.868793 2.014284 -1187.214\n41   10.076314 1.946574 -1185.668\n42   10.017680 1.985187 -1184.658\n43   10.002196 1.982494 -1184.650\n44    9.946819 1.995101 -1185.127\n45   10.003910 1.970859 -1184.700\n46   10.050379 2.007328 -1184.994\n47   10.050379 2.007328 -1184.994\n48    9.928969 1.990234 -1185.424\n49    9.949416 2.032470 -1185.589\n50    9.923592 1.958960 -1185.738\n51    9.858423 1.955526 -1187.774\n52   10.156169 1.999364 -1187.465\n53   10.074788 1.951499 -1185.542\n54   10.042305 1.958900 -1184.986\n55    9.972648 1.995641 -1184.821\n56   10.046449 1.977970 -1184.854\n57    9.995494 2.006768 -1184.775\n58   10.029722 2.020174 -1185.003\n59    9.986825 1.994788 -1184.719\n60   10.052909 2.010476 -1185.057\n61    9.968492 2.043526 -1185.640\n62    9.990227 2.072963 -1186.486\n63   10.050815 1.989380 -1184.887\n64   10.042094 1.985944 -1184.798\n65   10.125187 2.010520 -1186.520\n66   10.089736 1.958118 -1185.724\n67    9.960972 2.052699 -1185.984\n68   10.080237 2.042720 -1186.075\n69   10.034082 1.979502 -1184.745\n70    9.945603 2.005620 -1185.219\n71    9.961751 2.003179 -1184.981\n72   10.033954 1.954367 -1184.988\n73    9.948803 1.976038 -1185.105\n74    9.930871 1.969605 -1185.461\n75   10.004484 1.921781 -1185.729\n76   10.029837 1.980112 -1184.716\n77   10.024283 2.038497 -1185.362\n78   10.045732 2.043670 -1185.640\n79    9.966961 1.971778 -1184.901\n80   10.029218 2.010183 -1184.856\n81    9.970886 1.963682 -1184.938\n82   10.063803 2.011914 -1185.213\n83   10.013837 2.005444 -1184.749\n84    9.969271 2.049294 -1185.797\n85    9.964136 2.045264 -1185.731\n86   10.005470 1.943742 -1185.101\n87   10.070161 1.949448 -1185.502\n88    9.981024 1.963409 -1184.859\n89   10.031053 2.014655 -1184.925\n90   10.034686 1.989669 -1184.743\n91   10.005111 2.024237 -1185.014\n92    9.916192 1.973427 -1185.747\n93    9.920279 1.969643 -1185.684\n94   10.083073 2.005372 -1185.457\n95    9.942608 1.990025 -1185.178\n96   10.024316 1.934571 -1185.367\n97   10.000307 2.002306 -1184.721\n98   10.012455 1.920535 -1185.775\n99    9.943446 1.990021 -1185.164\n100  10.058515 2.035176 -1185.563\n101  10.042680 1.920134 -1185.956\n102   9.970623 1.987437 -1184.815\n103   9.983565 1.971844 -1184.764\n104   9.988215 1.974539 -1184.721\n105   9.955151 1.988313 -1184.990\n106  10.067268 2.007365 -1185.210\n107   9.969790 1.969996 -1184.886\n108  10.068446 2.028741 -1185.557\n109  10.088729 2.043124 -1186.243\n110  10.029657 1.948892 -1185.059\n111   9.981797 2.009795 -1184.872\n112  10.112866 1.944414 -1186.559\n113   9.983729 1.962113 -1184.857\n114   9.923246 1.962158 -1185.701\n115   9.901147 1.945532 -1186.550\n116   9.974595 1.930475 -1185.589\n117  10.121288 1.982323 -1186.300\n118  10.097450 1.937983 -1186.320\n119   9.897837 1.921395 -1187.364\n120   9.976910 2.030063 -1185.243\n121   9.966340 2.021167 -1185.164\n122  10.049145 1.892578 -1187.255\n123   9.996740 1.966958 -1184.746\n124  10.039969 1.962713 -1184.916\n125   9.982578 1.992881 -1184.735\n126   9.982578 1.992881 -1184.735\n127   9.960295 2.006363 -1185.028\n128  10.044286 1.989172 -1184.821\n129   9.892844 1.982218 -1186.314\n130  10.070664 2.035855 -1185.747\n131  10.076076 2.034951 -1185.812\n132  10.013687 2.090138 -1187.200\n133   9.980387 2.098350 -1187.674\n134  10.094196 1.974580 -1185.643\n135  10.116391 1.988905 -1186.152\n136   9.974009 1.931293 -1185.570\n137  10.056759 2.014873 -1185.160\n138   9.914854 1.949637 -1186.103\n139  10.113262 1.979901 -1186.084\n140  10.078940 1.984959 -1185.296\n141  10.003305 2.055664 -1185.826\n142   9.987531 1.963848 -1184.815\n143  10.128511 1.974846 -1186.556\n144   9.939931 2.039881 -1185.908\n145   9.906089 2.067329 -1187.432\n146   9.910036 2.068238 -1187.374\n147   9.949526 1.963419 -1185.202\n148  10.038906 2.100252 -1187.801\n149  10.103339 1.989077 -1185.813\n150  10.078909 1.981273 -1185.302\n151   9.928993 1.997211 -1185.448\n152   9.972502 2.031429 -1185.307\n153   9.961333 2.063406 -1186.338\n154  10.038905 2.033927 -1185.338\n155   9.914868 2.114011 -1189.375\n156  10.007792 2.005676 -1184.746\n157  10.007792 2.005676 -1184.746\n158   9.934634 2.040853 -1186.022\n159  10.110561 1.954406 -1186.290\n160   9.839417 1.977415 -1188.264\n161   9.917571 1.971607 -1185.729\n162  10.109491 1.991734 -1185.970\n163  10.020716 1.969101 -1184.736\n164   9.969481 1.954941 -1185.073\n165   9.992075 1.871498 -1188.307\n166  10.033479 2.085432 -1187.059\n167  10.028069 2.089061 -1187.195\n168  10.045391 2.009532 -1184.968\n169   9.956416 1.928780 -1185.845\n170  10.116540 1.969490 -1186.248\n171   9.996598 1.979325 -1184.668\n172  10.095106 1.989468 -1185.622\n173  10.095106 1.989468 -1185.622\n174   9.972405 1.992245 -1184.809\n175  10.052479 2.000131 -1184.953\n176  10.010939 1.890287 -1187.135\n177  10.069431 1.917008 -1186.427\n178  10.110107 2.059209 -1187.189\n179  10.136670 2.054775 -1187.778\n180  10.062268 1.946948 -1185.430\n181   9.884241 1.943030 -1187.122\n182   9.969266 1.997524 -1184.862\n183  10.023808 1.957028 -1184.889\n184  10.012824 1.947328 -1185.028\n185   9.974340 2.021748 -1185.101\n186  10.007472 1.953955 -1184.902\n187   9.975819 2.026911 -1185.186\n188  10.025665 1.937390 -1185.298\n189  10.059413 1.922834 -1186.059\n190   9.912099 1.977577 -1185.818\n191   9.990474 1.916401 -1185.963\n192   9.988004 1.936553 -1185.325\n193  10.065237 2.059386 -1186.344\n194   9.953147 1.886158 -1187.776\n195   9.955091 1.991982 -1184.998\n196  10.049592 2.011528 -1185.034\n197  10.093887 1.993214 -1185.603\n198   9.980792 2.011934 -1184.905\n199   9.989194 1.943887 -1185.140\n200  10.087968 1.915972 -1186.828\n201   9.933133 1.970077 -1185.413\n202  10.067787 1.926795 -1186.053\n203   9.939888 2.025039 -1185.583\n204  10.036999 1.961597 -1184.905\n205  10.036999 1.961597 -1184.905\n206   9.976478 1.960235 -1184.932\n207   9.998972 1.959228 -1184.831\n208  10.068099 2.029865 -1185.575\n209  10.053689 2.027112 -1185.332\n210   9.962934 1.981581 -1184.898\n211  10.050119 1.970106 -1184.941\n212  10.014276 1.963857 -1184.770\n213  10.002002 1.987959 -1184.649\n214  10.014703 1.963646 -1184.774\n215   9.971995 2.035479 -1185.404\n216   9.982388 1.932056 -1185.482\n217   9.988309 1.934290 -1185.384\n218   9.971819 1.989174 -1184.807\n219   9.924372 2.028412 -1185.932\n220   9.919703 2.045531 -1186.432\n221   9.902379 2.113990 -1189.649\n222   9.923275 2.143242 -1190.970\n223   9.996191 1.948353 -1185.020\n224  10.005074 2.004734 -1184.738\n225  10.024667 1.995630 -1184.708\n226   9.980791 1.975688 -1184.758\n227  10.054025 1.963163 -1185.055\n228   9.973335 1.944049 -1185.246\n229  10.040920 2.012349 -1184.963\n230   9.968288 1.953303 -1185.112\n231   9.960898 2.013736 -1185.108\n232  10.058406 1.976081 -1185.001\n233  10.059173 2.019241 -1185.256\n234   9.956580 1.951005 -1185.291\n235   9.923510 1.988281 -1185.534\n236   9.923510 1.988281 -1185.534\n237  10.071305 2.036614 -1185.775\n238   9.976057 1.906104 -1186.485\n239   9.974748 1.934207 -1185.480\n240  10.050165 2.082223 -1187.050\n241  10.021124 1.919294 -1185.843\n242  10.081870 1.924731 -1186.378\n243   9.916709 2.015586 -1185.879\n244   9.959732 2.034723 -1185.509\n245   9.973814 1.962964 -1184.920\n246  10.002645 2.027756 -1185.085\n247  10.015851 1.947360 -1185.033\n248   9.990888 2.030788 -1185.179\n249   9.995553 1.951303 -1184.966\n250   9.995553 1.951303 -1184.966\n251   9.983139 1.976643 -1184.738\n252  10.145743 2.036237 -1187.583\n253  10.169550 2.044356 -1188.632\n254  10.172125 2.060615 -1189.190\n255  10.005294 2.075021 -1186.535\n256   9.905732 1.942244 -1186.501\n257   9.851536 1.932415 -1188.637\n258   9.894975 1.962199 -1186.422\n259  10.107074 2.014761 -1186.083\n260  10.105931 2.022121 -1186.165\n261  10.044839 1.975769 -1184.848\n262  10.083424 2.044063 -1186.168\n263   9.974320 2.002448 -1184.852\n264  10.016788 1.931521 -1185.427\n265  10.107166 1.918793 -1187.190\n266   9.950512 1.991181 -1185.059\n267  10.059202 1.966990 -1185.080\n268  10.158393 2.037370 -1188.049\n269   9.859482 1.937491 -1188.161\n270   9.962128 2.004913 -1184.993\n271  10.013243 2.042801 -1185.444\n272  10.026518 2.062274 -1186.093\n273   9.962799 1.952958 -1185.178\n274   9.952900 1.996546 -1185.046\n275   9.988627 2.035451 -1185.295\n276  10.018241 1.935672 -1185.314\n277   9.946497 2.012560 -1185.283\n278  10.001205 1.963285 -1184.775\n279  10.035295 2.006564 -1184.853\n280  10.021787 1.988671 -1184.673\n281  10.012789 1.993574 -1184.665\n282   9.979489 1.987634 -1184.743\n283  10.052299 1.997411 -1184.934\n284  10.030327 2.059790 -1186.025\n285   9.962835 2.033515 -1185.446\n286   9.955891 2.059938 -1186.279\n287   9.995946 1.974162 -1184.693\n288   9.994384 2.031552 -1185.183\n289  10.012669 1.974329 -1184.679\n290  10.024715 2.021574 -1185.003\n291   9.967117 1.940689 -1185.385\n292  10.053898 2.018333 -1185.178\n293   9.982525 1.960779 -1184.881\n294  10.048594 1.922749 -1185.925\n295  10.025580 1.976740 -1184.706\n296   9.992719 1.971690 -1184.720\n297  10.019695 1.962282 -1184.802\n298   9.995048 1.987152 -1184.664\n299   9.959678 2.015883 -1185.152\n300  10.044790 2.088536 -1187.282\n301  10.102362 1.915161 -1187.205\n302   9.922571 1.986965 -1185.554\n303  10.079481 1.975344 -1185.338\n304   9.979763 1.937344 -1185.355\n305  10.036330 1.987339 -1184.752\n306  10.005013 1.900575 -1186.607\n307  10.057773 1.900859 -1186.945\n308  10.076841 2.044726 -1186.071\n309   9.954947 2.013632 -1185.179\n310  10.012114 1.942972 -1185.121\n311   9.984598 2.027771 -1185.146\n312  10.002157 1.937582 -1185.252\n313  10.027062 1.962877 -1184.826\n314  10.048329 2.018924 -1185.127\n315  10.037461 2.014785 -1184.969\n316   9.985077 1.958882 -1184.891\n317  10.095357 1.989476 -1185.628\n318   9.923900 1.965806 -1185.643\n319   9.921363 2.009756 -1185.705\n320   9.891845 2.036059 -1186.875\n321   9.998114 1.928759 -1185.509\n322  10.032315 1.980187 -1184.731\n323   9.997743 1.980948 -1184.661\n324  10.034549 1.965134 -1184.846\n325   9.987799 1.985476 -1184.692\n326  10.016203 1.965640 -1184.755\n327  10.002713 1.983453 -1184.648\n328   9.981646 2.003148 -1184.805\n329  10.032889 1.965927 -1184.827\n330   9.939526 1.988229 -1185.227\n331   9.891008 1.991956 -1186.359\n332   9.911491 1.997582 -1185.831\n333   9.911491 1.997582 -1185.831\n334  10.000701 1.968804 -1184.721\n335  10.000701 1.968804 -1184.721\n336   9.937310 1.941740 -1185.795\n337  10.083052 2.010965 -1185.516\n338   9.993935 1.942811 -1185.145\n339  10.046713 1.975633 -1184.868\n340  10.031422 1.961881 -1184.863\n341   9.990674 2.005630 -1184.780\n342  10.041065 2.026463 -1185.196\n343   9.994888 1.956917 -1184.875\n344  10.065163 2.044064 -1185.875\n345  10.050721 2.042570 -1185.660\n346  10.117769 2.050328 -1187.108\n347   9.998055 1.903346 -1186.488\n348  10.080942 2.049412 -1186.274\n349  10.035659 2.048543 -1185.698\n350  10.089835 1.982049 -1185.514\n351   9.986378 1.934488 -1185.389\n352  10.011200 2.073453 -1186.473\n353  10.027504 1.983517 -1184.697\n354   9.967779 1.996432 -1184.870\n355  10.033647 1.954241 -1184.988\n356  10.033647 1.954241 -1184.988\n357   9.923698 1.938944 -1186.143\n358   9.896301 2.042618 -1186.911\n359   9.889034 2.043047 -1187.122\n360  10.058213 1.996817 -1185.002\n361   9.971786 1.966363 -1184.901\n362  10.063893 2.007715 -1185.165\n363   9.970646 2.078473 -1186.833\n364  10.046223 2.079648 -1186.902\n365  10.017150 2.032858 -1185.204\n366   9.959904 1.991873 -1184.938\n367  10.057592 2.031504 -1185.469\n368   9.999495 1.924070 -1185.657\n369  10.004977 1.992645 -1184.658\n370  10.011494 1.968622 -1184.719\n371  10.037463 2.006332 -1184.866\n372   9.981723 1.973424 -1184.765\n373  10.049025 2.000836 -1184.921\n374   9.989779 1.907213 -1186.344\n375  10.032556 2.049681 -1185.713\n376   9.994269 2.001226 -1184.728\n377  10.002260 1.960899 -1184.803\n378   9.942407 1.969476 -1185.252\n379  10.004056 2.036764 -1185.286\n380  10.090166 1.984277 -1185.517\n381   9.934210 2.011421 -1185.472\n382   9.934209 2.018417 -1185.568\n383  10.089048 1.954416 -1185.769\n384  10.054676 2.007227 -1185.041\n385  10.007000 1.929554 -1185.474\n386  10.007516 2.003242 -1184.723\n387  10.001448 1.947940 -1185.016\n388  10.005544 2.064961 -1186.146\n389  10.082639 1.978261 -1185.382\n390   9.879005 1.930886 -1187.641\n391  10.006090 2.060030 -1185.971\n392   9.987858 2.045514 -1185.560\n393  10.087099 1.980693 -1185.461\n394   9.983772 1.993436 -1184.730\n395   9.935642 2.024397 -1185.643\n396   9.883222 2.009137 -1186.691\n397  10.008508 2.026938 -1185.066\n398  10.071547 2.052558 -1186.215\n399  10.075575 1.977150 -1185.258\n400   9.927056 2.022573 -1185.770\n401   9.977967 1.985815 -1184.753\n402   9.929825 2.023190 -1185.728\n403   9.914759 2.017414 -1185.949\n404   9.898589 2.033362 -1186.633\n405   9.921128 2.037096 -1186.187\n406  10.132999 1.968244 -1186.759\n407   9.912303 1.961722 -1185.962\n408  10.101318 1.979077 -1185.783\n409  10.073345 1.989200 -1185.199\n410   9.941951 1.940625 -1185.739\n411  10.039541 2.076156 -1186.702\n412  10.008405 2.021516 -1184.965\n413   9.996452 1.932463 -1185.403\n414  10.023703 1.963082 -1184.808\n415   9.964677 2.004400 -1184.960\n416   9.949490 2.003895 -1185.145\n417   9.988490 1.994350 -1184.709\n418   9.937557 2.060046 -1186.544\n419  10.195521 1.946564 -1189.715\n420   9.943534 2.069725 -1186.799\n421   9.942836 1.993138 -1185.182\n422  10.100765 1.951630 -1186.089\n423  10.040842 1.991650 -1184.796\n424  10.050957 2.007989 -1185.007\n425  10.060331 1.906106 -1186.738\n426  10.028372 1.919385 -1185.874\n427  10.040256 1.897603 -1186.903\n428   9.970686 2.054256 -1185.938\n429  10.036013 2.005045 -1184.843\n430   9.974267 1.972337 -1184.828\n431  10.041913 2.000654 -1184.852\n432   9.968080 1.970665 -1184.898\n433   9.947913 1.961397 -1185.252\n434   9.904887 2.041340 -1186.659\n435   9.922723 2.017054 -1185.770\n436  10.073487 2.029092 -1185.642\n437   9.947753 1.927154 -1186.026\n438  10.001000 2.021822 -1184.975\n439  10.037239 1.907102 -1186.430\n440   9.903904 1.957192 -1186.246\n441   9.926667 2.014601 -1185.656\n442   9.961632 2.053101 -1185.989\n443  10.015734 1.938005 -1185.247\n444   9.927915 1.955363 -1185.703\n445   9.955332 1.975261 -1185.016\n446   9.910994 1.971900 -1185.883\n447  10.052339 1.991340 -1184.909\n448   9.968777 1.955605 -1185.069\n449   9.951320 1.924496 -1186.058\n450  10.052555 2.062612 -1186.302\n451  10.038747 2.044721 -1185.611\n452  10.038747 2.044721 -1185.611\n453   9.974312 2.083296 -1187.010\n454   9.935859 2.011335 -1185.441\n455   9.895441 2.017004 -1186.428\n456  10.024168 1.938502 -1185.263\n457   9.939847 1.986570 -1185.221\n458  10.082517 2.004403 -1185.438\n459   9.941703 1.944297 -1185.657\n460   9.941703 1.944297 -1185.657\n461   9.969545 1.911985 -1186.294\n462   9.980168 2.037228 -1185.384\n463  10.032330 1.916116 -1186.021\n464  10.018183 1.942819 -1185.137\n465   9.946665 1.940017 -1185.675\n466  10.017071 1.948559 -1185.012\n467   9.962501 1.999252 -1184.943\n468  10.030745 1.979991 -1184.722\n469  10.047117 1.974157 -1184.880\n470   9.912962 2.040676 -1186.452\n471   9.900275 2.051302 -1187.047\n472  10.110613 1.948279 -1186.411\n473   9.939685 1.947559 -1185.622\n474  10.042113 1.963403 -1184.926\n475   9.995655 1.992486 -1184.674\n476   9.970429 1.967969 -1184.898\n477  10.025914 2.028401 -1185.138\n478  10.108710 1.998463 -1185.974\n479   9.915488 1.955186 -1185.984\n480   9.954943 2.003134 -1185.064\n481   9.954943 2.003134 -1185.064\n482   9.969430 2.019926 -1185.113\n483   9.995678 2.022629 -1185.001\n484   9.983197 1.954370 -1184.971\n485  10.016743 1.959757 -1184.826\n486   9.925040 1.978576 -1185.520\n487  10.081936 2.046289 -1186.202\n488  10.087572 2.026083 -1185.834\n489  10.015162 2.014369 -1184.859\n490   9.970544 1.959469 -1184.994\n491  10.016148 2.027878 -1185.095\n492  10.173567 1.945146 -1188.723\n493   9.981630 2.065680 -1186.250\n494   9.999412 2.083896 -1186.919\n495  10.002004 1.922015 -1185.723\n496  10.042081 2.054288 -1185.923\n497  10.064649 1.989869 -1185.064\n498   9.945124 1.998324 -1185.170\n499   9.955278 1.992643 -1184.998\n500  10.055158 1.966253 -1185.035\n501   9.995800 2.006814 -1184.774\n502   9.952604 1.920313 -1186.185\n503  10.055693 2.056909 -1186.142\n504   9.964878 1.985372 -1184.872\n505  10.015630 1.945951 -1185.061\n506  10.073687 2.041993 -1185.947\n507   9.953425 1.969573 -1185.083\n508  10.062710 1.977308 -1185.054\n509   9.989985 1.924329 -1185.681\n510   9.994247 1.983042 -1184.667\n511   9.916220 1.966223 -1185.812\n512  10.044098 1.901814 -1186.735\n513  10.041026 1.947826 -1185.164\n514  10.115262 1.967082 -1186.237\n515  10.083976 1.973203 -1185.437\n516   9.989898 2.004587 -1184.773\n517  10.015413 1.967936 -1184.731\n518   9.968564 2.032570 -1185.367\n519  10.055617 1.927581 -1185.849\n520  10.086576 1.911876 -1186.964\n521  10.038782 1.923625 -1185.798\n522  10.029610 1.973013 -1184.747\n523   9.899175 2.057764 -1187.274\n524   9.983024 2.048741 -1185.679\n525   9.954755 1.935060 -1185.684\n526  10.062697 2.010657 -1185.182\n527  10.047375 2.005544 -1184.945\n528  10.047375 2.005544 -1184.945\n529   9.953736 1.977608 -1185.026\n530   9.948774 2.022861 -1185.407\n531  10.020927 1.977337 -1184.685\n532   9.915324 2.063552 -1187.088\n533   9.911681 2.056192 -1186.923\n534   9.990874 1.994581 -1184.699\n535  10.046732 1.977164 -1184.860\n536  10.016920 1.940644 -1185.184\n537  10.003584 1.986268 -1184.646\n538  10.009634 2.010584 -1184.802\n539  10.028857 2.012252 -1184.880\n540  10.081854 1.987011 -1185.349\n541  10.030979 1.958907 -1184.899\n542   9.973300 1.979595 -1184.800\n543  10.021093 1.935610 -1185.325\n544   9.967435 2.040176 -1185.561\n545  10.035177 1.968314 -1184.820\n546   9.945941 2.035018 -1185.697\n547  10.064899 1.972171 -1185.116\n548  10.011042 1.956042 -1184.870\n549  10.011042 1.956042 -1184.870\n550  10.056684 1.970975 -1185.012\n551  10.076885 2.029971 -1185.716\n552  10.021277 1.997787 -1184.707\n553  10.000746 1.990380 -1184.656\n554  10.037780 1.975084 -1184.791\n555  10.037780 1.975084 -1184.791\n556  10.042593 1.978559 -1184.815\n557  10.046376 2.010780 -1184.993\n558  10.002484 1.984808 -1184.647\n559  10.074472 1.984374 -1185.217\n560  10.015364 2.024414 -1185.025\n561  10.137461 1.948815 -1187.225\n562   9.962332 1.871831 -1188.540\n563  10.017474 1.910427 -1186.178\n564   9.991288 2.060426 -1186.015\n565  10.021224 1.970261 -1184.728\n566   9.996343 1.961341 -1184.810\n567  10.009852 2.031579 -1185.165\n568  10.086262 1.983164 -1185.438\n569   9.946726 1.988563 -1185.110\n570   9.946726 1.988563 -1185.110\n571  10.030174 1.921627 -1185.804\n572   9.986687 2.112271 -1188.370\n573   9.966898 2.008941 -1184.984\n574  10.008490 2.005400 -1184.744\n575   9.977226 1.992008 -1184.769\n576  10.002700 2.003554 -1184.729\n577  10.006023 1.966848 -1184.733\n578   9.884763 1.982389 -1186.557\n579  10.045391 2.055015 -1185.975\n580  10.040754 2.066231 -1186.324\n581  10.021288 1.971772 -1184.717\n582  10.055510 2.002989 -1185.011\n583   9.970043 1.986678 -1184.820\n584   9.837415 2.024074 -1188.533\n585   9.991047 2.031894 -1185.203\n586   9.884621 1.961080 -1186.754\n587  10.021845 1.946406 -1185.071\n588   9.967885 2.016969 -1185.081\n589  10.101635 2.054206 -1186.832\n590  10.009880 2.031052 -1185.153\n591  10.090093 1.990468 -1185.516\n592  10.108302 1.996177 -1185.953\n593  10.102356 2.041459 -1186.488\n594  10.098980 2.053389 -1186.748\n595   9.924413 1.984357 -1185.517\n596   9.994782 1.979209 -1184.674\n597  10.092931 1.951486 -1185.907\n598   9.898553 1.946646 -1186.598\n599  10.094079 2.041173 -1186.300\n600  10.018967 1.935756 -1185.314\n601  10.110208 2.035006 -1186.521\n602   9.885577 1.983679 -1186.527\n603  10.010839 1.928098 -1185.520\n604  10.025996 2.010417 -1184.842\n605  10.010641 1.999338 -1184.694\n606   9.998882 1.952045 -1184.944\n607  10.010924 2.003174 -1184.724\n608  10.006035 1.938638 -1185.221\n609   9.998808 2.049443 -1185.638\n610   9.968614 2.016853 -1185.072\n611   9.862893 1.998571 -1187.298\n612   9.987228 2.037008 -1185.339\n613  10.088708 2.008515 -1185.598\n614  10.082310 2.002649 -1185.420\n615   9.931205 1.953315 -1185.671\n616   9.946844 1.965693 -1185.217\n617  10.012064 1.973794 -1184.682\n618  10.039778 2.013327 -1184.967\n619   9.952419 1.987257 -1185.026\n620   9.963517 2.011551 -1185.050\n621   9.932929 1.910475 -1186.919\n622  10.083557 2.024075 -1185.721\n623  10.116836 2.033970 -1186.668\n624  10.073885 1.957108 -1185.431\n625   9.990779 1.984236 -1184.679\n626  10.012789 1.979446 -1184.657\n627   9.946467 2.037219 -1185.741\n628  10.125693 2.071680 -1188.034\n629   9.889808 1.924343 -1187.504\n630   9.961729 1.995852 -1184.932\n631   9.992429 1.957144 -1184.880\n632   9.964898 2.026801 -1185.282\n633  10.052558 1.968400 -1184.983\n634  10.062311 1.956286 -1185.260\n635   9.920726 1.998335 -1185.624\n636  10.106594 2.014446 -1186.067\n637  10.115763 2.012281 -1186.276\n638   9.948989 1.996987 -1185.104\n639   9.926212 2.006359 -1185.570\n640  10.001846 1.994386 -1184.668\n641   9.983943 1.918399 -1185.924\n642   9.998762 1.905541 -1186.386\n643  10.121103 1.988680 -1186.284\n644  10.020091 1.979711 -1184.673\n645   9.996549 1.997495 -1184.695\n646  10.049879 1.954427 -1185.131\n647  10.118931 1.995496 -1186.234\n648   9.964456 1.935185 -1185.557\n649   9.930507 1.917709 -1186.677\n650   9.930429 1.928103 -1186.313\n651  10.033704 2.032589 -1185.271\n652  10.005380 2.017463 -1184.898\n653   9.951002 1.992872 -1185.057\n654   9.988230 1.962443 -1184.828\n655  10.067195 2.016278 -1185.321\n656   9.915449 1.990480 -1185.715\n657  10.056309 1.959046 -1185.137\n658   9.897716 2.040751 -1186.827\n659   9.870421 2.034704 -1187.498\n660  10.107380 2.012040 -1186.057\n661  10.057155 1.955633 -1185.200\n662   9.920480 2.003739 -1185.666\n663  10.001511 2.023101 -1184.997\n664  10.018474 1.963539 -1184.784\n665  10.033698 2.037885 -1185.396\n666  10.002402 2.008459 -1184.779\n667  10.007977 1.984046 -1184.645\n668  10.006262 1.951732 -1184.940\n669  10.089470 1.996405 -1185.522\n670  10.128344 1.994336 -1186.506\n671  10.142479 1.994312 -1186.961\n672   9.885458 1.999933 -1186.552\n673   9.961717 2.030578 -1185.394\n674  10.151598 1.966133 -1187.433\n675  10.088228 1.975967 -1185.506\n676  10.005935 1.998104 -1184.685\n677   9.862355 1.892001 -1189.975\n678   9.942731 1.979100 -1185.186\n679   9.942731 1.979100 -1185.186\n680  10.108912 1.874117 -1189.571\n681  10.115008 1.863731 -1190.485\n682   9.991113 1.911760 -1186.144\n683  10.020673 1.952792 -1184.945\n684   9.976660 2.016533 -1184.999\n685   9.993704 1.940172 -1185.208\n686  10.015194 2.012374 -1184.832\n687  10.004443 2.001260 -1184.708\n688   9.944896 1.986757 -1185.138\n689   9.955549 1.996987 -1185.013\n690  10.038785 2.109692 -1188.293\n691  10.044475 2.090320 -1187.362\n692   9.910265 1.977181 -1185.866\n693  10.073388 2.002791 -1185.264\n694   9.980088 1.948773 -1185.093\n695  10.085900 1.946845 -1185.849\n696   9.943815 1.949908 -1185.503\n697  10.066842 2.051511 -1186.114\n698  10.072252 2.040008 -1185.873\n699   9.945791 1.959184 -1185.315\n700  10.005701 1.962805 -1184.777\n701  10.067252 1.983356 -1185.102\n702  10.093500 2.011889 -1185.736\n703   9.927730 1.940029 -1186.028\n704  10.057731 2.072023 -1186.711\n705  10.047391 2.066117 -1186.377\n706  10.044726 2.076259 -1186.748\n707   9.956271 1.905206 -1186.749\n708  10.072864 2.052503 -1186.233\n709   9.964058 1.938283 -1185.479\n710  10.021415 2.049407 -1185.652\n711   9.908420 2.039218 -1186.521\n712   9.997084 2.058946 -1185.946\n713   9.940308 1.971780 -1185.269\n714   9.947415 2.037221 -1185.728\n715  10.067161 1.914773 -1186.476\n716  10.080820 1.873286 -1188.925\n717   9.942525 2.107800 -1188.552\n718  10.082714 1.944921 -1185.826\n719   9.990102 2.069020 -1186.332\n720  10.057910 1.949030 -1185.327\n721   9.893824 2.012003 -1186.410\n722   9.973485 2.030998 -1185.290\n723  10.004250 1.956095 -1184.869\n724   9.958835 1.979687 -1184.952\n725  10.025826 2.009699 -1184.833\n726   9.985132 1.974107 -1184.740\n727  10.004380 2.021277 -1184.961\n728   9.899831 2.074279 -1187.847\n729  10.128978 1.947807 -1186.966\n730   9.884634 2.015429 -1186.719\n731   9.946201 1.952374 -1185.418\n732  10.059678 2.027407 -1185.409\n733   9.945719 1.932671 -1185.889\n734   9.840372 1.943169 -1188.803\n735   9.842250 1.961068 -1188.339\n736  10.079920 1.921869 -1186.439\n737   9.961208 2.110008 -1188.437\n738   9.962197 1.954211 -1185.164\n739  10.095421 1.998884 -1185.661\n740  10.065060 1.964296 -1185.192\n741  10.017438 1.981716 -1184.661\n742  10.066123 1.949705 -1185.432\n743  10.010204 1.990243 -1184.651\n744  10.032651 2.041765 -1185.489\n745   9.997801 1.938647 -1185.233\n746  10.058550 2.034392 -1185.545\n747  10.036210 2.025331 -1185.137\n748   9.957541 1.984633 -1184.958\n749   9.946361 1.986483 -1185.115\n750  10.078550 1.983844 -1185.290\n751  10.066177 1.976484 -1185.108\n752   9.957748 2.012715 -1185.132\n753   9.985054 1.959884 -1184.877\n754  10.095669 2.061267 -1186.933\n755   9.925726 1.941932 -1186.024\n756  10.105676 2.015168 -1186.055\n757  10.138104 1.992138 -1186.811\n758  10.182444 1.966004 -1188.710\n759  10.129059 1.962968 -1186.698\n760  10.171900 1.946707 -1188.611\n761  10.014585 1.914329 -1186.012\n762  10.030265 1.928288 -1185.583\n763  10.069380 1.917397 -1186.411\n764  10.020161 2.030288 -1185.156\n765   9.992494 2.018548 -1184.942\n766  10.023573 1.923491 -1185.705\n767  10.002528 2.035502 -1185.257\n768  10.010004 1.917023 -1185.902\n769  10.006180 1.930448 -1185.447\n770   9.960004 1.972154 -1184.977\n771   9.976168 1.979841 -1184.776\n772  10.049738 2.016234 -1185.100\n773   9.881428 1.905617 -1188.554\n774  10.047956 2.022879 -1185.191\n775  10.070799 2.048408 -1186.079\n776  10.023326 1.975417 -1184.703\n777  10.049089 1.989947 -1184.870\n778   9.999665 1.968781 -1184.723\n779  10.098370 1.861704 -1190.159\n780  10.049990 2.013097 -1185.059\n781   9.938588 1.974362 -1185.281\n782  10.063875 2.059866 -1186.342\n783  10.062863 2.071319 -1186.747\n784   9.933924 2.064459 -1186.759\n785  10.112319 1.931225 -1186.902\n786   9.933976 2.076160 -1187.205\n787   9.963501 2.073464 -1186.695\n788  10.062349 1.906382 -1186.755\n789   9.950601 2.046225 -1185.919\n790  10.071206 1.918425 -1186.403\n791   9.850859 2.004990 -1187.783\n792  10.036423 2.071501 -1186.493\n793  10.018048 2.061284 -1186.028\n794  10.002810 1.999766 -1184.698\n795   9.902893 2.031342 -1186.479\n796  10.010042 1.943262 -1185.112\n797  10.000661 2.006801 -1184.763\n798  10.095852 1.947800 -1186.048\n799   9.998341 2.014875 -1184.869\n800   9.976091 2.024715 -1185.142\n801  10.051666 1.956517 -1185.118\n802  10.051666 1.956517 -1185.118\n803   9.979439 1.931695 -1185.514\n804   9.988909 1.983795 -1184.688\n805   9.908219 1.994758 -1185.899\n806  10.112648 2.000581 -1186.088\n807  10.046119 2.068685 -1186.461\n808   9.926360 2.007048 -1185.574\n809   9.931176 1.989027 -1185.380\n810  10.048987 2.020373 -1185.158\n811   9.906473 1.972232 -1185.995\n812   9.936863 1.933023 -1186.035\n813  10.013946 1.972878 -1184.690\n814   9.990320 1.999283 -1184.728\n815  10.032337 1.953057 -1184.999\n816  10.032337 1.953057 -1184.999\n817  10.022253 1.974246 -1184.705\n818  10.065754 2.014942 -1185.280\n819  10.095798 1.944342 -1186.123\n820  10.042015 1.989987 -1184.802\n821   9.948980 1.947811 -1185.462\n822  10.129673 2.010471 -1186.652\n823  10.024627 2.007728 -1184.805\n824  10.007512 1.967416 -1184.727\n825  10.020329 2.025947 -1185.067\n826  10.000126 1.934392 -1185.340\n827  10.056766 1.939408 -1185.527\n828  10.107101 2.058566 -1187.096\n829   9.958896 1.903639 -1186.785\n830   9.981548 1.924235 -1185.733\n831   9.980526 1.914462 -1186.098\n832   9.923261 2.012067 -1185.692\n833  10.073099 1.951966 -1185.504\n834  10.004334 2.004726 -1184.738\n835   9.944923 1.998875 -1185.176\n836  10.014867 2.008635 -1184.785\n837  10.091002 1.979473 -1185.547\n838  10.010202 1.998243 -1184.686\n839   9.991508 2.006541 -1184.786\n840  10.078381 2.021881 -1185.589\n841  10.088710 2.034351 -1186.028\n842   9.998777 1.967898 -1184.732\n843   9.964597 2.062963 -1186.288\n844  10.047739 1.909444 -1186.430\n845   9.975413 2.062734 -1186.185\n846  10.061956 1.933681 -1185.753\n847  10.000061 1.968405 -1184.725\n848  10.059596 2.033130 -1185.529\n849   9.958929 1.937085 -1185.573\n850   9.958929 1.937085 -1185.573\n851  10.061278 1.946309 -1185.429\n852   9.948956 1.996261 -1185.101\n853  10.041136 2.001124 -1184.849\n854   9.978494 1.994324 -1184.768\n855  10.057647 2.021282 -1185.271\n856   9.945818 1.968330 -1185.207\n857  10.075667 2.001714 -1185.294\n858  10.077170 2.022194 -1185.573\n859  10.072225 2.016953 -1185.408\n860   9.944938 1.946565 -1185.553\n861   9.985558 1.918100 -1185.925\n862  10.058896 1.976604 -1185.005\n863   9.974781 1.979350 -1184.788\n864  10.037500 2.076321 -1186.694\n865   9.910337 1.959040 -1186.049\n866   9.955310 1.967087 -1185.080\n867  10.047612 1.985605 -1184.850\n868  10.047612 1.985605 -1184.850\n869   9.941326 2.017933 -1185.439\n870  10.022475 1.937443 -1185.282\n871   9.905492 2.034342 -1186.479\n872  10.110290 1.975893 -1186.026\n873   9.959184 1.937980 -1185.546\n874  10.022722 2.063606 -1186.125\n875   9.959843 1.935134 -1185.614\n876  10.059491 2.024499 -1185.351\n877  10.040388 2.033250 -1185.334\n878   9.976070 1.956559 -1184.988\n879   9.969040 1.926318 -1185.772\n880  10.048842 1.970453 -1184.924\n881   9.965928 1.925812 -1185.822\n882  10.034894 1.977663 -1184.757\n883   9.998039 2.029779 -1185.135\n884   9.939839 2.025663 -1185.596\n885   9.945655 1.960305 -1185.302\n886   9.908753 1.956748 -1186.126\n887  10.105990 2.002773 -1185.934\n888  10.094409 2.003845 -1185.674\n889  10.159314 2.007133 -1187.630\n890  10.152781 2.016407 -1187.484\n891   9.983558 1.908704 -1186.314\n892  10.032009 2.013956 -1184.921\n893  10.011646 2.013299 -1184.839\n894   9.983527 1.978689 -1184.728\n895   9.974566 1.920852 -1185.906\n896   9.998295 2.072036 -1186.424\n897  10.110577 2.051419 -1186.957\n898  10.096666 1.982164 -1185.663\n899   9.970969 1.953829 -1185.077\n900   9.987658 1.901103 -1186.634\n901   9.979992 1.922487 -1185.804\n902  10.079935 1.988878 -1185.314\n903  10.028569 1.994226 -1184.721\n904   9.980872 1.960483 -1184.896\n905  10.026331 1.939938 -1185.237\n906  10.073912 2.006582 -1185.307\n907  10.044674 2.081739 -1186.978\n908   9.952860 1.901571 -1186.969\n909   9.967996 1.930889 -1185.641\n910   9.967996 1.930889 -1185.641\n911  10.088506 2.014912 -1185.671\n912   9.934471 2.036576 -1185.919\n913   9.937255 2.060828 -1186.576\n914   9.945740 1.995594 -1185.146\n915  10.050143 1.962575 -1185.017\n916  10.056914 1.957716 -1185.164\n917   9.971020 2.086072 -1187.160\n918  10.051206 2.025790 -1185.278\n919   9.949958 1.915320 -1186.414\n920   9.946036 1.922286 -1186.218\n921   9.911585 1.949587 -1186.185\n922  10.074295 1.891943 -1187.671\n923  10.100204 1.884195 -1188.693\n924  10.020538 1.973928 -1184.700\n925  10.004695 1.972022 -1184.691\n926  10.012901 1.987060 -1184.649\n927   9.980403 1.956774 -1184.952\n928  10.117009 1.988888 -1186.169\n929  10.091357 2.004779 -1185.617\n930  10.134050 1.949116 -1187.103\n931   9.854547 2.037800 -1188.119\n932  10.148336 1.974496 -1187.226\n933   9.901124 2.002882 -1186.125\n934  10.075415 1.992627 -1185.242\n935   9.939295 2.011217 -1185.381\n936  10.025803 2.004564 -1184.778\n937  10.025803 2.004564 -1184.778\n938  10.088789 1.938604 -1186.106\n939  10.079750 1.958594 -1185.515\n940   9.995007 2.021007 -1184.974\n941   9.986848 1.960084 -1184.865\n942   9.985677 1.962358 -1184.842\n943  10.013789 1.998373 -1184.691\n944  10.009042 2.005827 -1184.748\n945   9.999744 1.988801 -1184.654\n946   9.978538 1.932791 -1185.489\n947  10.127721 1.962490 -1186.663\n948  10.037012 1.943427 -1185.224\n949   9.911983 2.055574 -1186.896\n950   9.962808 1.883962 -1187.770\n951  10.138259 2.098192 -1189.532\n952  10.201420 2.057356 -1190.332\n953   9.916865 2.007539 -1185.780\n954  10.021064 2.039381 -1185.373\n955   9.947359 1.966058 -1185.205\n956   9.958576 1.992092 -1184.954\n957  10.096819 1.987818 -1185.660\n958  10.018573 1.940268 -1185.198\n959  10.004117 2.004958 -1184.741\n960  10.012605 1.968142 -1184.724\n961  10.039109 2.015611 -1184.994\n962  10.051465 1.954926 -1185.141\n963   9.989223 2.045983 -1185.567\n964  10.002548 1.954400 -1184.897\n965  10.115108 2.004962 -1186.185\n966  10.025089 2.025472 -1185.076\n967   9.985122 1.941004 -1185.228\n968  10.002044 2.036731 -1185.287\n969  10.118302 1.980432 -1186.221\n970  10.121934 1.978830 -1186.333\n971  10.155153 1.970511 -1187.516\n972   9.862484 1.982984 -1187.312\n973   9.876016 1.988140 -1186.826\n974  10.012633 2.022409 -1184.984\n975  10.104280 1.965088 -1185.969\n976   9.981690 1.938643 -1185.308\n977  10.056268 2.012390 -1185.120\n978  10.020161 1.987344 -1184.666\n979  10.009055 1.994868 -1184.667\n980  10.011951 1.996366 -1184.677\n981  10.012273 1.983922 -1184.648\n982  10.028589 2.005628 -1184.802\n983   9.930398 1.988468 -1185.394\n984   9.974241 2.015080 -1184.996\n985   9.992463 1.974491 -1184.703\n986   9.972811 1.985600 -1184.795\n987  10.061117 1.958407 -1185.211\n988  10.044357 1.941574 -1185.332\n989  10.068099 2.036388 -1185.721\n990  10.081722 1.969436 -1185.424\n991   9.950612 2.031803 -1185.558\n992  10.184518 1.887300 -1191.708\n993  10.190843 1.954129 -1189.310\n994  10.205263 2.037897 -1190.031\n995   9.834488 1.938833 -1189.188\n996  10.082955 1.998498 -1185.404\n997   9.919901 2.004395 -1185.684\n998  10.016250 2.014508 -1184.863\n999   9.995735 1.938257 -1185.249\n1000  9.913751 1.962931 -1185.910\n1001  9.945085 1.968825 -1185.214\n1002 10.038563 2.010037 -1184.916\n1003 10.052395 1.996562 -1184.930\n1004 10.097518 1.960514 -1185.864\n1005 10.121238 1.965939 -1186.421\n1006  9.940888 2.071814 -1186.920\n1007  9.918757 2.084514 -1187.841\n1008 10.039675 2.016706 -1185.015\n1009  9.975738 2.009681 -1184.914\n1010 10.045613 1.980791 -1184.837\n1011  9.966239 2.022335 -1185.185\n1012 10.048670 1.949221 -1185.212\n1013  9.964394 2.024740 -1185.248\n1014  9.980187 1.968528 -1184.812\n1015 10.032104 1.993170 -1184.737\n1016  9.936551 2.006867 -1185.380\n1017 10.034599 2.033660 -1185.301\n1018  9.991176 2.030624 -1185.174\n1019  9.996711 1.950233 -1184.982\n1020 10.088105 1.984312 -1185.474\n1021 10.031183 2.036009 -1185.335\n1022  9.996336 1.961839 -1184.803\n1023  9.997269 1.958779 -1184.841\n1024 10.069386 1.969083 -1185.210\n1025  9.946136 2.001764 -1185.178\n1026 10.004677 1.983307 -1184.646\n1027 10.006586 2.003128 -1184.722\n1028 10.097732 1.952185 -1186.005\n1029  9.850135 2.009027 -1187.842\n1030  9.938766 2.014481 -1185.432\n1031 10.008509 1.913828 -1186.025\n1032 10.093369 1.965361 -1185.707\n1033  9.941547 1.972957 -1185.239\n1034  9.954945 1.936120 -1185.652\n1035  9.970092 1.938301 -1185.414\n1036  9.987780 1.978419 -1184.705\n1037 10.003894 1.904294 -1186.434\n1038 10.003894 1.904294 -1186.434\n1039  9.933058 1.897338 -1187.530\n1040  9.959445 1.968717 -1185.011\n1041  9.882254 1.977355 -1186.660\n1042 10.072177 2.049334 -1186.127\n1043 10.091010 2.045874 -1186.362\n1044 10.034205 2.100670 -1187.791\n1045 10.050064 1.985235 -1184.876\n1046  9.993543 1.992225 -1184.680\n1047 10.021451 1.984911 -1184.670\n1048  9.949398 2.041055 -1185.796\n1049 10.053381 1.936342 -1185.564\n1050 10.012858 1.976465 -1184.669\n1051  9.985973 2.004786 -1184.794\n1052  9.988936 2.018600 -1184.957\n1053 10.005000 2.057445 -1185.884\n1054 10.038089 2.016783 -1185.004\n1055 10.059540 1.985701 -1184.990\n1056 10.025309 1.991285 -1184.694\n1057 10.076867 1.974345 -1185.296\n1058 10.086083 2.005809 -1185.519\n1059 10.005306 2.045557 -1185.517\n1060  9.882487 1.955459 -1186.914\n1061 10.013493 1.968815 -1184.720\n1062 10.009985 2.031882 -1185.171\n1063 10.001454 1.956671 -1184.863\n1064  9.918558 1.974494 -1185.684\n1065  9.891474 1.966154 -1186.475\n1066 10.122406 2.012597 -1186.463\n1067 10.059158 2.019284 -1185.256\n1068 10.087592 2.007736 -1185.568\n1069  9.895039 1.949968 -1186.629\n1070  9.890488 2.042863 -1187.076\n1071 10.045051 1.994262 -1184.843\n1072 10.083920 1.969595 -1185.465\n1073  9.992660 2.000924 -1184.731\n1074 10.081729 2.005302 -1185.432\n1075  9.982752 2.010027 -1184.869\n1076 10.003021 2.023217 -1184.997\n1077 10.047017 1.933564 -1185.567\n1078 10.047549 1.946073 -1185.264\n1079  9.977041 2.039650 -1185.467\n1080  9.966927 2.030067 -1185.329\n1081  9.942239 1.915425 -1186.539\n1082  9.953840 1.968732 -1185.084\n1083  9.976189 1.982327 -1184.770\n1084 10.094077 1.962554 -1185.757\n1085 10.060281 1.957344 -1185.215\n1086 10.078181 1.957420 -1185.503\n1087  9.978639 2.003909 -1184.832\n1088  9.977380 1.989986 -1184.762\n1089  9.960963 1.995715 -1184.940\n1090 10.075740 1.993581 -1185.250\n1091 10.020126 1.942233 -1185.156\n1092 10.039428 2.007310 -1184.891\n1093  9.900421 1.999843 -1186.124\n1094 10.091289 1.923048 -1186.638\n1095 10.137684 1.963437 -1186.974\n1096 10.162766 1.939892 -1188.402\n1097  9.982634 2.048930 -1185.687\n1098  9.863471 2.026015 -1187.568\n1099 10.145382 1.951253 -1187.453\n1100 10.032923 1.945114 -1185.157\n1101 10.119319 2.005925 -1186.308\n1102  9.958692 1.919293 -1186.137\n1103 10.041223 1.876179 -1188.131\n1104  9.950627 1.999339 -1185.094\n1105  9.966411 1.967355 -1184.944\n1106 10.039339 2.015571 -1184.995\n1107  9.972921 1.957073 -1185.007\n1108 10.033867 1.945604 -1185.153\n1109 10.037919 1.927668 -1185.658\n1110 10.013539 1.934000 -1185.349\n1111 10.038933 1.998226 -1184.811\n1112  9.975158 1.974761 -1184.806\n1113 10.043766 1.998651 -1184.854\n1114  9.928364 2.000448 -1185.479\n1115  9.912657 1.977765 -1185.804\n1116 10.022970 1.983392 -1184.676\n1117 10.016874 1.920390 -1185.789\n1118 10.197194 1.995895 -1189.198\n1119 10.029397 1.944562 -1185.147\n1120 10.002680 1.935984 -1185.293\n1121 10.016719 2.005270 -1184.753\n1122  9.969210 1.924532 -1185.829\n1123  9.996797 1.910925 -1186.158\n1124 10.005143 1.948152 -1185.008\n1125  9.967807 2.025433 -1185.227\n1126 10.008201 1.986606 -1184.645\n1127  9.983972 1.962748 -1184.847\n1128 10.102683 2.014036 -1185.968\n1129 10.075525 1.993091 -1185.245\n1130  9.957909 1.933645 -1185.680\n1131  9.995303 1.961518 -1184.810\n1132 10.070050 1.921447 -1186.273\n1133  9.987492 2.065203 -1186.201\n1134  9.982128 1.911423 -1186.209\n1135 10.064768 1.976899 -1185.085\n1136 10.024679 1.986913 -1184.683\n1137 10.000507 1.953057 -1184.923\n1138  9.998571 1.997071 -1184.688\n1139  9.969284 2.058451 -1186.087\n1140 10.043701 1.916360 -1186.107\n1141 10.120142 1.976354 -1186.295\n1142  9.893318 1.995895 -1186.302\n1143  9.927791 1.917991 -1186.724\n1144  9.863050 1.980083 -1187.305\n1145 10.155690 1.993720 -1187.431\n1146 10.079460 2.017854 -1185.543\n1147 10.023714 1.937036 -1185.298\n1148  9.967669 1.996195 -1184.870\n1149 10.017496 1.964951 -1184.766\n1150  9.949817 2.023580 -1185.405\n1151  9.889247 1.999638 -1186.437\n1152  9.885512 1.981307 -1186.537\n1153 10.179391 1.963684 -1188.606\n1154 10.048447 1.941226 -1185.383\n1155 10.064562 1.960837 -1185.227\n1156 10.035097 2.037263 -1185.390\n1157  9.952001 1.991288 -1185.038\n1158  9.962148 1.994912 -1184.923\n1159  9.970644 1.909536 -1186.386\n1160 10.011839 1.942519 -1185.131\n1161 10.100430 1.965660 -1185.867\n1162  9.918766 1.958085 -1185.860\n1163  9.917967 2.023954 -1185.983\n1164 10.013832 2.042712 -1185.443\n1165 10.022908 2.059170 -1185.970\n1166  9.952473 1.956813 -1185.249\n1167 10.020958 1.980463 -1184.674\n1168 10.070077 1.964381 -1185.269\n1169 10.033266 2.021744 -1185.051\n1170 10.118800 2.032875 -1186.697\n1171 10.074195 2.039945 -1185.902\n1172  9.970357 2.004545 -1184.905\n1173  9.935878 1.994092 -1185.304\n1174  9.930334 1.995919 -1185.415\n1175  9.950922 1.981672 -1185.052\n1176  9.931987 1.976996 -1185.388\n1177  9.922031 2.004498 -1185.640\n1178  9.925166 1.968176 -1185.591\n1179 10.002409 1.987898 -1184.649\n1180  9.979344 1.928869 -1185.600\n1181  9.940122 1.959469 -1185.406\n1182  9.930091 1.952936 -1185.700\n1183 10.001254 1.983048 -1184.650\n1184 10.037642 1.917460 -1186.010\n1185 10.071123 1.970619 -1185.225\n1186 10.076525 1.978645 -1185.268\n1187 10.122866 2.010901 -1186.457\n1188 10.014292 1.949490 -1184.988\n1189  9.987661 1.966066 -1184.790\n1190 10.066419 1.973288 -1185.131\n1191 10.020078 1.890329 -1187.154\n1192 10.014390 1.907033 -1186.316\n1193  9.982286 2.031580 -1185.240\n1194 10.013149 2.009495 -1184.792\n1195  9.945767 2.005798 -1185.218\n1196  9.916244 2.001912 -1185.746\n1197 10.002903 1.967807 -1184.726\n1198 10.004013 1.957802 -1184.843\n1199 10.054571 1.957884 -1185.132\n1200  9.984262 1.987183 -1184.712\n1201 10.058425 2.010175 -1185.120\n1202  9.944540 2.003577 -1185.217\n1203 10.073649 2.034247 -1185.756\n1204 10.073847 2.060783 -1186.518\n1205 10.067360 2.094613 -1187.819\n1206  9.930424 1.900165 -1187.444\n1207 10.043666 1.961314 -1184.966\n1208  9.971423 1.981361 -1184.812\n1209 10.056703 1.948664 -1185.319\n1210 10.079311 1.979960 -1185.313\n1211 10.133381 2.036187 -1187.188\n1212 10.066160 1.969039 -1185.160\n1213 10.002303 1.990508 -1184.654\n1214 10.002537 1.989890 -1184.652\n1215 10.031393 1.988623 -1184.720\n1216 10.017789 1.994211 -1184.677\n1217  9.996588 1.977838 -1184.673\n1218  9.994519 2.033005 -1185.216\n1219  9.985645 2.023840 -1185.064\n1220  9.979187 1.963393 -1184.872\n1221  9.934077 2.013563 -1185.501\n1222 10.073132 2.009223 -1185.322\n1223 10.080177 1.949163 -1185.687\n1224 10.050243 1.947817 -1185.257\n1225 10.051261 1.970256 -1184.952\n1226  9.949064 1.974765 -1185.108\n1227 10.026228 1.989610 -1184.694\n1228 10.020127 1.976187 -1184.687\n1229  9.994246 1.995826 -1184.693\n1230  9.969937 2.028040 -1185.258\n1231  9.963623 1.950646 -1185.210\n1232 10.000059 1.946088 -1185.056\n1233  9.971185 1.924140 -1185.823\n1234  9.974469 1.985248 -1184.781\n1235 10.116796 1.875927 -1189.688\n1236 10.086907 1.897793 -1187.622\n1237  9.996873 2.078294 -1186.682\n1238  9.979069 1.925331 -1185.715\n1239  9.931342 1.905482 -1187.173\n1240  9.939438 1.880133 -1188.372\n1241 10.084568 2.046175 -1186.247\n1242 10.018749 1.958463 -1184.850\n1243 10.059085 1.966984 -1185.078\n1244 10.068023 1.958390 -1185.314\n1245  9.992849 1.947414 -1185.050\n1246  9.991180 1.985318 -1184.677\n1247 10.028109 1.962091 -1184.841\n1248  9.955937 2.013606 -1185.166\n1249 10.030770 1.947839 -1185.086\n1250 10.000740 1.954574 -1184.897\n1251 10.018824 2.019911 -1184.953\n1252 10.035457 2.025326 -1185.131\n1253  9.988475 1.980627 -1184.695\n1254 10.082767 2.024848 -1185.720\n1255 10.086902 2.023805 -1185.779\n1256 10.008116 1.987123 -1184.645\n1257  9.961038 1.995293 -1184.937\n1258 10.008783 2.051712 -1185.699\n1259  9.968427 2.000027 -1184.886\n1260 10.048026 1.970654 -1184.914\n1261 10.041573 1.972735 -1184.836\n1262 10.099843 1.969377 -1185.814\n1263  9.993029 2.013989 -1184.871\n1264 10.042427 1.939835 -1185.355\n1265  9.974314 2.031563 -1185.295\n1266 10.090131 1.948209 -1185.910\n1267  9.974195 2.025517 -1185.172\n1268  9.993330 1.996686 -1184.700\n1269 10.056923 1.976866 -1184.978\n1270 10.069707 1.975303 -1185.169\n1271 10.098850 1.990512 -1185.708\n1272 10.056731 1.931617 -1185.740\n1273 10.060864 2.044916 -1185.841\n1274 10.164373 1.989371 -1187.765\n1275 10.063859 1.998540 -1185.088\n1276  9.881676 2.027835 -1187.003\n1277  9.844123 2.027005 -1188.308\n1278 10.097027 2.035005 -1186.214\n1279 10.166467 1.953439 -1188.230\n1280 10.039226 1.953803 -1185.038\n1281  9.998930 1.988159 -1184.655\n1282 10.026022 1.921425 -1185.788\n1283 10.051076 2.048288 -1185.824\n1284 10.023016 1.953626 -1184.940\n1285  9.933599 1.989725 -1185.335\n1286  9.992377 2.020133 -1184.968\n1287  9.973742 1.945137 -1185.218\n1288 10.028491 1.999452 -1184.750\n1289 10.038117 1.977452 -1184.782\n1290  9.910073 1.911978 -1187.393\n1291  9.962870 1.942527 -1185.389\n1292 10.016273 1.968449 -1184.729\n1293  9.966377 1.997343 -1184.890\n1294  9.994019 2.020363 -1184.966\n1295 10.016883 1.971606 -1184.705\n1296 10.014734 1.980932 -1184.656\n1297 10.086350 2.001640 -1185.490\n1298 10.045101 1.984969 -1184.826\n1299 10.007141 1.951101 -1184.951\n1300 10.060569 1.932412 -1185.769\n1301  9.869326 2.039723 -1187.646\n1302  9.945656 1.921167 -1186.264\n1303  9.983681 2.073660 -1186.544\n1304 10.047502 1.940602 -1185.388\n1305 10.044300 1.934615 -1185.510\n1306  9.917519 2.048651 -1186.566\n1307  9.892824 1.996501 -1186.319\n1308  9.912589 2.000219 -1185.820\n1309  9.868323 1.981970 -1187.105\n1310  9.877760 1.976247 -1186.814\n1311 10.011722 1.962082 -1184.787\n1312  9.933964 1.983851 -1185.328\n1313 10.156538 2.038581 -1188.009\n1314 10.028791 1.980228 -1184.710\n1315  9.970371 1.995147 -1184.839\n1316  9.971707 1.968574 -1184.880\n1317  9.943320 1.922857 -1186.244\n1318  9.885835 1.957429 -1186.773\n1319  9.994119 2.003037 -1184.743\n1320 10.025235 1.970356 -1184.744\n1321 10.038819 1.980216 -1184.778\n1322 10.046316 2.016360 -1185.068\n1323  9.976896 1.971369 -1184.814\n1324 10.054053 1.962269 -1185.066\n1325  9.898121 1.995856 -1186.168\n1326 10.089204 1.895431 -1187.795\n1327 10.074271 1.894256 -1187.547\n1328  9.884560 1.928259 -1187.539\n1329  9.978780 1.920340 -1185.889\n1330 10.092067 2.015841 -1185.757\n1331 10.067917 2.037561 -1185.747\n1332 10.011698 1.980234 -1184.653\n1333 10.084284 1.975908 -1185.426\n1334 10.076422 2.001628 -1185.306\n1335 10.075611 1.959922 -1185.420\n1336  9.961190 2.070659 -1186.609\n1337 10.058973 1.962217 -1185.130\n1338  9.986926 2.054497 -1185.836\n1339 10.016457 2.037634 -1185.316\n1340 10.058291 2.027610 -1185.396\n1341  9.986993 1.953923 -1184.956\n1342 10.042297 2.022928 -1185.139\n1343 10.008557 2.007424 -1184.765\n1344 10.057261 1.954080 -1185.227\n1345 10.035737 2.041799 -1185.510\n1346 10.027975 2.050294 -1185.706\n1347 10.014648 2.040375 -1185.382\n1348  9.963421 1.963209 -1185.021\n1349 10.004983 1.995115 -1184.668\n1350 10.058337 1.969087 -1185.049\n1351 10.033151 1.970876 -1184.784\n1352  9.975569 2.011176 -1184.933\n1353  9.961899 2.011636 -1185.069\n1354 10.038786 1.982455 -1184.772\n1355 10.040495 1.950523 -1185.107\n1356  9.947553 1.985197 -1185.097\n1357  9.980609 2.028920 -1185.193\n1358 10.051795 1.990910 -1184.901\n1359 10.041356 1.978456 -1184.805\n1360  9.994346 1.991313 -1184.674\n1361 10.064515 2.015914 -1185.277\n1362 10.075485 1.974047 -1185.274\n1363 10.031758 2.010519 -1184.874\n1364  9.984197 1.960052 -1184.880\n1365 10.044283 1.992273 -1184.828\n1366  9.938442 2.050770 -1186.233\n1367  9.927001 2.020381 -1185.735\n1368  9.967332 2.081365 -1186.985\n1369 10.046636 1.895846 -1187.056\n1370 10.095241 1.907721 -1187.342\n1371  9.964700 1.906961 -1186.562\n1372 10.059295 2.071007 -1186.690\n1373 10.018301 2.032166 -1185.192\n1374 10.029371 1.947912 -1185.076\n1375 10.061840 1.989692 -1185.024\n1376 10.013608 1.959751 -1184.820\n1377 10.062703 1.997750 -1185.067\n1378  9.986210 1.974163 -1184.734\n1379 10.013465 2.005779 -1184.752\n1380 10.119977 2.115525 -1189.922\n1381  9.896796 1.934713 -1186.955\n1382 10.018629 2.054988 -1185.817\n1383 10.038791 1.984885 -1184.770\n1384 10.052129 2.031215 -1185.399\n1385 10.103494 1.937577 -1186.481\n1386 10.169176 1.985979 -1187.966\n1387  9.843060 1.992707 -1188.054\n1388  9.873932 1.955873 -1187.196\n1389  9.905376 1.976374 -1185.995\n1390 10.050872 2.007946 -1185.006\n1391 10.087178 2.004866 -1185.532\n1392 10.071440 1.987686 -1185.166\n1393 10.073594 2.009710 -1185.335\n1394 10.055236 2.053630 -1186.031\n1395 10.063091 1.984682 -1185.039\n1396  9.910311 1.949321 -1186.222\n1397 10.022986 2.055265 -1185.840\n1398  9.987589 1.921811 -1185.779\n1399  9.989932 2.024886 -1185.063\n1400 10.025084 1.947382 -1185.064\n1401  9.979718 1.957149 -1184.951\n1402  9.976746 1.998155 -1184.802\n1403 10.048332 2.070242 -1186.541\n1404  9.966073 1.909298 -1186.445\n1405  9.876554 2.052598 -1187.755\n1406 10.046576 1.941776 -1185.350\n1407  9.973140 1.981076 -1184.798\n1408  9.906167 1.979106 -1185.960\n1409  9.983726 2.041811 -1185.480\n1410 10.002491 1.955489 -1184.880\n1411  9.959080 2.014070 -1185.134\n1412 10.053592 1.960842 -1185.079\n1413 10.033353 2.037202 -1185.377\n1414  9.980017 2.051515 -1185.781\n1415 10.045906 1.972857 -1184.876\n1416  9.972374 1.998803 -1184.842\n1417 10.055536 2.032175 -1185.459\n1418  9.983887 1.979919 -1184.722\n1419 10.027878 1.908111 -1186.321\n1420 10.028329 1.917284 -1185.951\n1421 10.050948 1.901373 -1186.832\n1422 10.008766 1.952780 -1184.922\n1423 10.005586 2.018312 -1184.911\n1424  9.933826 2.002832 -1185.393\n1425 10.032838 1.919178 -1185.909\n1426  9.928940 2.040105 -1186.106\n1427 10.030138 1.988707 -1184.713\n1428  9.974289 2.018529 -1185.048\n1429 10.084408 1.955493 -1185.654\n1430  9.969880 1.977440 -1184.839\n1431  9.951442 2.053248 -1186.117\n1432  9.956672 1.994600 -1184.987\n1433 10.069017 1.962584 -1185.273\n1434  9.911156 2.051435 -1186.788\n1435  9.953626 1.966513 -1185.109\n1436  9.955488 1.967194 -1185.076\n1437 10.059627 2.004244 -1185.073\n1438  9.988325 1.915735 -1185.999\n1439 10.018367 2.065901 -1186.195\n1440  9.950099 1.946749 -1185.467\n1441 10.025227 1.956181 -1184.908\n1442 10.000917 1.981930 -1184.652\n1443  9.936960 1.957917 -1185.486\n1444  9.991885 1.990536 -1184.681\n1445  9.973693 1.961348 -1184.941\n1446 10.070838 1.969364 -1185.231\n1447 10.047515 1.947085 -1185.242\n1448  9.995839 1.964161 -1184.778\n1449 10.068964 2.006311 -1185.225\n1450 10.061166 1.959645 -1185.194\n1451  9.997032 2.017228 -1184.907\n1452 10.007549 2.009104 -1184.783\n1453  9.943524 1.945041 -1185.609\n1454  9.897275 1.950344 -1186.556\n1455 10.020761 2.023019 -1185.014\n1456  9.930515 2.016358 -1185.606\n1457 10.083763 1.958446 -1185.595\n1458  9.880246 1.978875 -1186.716\n1459 10.078702 2.021063 -1185.581\n1460 10.121740 2.021122 -1186.561\n1461  9.895152 1.952864 -1186.569\n1462 10.166936 1.965891 -1188.039\n1463 10.186435 1.961493 -1188.963\n1464 10.147333 1.978107 -1187.164\n1465 10.090547 1.945460 -1185.978\n1466  9.847862 2.024858 -1188.125\n1467  9.866267 2.023557 -1187.430\n1468  9.963354 2.027384 -1185.310\n1469 10.040436 1.963753 -1184.908\n1470 10.014963 1.951767 -1184.947\n1471 10.011039 1.957770 -1184.844\n1472  9.981481 1.957226 -1184.937\n1473 10.021776 2.050421 -1185.684\n1474 10.033120 2.004864 -1184.821\n1475 10.034646 1.936349 -1185.380\n1476 10.031444 1.931945 -1185.481\n1477 10.028191 1.984333 -1184.700\n1478 10.001073 1.944736 -1185.083\n1479  9.927453 1.926218 -1186.437\n1480 10.067246 1.924704 -1186.113\n1481 10.023200 1.984382 -1184.676\n1482 10.010149 2.056069 -1185.838\n1483 10.064125 1.875353 -1188.480\n1484  9.947168 2.105620 -1188.372\n1485  9.937511 2.060406 -1186.557\n1486 10.199258 1.966140 -1189.506\n1487 10.025332 1.995705 -1184.712\n1488  9.929278 2.013842 -1185.594\n1489  9.940874 2.010232 -1185.343\n1490  9.969861 1.978445 -1184.835\n1491 10.043824 1.995123 -1184.835\n1492  9.990313 2.052263 -1185.750\n1493 10.069618 2.018918 -1185.397\n1494 10.043453 2.054423 -1185.939\n1495 10.049942 2.006243 -1184.978\n1496  9.963305 1.964486 -1185.008\n1497  9.963305 1.964486 -1185.008\n1498 10.041720 2.010755 -1184.950\n1499  9.980857 1.941906 -1185.235\n1500 10.027324 1.974365 -1184.727\n1501  9.982050 2.004007 -1184.810\n1502 10.055535 1.966485 -1185.037\n1503 10.046959 1.960281 -1185.012\n1504 10.057618 1.954943 -1185.217\n1505 10.041619 1.906295 -1186.504\n1506 10.056829 2.036926 -1185.584\n1507  9.921231 1.964810 -1185.713\n1508  9.973106 2.073829 -1186.622\n1509  9.951784 1.924478 -1186.052\n1510 10.084479 2.015517 -1185.601\n1511 10.014530 1.929587 -1185.480\n1512 10.034833 1.932674 -1185.483\n1513  9.999966 2.001236 -1184.713\n1514 10.059813 2.003176 -1185.066\n1515  9.997669 1.998626 -1184.699\n1516  9.997669 1.998626 -1184.699\n1517 10.059891 2.006102 -1185.094\n1518 10.068834 1.978029 -1185.142\n1519 10.012692 2.013469 -1184.842\n1520 10.042965 2.027903 -1185.240\n1521 10.033217 2.020337 -1185.027\n1522  9.950558 1.964046 -1185.179\n1523 10.010155 2.054392 -1185.784\n1524 10.060670 2.045410 -1185.853\n1525 10.090111 2.031204 -1185.987\n1526 10.046657 1.935912 -1185.499\n1527 10.052077 1.916045 -1186.211\n1528  9.949704 1.985152 -1185.065\n1529  9.949964 1.935778 -1185.734\n1530  9.953454 1.926968 -1185.945\n1531 10.010543 1.978605 -1184.657\n1532  9.982465 1.983755 -1184.723\n1533 10.054926 1.991045 -1184.938\n1534 10.060403 2.039242 -1185.685\n1535 10.119346 1.979032 -1186.257\n1536 10.026770 2.029715 -1185.169\n1537 10.008164 1.958676 -1184.830\n1538 10.004081 1.963516 -1184.769\n1539  9.985697 1.961428 -1184.854\n1540 10.144918 2.049476 -1187.885\n1541 10.107254 2.040069 -1186.568\n1542  9.913111 1.934183 -1186.525\n1543 10.097609 2.045057 -1186.477\n1544  9.995503 1.976707 -1184.681\n1545  9.866266 2.003756 -1187.205\n1546 10.146420 1.972084 -1187.178\n1547 10.140552 1.973336 -1186.962\n1548 10.115662 1.999543 -1186.163\n1549 10.132161 1.966015 -1186.758\n1550 10.053702 2.020254 -1185.207\n1551 10.013715 1.980448 -1184.656\n1552 10.039330 1.979020 -1184.786\n1553  9.988891 1.910138 -1186.222\n1554 10.001923 1.973486 -1184.684\n1555  9.946416 2.038008 -1185.761\n1556 10.025362 1.915147 -1186.018\n1557 10.042704 1.897139 -1186.949\n1558 10.041621 1.868187 -1188.668\n1559 10.020400 1.901275 -1186.597\n1560 10.029865 1.916665 -1185.984\n1561 10.085297 1.951569 -1185.742\n1562 10.109133 1.974025 -1186.008\n1563 10.019500 1.947513 -1185.040\n1564  9.993986 1.949045 -1185.013\n1565 10.045275 1.946598 -1185.229\n1566 10.032322 1.954294 -1184.978\n1567 10.015717 2.012983 -1184.841\n1568 10.076509 1.958492 -1185.457\n1569  9.961490 1.940322 -1185.458\n1570  9.977363 2.073277 -1186.568\n1571 10.015324 2.084202 -1186.932\n1572  9.986622 2.086007 -1187.055\n1573 10.049372 1.997694 -1184.904\n1574  9.994668 1.993088 -1184.679\n1575 10.023131 1.977733 -1184.691\n1576  9.944502 1.991110 -1185.150\n1577  9.996593 1.936643 -1185.288\n1578 10.002835 1.922236 -1185.715\n1579 10.010167 1.991206 -1184.654\n1580 10.017412 2.018880 -1184.933\n1581 10.068422 2.061675 -1186.468\n1582 10.063167 1.915779 -1186.374\n1583  9.976861 1.917126 -1186.023\n1584 10.033984 2.066113 -1186.272\n1585 10.001921 1.984248 -1184.648\n1586 10.014468 1.962191 -1184.790\n1587 10.050408 2.029924 -1185.353\n1588  9.973650 2.000605 -1184.843\n1589 10.094968 2.063078 -1186.981\n1590 10.037687 2.023059 -1185.105\n1591  9.988943 1.939150 -1185.253\n1592 10.025849 2.016402 -1184.924\n1593 10.021922 2.013156 -1184.861\n1594 10.040650 1.950542 -1185.108\n1595  9.946183 1.942120 -1185.632\n1596 10.023914 1.998466 -1184.721\n1597  9.940161 1.959203 -1185.409\n1598 10.028040 1.879688 -1187.809\n1599 10.109570 1.871473 -1189.769\n1600 10.095055 1.936477 -1186.304\n1601  9.920423 2.037484 -1186.211\n1602  9.932673 2.029158 -1185.788\n1603 10.031650 2.048505 -1185.672\n1604 10.024551 2.033792 -1185.250\n1605  9.979019 1.936876 -1185.373\n1606  9.953972 1.969356 -1185.077\n1607  9.879568 1.936603 -1187.449\n1608  9.856848 1.937614 -1188.262\n1609  9.891628 1.995844 -1186.351\n1610  9.900416 1.996716 -1186.109\n1611  9.813759 1.945191 -1190.018\n1612  9.880055 2.003494 -1186.742\n1613 10.127066 1.978367 -1186.489\n1614  9.995662 1.996215 -1184.690\n1615 10.010794 2.014586 -1184.856\n1616  9.995919 1.965744 -1184.761\n1617  9.963073 2.017376 -1185.136\n1618 10.029684 1.975216 -1184.735\n1619  9.983843 2.028206 -1185.159\n1620  9.998581 1.974254 -1184.686\n1621  9.994993 1.968790 -1184.735\n1622 10.019966 2.010009 -1184.814\n1623  9.977331 1.975827 -1184.783\n1624 10.036110 1.996631 -1184.780\n1625 10.041800 1.921910 -1185.884\n1626 10.011407 1.989500 -1184.650\n1627 10.003139 1.981832 -1184.650\n1628 10.022538 2.033974 -1185.246\n1629 10.075549 1.980762 -1185.243\n1630 10.053881 1.947917 -1185.298\n1631 10.001328 2.001918 -1184.717\n1632 10.075217 2.022186 -1185.540\n1633  9.923812 1.982737 -1185.532\n1634 10.073391 2.096952 -1188.019\n1635 10.066481 2.064239 -1186.531\n1636 10.045625 1.986967 -1184.831\n1637  9.974858 1.992082 -1184.788\n1638  9.903058 2.035295 -1186.560\n1639 10.091293 2.055311 -1186.648\n1640  9.831568 1.929640 -1189.618\n1641  9.987027 2.007160 -1184.813\n1642 10.028008 1.964424 -1184.813\n1643 10.009811 2.059233 -1185.944\n1644 10.010005 2.042011 -1185.419\n1645  9.926960 2.006095 -1185.552\n1646  9.957201 1.976619 -1184.985\n1647 10.112626 2.014341 -1186.218\n1648  9.986126 1.989056 -1184.704\n1649 10.084544 2.034004 -1185.940\n1650 10.088596 2.003651 -1185.550\n1651  9.922919 1.968811 -1185.633\n1652  9.916432 2.054805 -1186.774\n1653 10.008408 1.994460 -1184.665\n1654 10.013860 2.020774 -1184.957\n1655 10.007640 1.974016 -1184.677\n1656  9.965058 2.014237 -1185.069\n1657 10.038655 2.021405 -1185.083\n1658 10.014326 1.975801 -1184.674\n1659  9.891742 2.022722 -1186.618\n1660  9.901585 2.028662 -1186.459\n1661 10.001069 2.069743 -1186.330\n1662  9.987568 2.053041 -1185.786\n1663 10.028756 1.924643 -1185.692\n1664  9.983600 2.050888 -1185.740\n1665 10.010590 2.057945 -1185.901\n1666 10.057713 2.056743 -1186.160\n1667 10.116080 2.040498 -1186.800\n1668 10.078353 1.994672 -1185.300\n1669 10.119541 2.050675 -1187.165\n1670 10.003681 2.048946 -1185.616\n1671  9.922165 1.941067 -1186.123\n1672 10.005951 2.006412 -1184.754\n1673 10.010705 1.967799 -1184.725\n1674 10.002226 1.962492 -1184.783\n1675 10.061943 1.921447 -1186.144\n1676 10.090825 1.987918 -1185.528\n1677 10.026613 2.004563 -1184.782\n1678  9.994308 2.008164 -1184.794\n1679  9.994586 1.953227 -1184.935\n1680  9.988278 1.949497 -1185.029\n1681  9.952176 1.938125 -1185.639\n1682  9.960276 2.054067 -1186.035\n1683  9.860261 2.052490 -1188.289\n1684  9.866124 2.056761 -1188.216\n1685  9.943292 2.066254 -1186.673\n1686  9.898741 1.988753 -1186.137\n1687 10.112888 1.985323 -1186.058\n1688 10.179853 1.946038 -1188.982\n1689  9.897347 1.992132 -1186.178\n1690  9.964571 1.927750 -1185.775\n1691  9.938465 1.977306 -1185.267\n1692  9.948901 2.020800 -1185.370\n1693 10.077291 1.985410 -1185.266\n1694 10.088717 1.951912 -1185.807\n1695 10.036600 2.029290 -1185.219\n1696  9.979241 1.975661 -1184.769\n1697 10.082566 2.013790 -1185.542\n1698 10.008224 1.884562 -1187.456\n1699  9.983301 1.851491 -1189.836\n1700 10.033176 1.978050 -1184.744\n1701  9.981369 1.993663 -1184.746\n1702 10.063098 1.954041 -1185.308\n1703  9.951087 2.020043 -1185.326\n1704 10.055791 2.078845 -1186.965\n1705 10.007017 1.997955 -1184.684\n1706  9.946828 2.013626 -1185.292\n1707  9.949155 1.968003 -1185.158\n1708 10.027999 1.906386 -1186.397\n1709  9.957092 1.989367 -1184.966\n1710 10.048246 1.977638 -1184.874\n1711  9.985402 1.985055 -1184.705\n1712  9.939903 2.025546 -1185.592\n1713  9.879076 1.990584 -1186.725\n1714 10.022064 1.883735 -1187.535\n1715 10.072070 2.034833 -1185.745\n1716 10.011708 1.974781 -1184.676\n1717 10.121921 2.015842 -1186.489\n1718  9.937476 1.955336 -1185.517\n1719 10.066610 1.985774 -1185.090\n1720 10.034039 1.981868 -1184.738\n1721  9.948856 1.964757 -1185.197\n1722 10.028794 1.970287 -1184.762\n1723  9.979963 2.013125 -1184.926\n1724 10.021462 1.990134 -1184.675\n1725  9.919682 1.979157 -1185.634\n1726 10.005694 1.994727 -1184.666\n1727 10.063552 1.981218 -1185.052\n1728 10.088137 2.012095 -1185.628\n1729 10.070552 2.028489 -1185.584\n1730 10.045904 1.992577 -1184.845\n1731 10.069548 2.006553 -1185.237\n1732 10.071217 2.028741 -1185.599\n1733 10.090225 1.967864 -1185.611\n1734 10.042947 1.992582 -1184.817\n1735 10.062259 1.957125 -1185.246\n1736  9.953197 2.014059 -1185.208\n1737  9.971427 2.062685 -1186.215\n1738 10.039290 1.912249 -1186.229\n1739  9.963895 1.961488 -1185.037\n1740  9.990960 1.969223 -1184.746\n1741 10.085235 1.954192 -1185.693\n1742 10.101666 1.957237 -1186.013\n1743  9.963663 2.050197 -1185.879\n1744  9.948732 2.049770 -1186.047\n1745 10.055823 1.981620 -1184.948\n1746  9.966839 1.992079 -1184.861\n1747 10.027846 1.950145 -1185.025\n1748 10.056256 1.956420 -1185.176\n1749 10.060540 1.998149 -1185.040\n1750  9.999344 1.979029 -1184.663\n1751 10.023504 1.925931 -1185.623\n1752  9.940280 1.956457 -1185.449\n1753  9.952902 1.959888 -1185.198\n1754  9.993436 1.980114 -1184.676\n1755 10.027103 2.026621 -1185.108\n1756  9.994778 1.968440 -1184.738\n1757  9.985717 2.043632 -1185.518\n1758 10.073230 1.949574 -1185.552\n1759 10.153930 1.962084 -1187.577\n1760  9.861673 2.018702 -1187.519\n1761 10.045952 2.025752 -1185.225\n1762  9.923148 1.955355 -1185.805\n1763  9.956148 1.984902 -1184.976\n1764  9.955460 1.978724 -1184.999\n1765 10.073971 1.957550 -1185.426\n1766 10.020886 1.932588 -1185.409\n1767  9.973168 2.012540 -1184.970\n1768 10.056675 1.958587 -1185.149\n1769 10.012469 1.972367 -1184.691\n1770  9.995200 2.000110 -1184.716\n1771 10.044706 1.999291 -1184.867\n1772 10.079040 1.961400 -1185.462\n1773  9.970272 2.007025 -1184.930\n1774 10.107155 2.007079 -1185.999\n1775  9.976366 2.045930 -1185.641\n1776  9.893641 2.051543 -1187.228\n1777  9.888803 2.057926 -1187.557\n1778  9.911122 2.060741 -1187.084\n1779  9.911599 2.042541 -1186.530\n1780 10.103202 1.940691 -1186.392\n1781 10.101574 1.980867 -1185.782\n1782  9.946816 2.038079 -1185.757\n1783  9.942973 2.052815 -1186.224\n1784 10.019463 1.935658 -1185.319\n1785  9.948182 1.967967 -1185.174\n1786  9.952168 1.918274 -1186.267\n1787  9.968160 1.934221 -1185.543\n1788  9.950857 1.913779 -1186.462\n1789  9.965728 1.906156 -1186.586\n1790 10.020897 2.027018 -1185.090\n1791  9.908087 2.052826 -1186.901\n1792  9.950222 1.956389 -1185.288\n1793 10.065112 2.017741 -1185.312\n1794 10.064577 1.924512 -1186.077\n1795  9.928162 2.020885 -1185.720\n1796 10.085653 1.950888 -1185.762\n1797 10.119573 1.976628 -1186.277\n1798  9.995772 2.031511 -1185.178\n1799  9.966906 1.922629 -1185.919\n1800  9.955665 1.918682 -1186.201\n1801  9.967544 2.051008 -1185.865\n1802 10.006238 2.020454 -1184.946\n1803 10.103820 2.088282 -1188.177\n1804 10.004216 1.906615 -1186.329\n1805  9.985195 1.880675 -1187.757\n1806 10.030572 2.106307 -1188.062\n1807  9.981871 1.880518 -1187.789\n1808  9.946747 1.959402 -1185.297\n1809 10.070908 2.016051 -1185.374\n1810 10.026959 1.989695 -1184.698\n1811 10.068185 1.971099 -1185.174\n1812  9.973822 2.061005 -1186.137\n1813  9.993999 2.078049 -1186.680\n1814  9.960179 1.959554 -1185.106\n1815  9.956576 1.931956 -1185.747\n1816  9.936293 1.952441 -1185.589\n1817 10.076971 2.024882 -1185.618\n1818  9.986813 1.945741 -1185.112\n1819 10.025892 2.042625 -1185.477\n1820  9.989202 1.933294 -1185.408\n1821  9.987213 1.961682 -1184.842\n1822  9.988700 1.966815 -1184.778\n1823 10.018473 1.954338 -1184.912\n1824 10.080315 1.989614 -1185.322\n1825  9.898207 2.039997 -1186.795\n1826  9.990595 2.034029 -1185.253\n1827 10.001957 2.030183 -1185.137\n1828 10.016551 2.007198 -1184.773\n1829  9.948561 1.947603 -1185.473\n1830  9.965890 1.949224 -1185.212\n1831  9.984044 2.010293 -1184.865\n1832 10.004367 1.960989 -1184.800\n1833 10.065864 2.004201 -1185.159\n1834 10.077123 2.016496 -1185.482\n1835  9.974426 1.994975 -1184.803\n1836  9.939530 2.065860 -1186.717\n1837  9.937106 1.899704 -1187.331\n1838  9.943662 1.980426 -1185.167\n1839  9.977851 1.996713 -1184.785\n1840  9.998835 2.000249 -1184.708\n1841  9.973877 1.940358 -1185.327\n1842  9.933945 1.955835 -1185.575\n1843 10.069759 1.944994 -1185.588\n1844  9.966888 1.993322 -1184.865\n1845  9.982274 2.002983 -1184.799\n1846  9.963699 1.998362 -1184.924\n1847  9.992957 2.055958 -1185.858\n1848 10.030935 1.947339 -1185.097\n1849 10.064617 2.031215 -1185.554\n1850 10.020961 1.921263 -1185.771\n1851 10.027513 2.001961 -1184.763\n1852  9.947529 2.015608 -1185.309\n1853  9.921357 1.995438 -1185.597\n1854 10.011833 1.995899 -1184.674\n1855 10.047962 1.925475 -1185.826\n1856  9.966254 2.052718 -1185.930\n1857  9.964068 2.076907 -1186.829\n1858  9.959097 2.032973 -1185.476\n1859  9.960190 2.039857 -1185.629\n1860 10.053972 1.933499 -1185.650\n1861 10.165290 2.024939 -1188.071\n1862 10.121711 2.023806 -1186.604\n1863  9.990043 1.990437 -1184.688\n1864  9.998992 1.909747 -1186.202\n1865  9.954696 1.980288 -1185.004\n1866  9.969624 1.997400 -1184.858\n1867  9.999290 1.961539 -1184.800\n1868  9.855915 1.956201 -1187.860\n1869  9.980611 2.052961 -1185.822\n1870 10.015895 1.967261 -1184.738\n1871 10.057310 1.956033 -1185.195\n1872  9.998655 2.041673 -1185.419\n1873 10.034503 1.951073 -1185.049\n1874  9.983968 2.030570 -1185.208\n1875 10.019832 2.085975 -1187.022\n1876 10.013308 2.112798 -1188.356\n1877  9.973789 1.911796 -1186.261\n1878  9.991110 2.058625 -1185.954\n1879 10.011686 1.997800 -1184.685\n1880 10.009305 1.948851 -1184.994\n1881  9.878543 1.957171 -1187.015\n1882  9.994217 2.074885 -1186.549\n1883 10.050033 2.009256 -1185.011\n1884 10.024850 1.914726 -1186.032\n1885  9.989639 2.062916 -1186.109\n1886  9.979885 2.001400 -1184.802\n1887  9.968832 1.979871 -1184.841\n1888 10.032671 2.008920 -1184.861\n1889 10.020615 1.988257 -1184.669\n1890 10.017707 1.967402 -1184.742\n1891 10.098203 1.962841 -1185.848\n1892 10.053307 2.012786 -1185.091\n1893  9.940110 1.933620 -1185.958\n1894 10.065391 2.052547 -1186.125\n1895  9.959519 1.924755 -1185.934\n1896 10.152713 2.051915 -1188.216\n1897 10.061864 1.935537 -1185.699\n1898  9.901605 1.954020 -1186.363\n1899  9.896790 1.946679 -1186.648\n1900  9.977980 1.931778 -1185.523\n1901 10.012672 1.959087 -1184.828\n1902 10.046671 2.009689 -1184.982\n1903 10.060654 1.965805 -1185.112\n1904 10.055275 1.973305 -1184.977\n1905 10.022562 1.957745 -1184.873\n1906 10.033481 1.997961 -1184.769\n1907 10.062289 1.925368 -1186.014\n1908 10.028691 1.997833 -1184.740\n1909 10.032070 1.923659 -1185.746\n1910 10.003530 1.932069 -1185.401\n1911  9.964260 1.991238 -1184.886\n1912 10.002539 1.960991 -1184.801\n1913 10.002539 1.960991 -1184.801\n1914 10.054994 2.008986 -1185.064\n1915 10.006605 1.953966 -1184.902\n1916 10.008651 2.019519 -1184.931\n1917  9.961945 1.995206 -1184.926\n1918  9.962143 1.939901 -1185.461\n1919 10.115547 2.035146 -1186.660\n1920 10.155020 2.035281 -1187.883\n1921 10.074154 2.058409 -1186.443\n1922  9.951961 1.919209 -1186.235\n1923  9.947235 1.895572 -1187.356\n1924 10.049176 1.968274 -1184.946\n1925  9.941821 2.035935 -1185.781\n1926  9.835360 2.009566 -1188.449\n1927  9.866111 1.993144 -1187.168\n1928 10.116607 1.915977 -1187.568\n1929 10.072329 1.866986 -1189.190\n1930  9.906175 1.948033 -1186.357\n1931  9.926790 1.962083 -1185.627\n1932  9.925046 1.883467 -1188.474\n1933  9.818809 1.902806 -1191.407\n1934  9.885608 1.924557 -1187.632\n1935 10.130857 2.052801 -1187.544\n1936 10.111399 2.034485 -1186.539\n1937 10.059174 1.966646 -1185.083\n1938 10.021470 2.068227 -1186.291\n1939 10.037606 2.020515 -1185.060\n1940 10.030696 2.024336 -1185.083\n1941  9.977810 1.973499 -1184.792\n1942 10.012155 2.019367 -1184.931\n1943  9.938089 1.967777 -1185.343\n1944  9.977424 2.008326 -1184.885\n1945 10.038074 1.918247 -1185.984\n1946 10.184412 1.976623 -1188.678\n1947  9.835217 1.999844 -1188.398\n1948  9.876702 1.987434 -1186.804\n1949 10.002681 1.962670 -1184.781\n1950 10.011746 1.992950 -1184.661\n1951 10.046943 1.942020 -1185.348\n1952 10.012958 1.988682 -1184.651\n1953 10.026117 1.974984 -1184.717\n1954 10.030556 1.966062 -1184.811\n1955 10.023964 2.018484 -1184.948\n1956 10.010472 2.001636 -1184.711\n1957 10.000215 2.018008 -1184.912\n1958 10.045352 2.043537 -1185.633\n1959  9.970385 1.929340 -1185.663\n1960  9.992034 1.934514 -1185.361\n1961  9.954047 1.943572 -1185.479\n1962  9.975583 1.978471 -1184.785\n1963  9.940408 2.016886 -1185.438\n1964  9.959495 2.010132 -1185.078\n1965  9.890834 1.946490 -1186.831\n1966  9.992137 1.888395 -1187.270\n1967 10.037441 1.852006 -1189.843\n1968  9.983938 2.056934 -1185.931\n1969  9.995585 2.044733 -1185.509\n1970 10.018265 1.930497 -1185.461\n1971 10.030336 1.973737 -1184.747\n1972 10.024549 1.961748 -1184.828\n1973 10.059433 2.022705 -1185.318\n1974 10.100285 1.953719 -1186.038\n1975 10.103529 1.991451 -1185.821\n1976  9.989969 2.014689 -1184.893\n1977 10.008067 1.953125 -1184.916\n1978 10.081362 1.953122 -1185.635\n1979 10.100959 1.974599 -1185.799\n1980  9.906870 1.930591 -1186.795\n1981  9.927952 1.915764 -1186.807\n1982  9.890741 1.909699 -1188.057\n1983  9.905374 1.924499 -1187.037\n1984 10.108790 2.002607 -1186.002\n1985 10.134276 2.014003 -1186.834\n1986 10.045264 1.942625 -1185.316\n1987  9.968368 2.031349 -1185.342\n1988  9.989243 1.975927 -1184.709\n1989 10.009856 1.986208 -1184.645\n1990 10.060167 1.967590 -1185.087\n1991  9.948148 2.012129 -1185.253\n1992 10.138530 2.005594 -1186.886\n1993 10.058751 2.044045 -1185.791\n1994 10.008046 2.006073 -1184.750\n1995 10.015306 2.007325 -1184.771\n1996  9.988364 1.957126 -1184.899\n1997  9.972929 1.924069 -1185.809\n1998  9.963148 1.948310 -1185.261\n1999 10.051063 2.023213 -1185.229\n2000 10.049425 1.971660 -1184.921\n2001  9.977411 2.092797 -1187.423\n2002 10.077283 1.905043 -1187.073\n2003  9.993386 2.020432 -1184.970\n2004  9.942511 1.956457 -1185.410\n2005 10.080858 1.995465 -1185.349\n2006  9.956139 1.993933 -1184.991\n2007 10.048473 1.952866 -1185.142\n2008  9.996144 2.036019 -1185.281\n2009 10.055996 2.064120 -1186.394\n2010  9.978045 1.968198 -1184.831\n2011 10.039921 1.990584 -1184.785\n2012 10.008928 1.973892 -1184.678\n2013 10.015050 2.051228 -1185.691\n2014  9.982722 1.912716 -1186.152\n2015  9.936689 1.970016 -1185.347\n2016  9.916676 1.959944 -1185.881\n2017 10.068995 2.031185 -1185.617\n2018  9.974788 1.979260 -1184.789\n2019 10.046528 2.007812 -1184.960\n2020  9.952381 1.980243 -1185.035\n2021 10.060362 2.070254 -1186.674\n2022 10.153182 2.023959 -1187.606\n2023 10.153182 2.023959 -1187.606\n2024 10.072170 1.944351 -1185.643\n2025 10.072170 1.944351 -1185.643\n2026 10.010075 2.061723 -1186.031\n2027  9.911145 1.944377 -1186.309\n2028  9.991289 1.986108 -1184.677\n2029 10.077671 1.996557 -1185.296\n2030 10.082115 1.998113 -1185.386\n2031 10.065640 2.045610 -1185.924\n2032 10.096206 2.046571 -1186.489\n2033 10.160012 2.011055 -1187.690\n2034 10.015555 1.984672 -1184.653\n2035  9.980593 1.986654 -1184.735\n2036  9.966205 1.987961 -1184.859\n2037 10.102802 1.938237 -1186.445\n2038  9.986545 1.946499 -1185.098\n2039 10.017285 2.040379 -1185.388\n2040 10.020437 1.931518 -1185.438\n2041 10.012424 1.942414 -1185.134\n2042 10.025966 1.970107 -1184.749\n2043  9.995325 1.959286 -1184.840\n2044  9.897772 1.936799 -1186.867\n2045  9.915367 1.948904 -1186.105\n2046 10.023296 1.994151 -1184.695\n2047 10.024273 1.994983 -1184.703\n2048  9.929937 1.968537 -1185.490\n2049 10.082627 1.995423 -1185.382\n2050 10.076843 1.974524 -1185.295\n2051  9.993240 2.053749 -1185.786\n2052  9.991525 1.928047 -1185.554\n2053 10.026246 1.944841 -1185.123\n2054  9.916199 1.956148 -1185.951\n2055  9.911483 1.948151 -1186.217\n2056 10.076789 2.044113 -1186.054\n2057  9.971585 1.929253 -1185.654\n2058  9.978391 1.936577 -1185.386\n2059 10.012302 2.021341 -1184.965\n2060 10.014454 1.964506 -1184.764\n2061  9.995392 2.012193 -1184.839\n2062 10.016063 2.035102 -1185.254\n2063 10.127715 2.061714 -1187.735\n2064 10.126176 2.059719 -1187.626\n2065  9.990537 1.934853 -1185.358\n2066 10.074586 1.966244 -1185.324\n2067 10.020652 2.086085 -1187.030\n2068  9.919005 1.930914 -1186.478\n2069 10.076295 1.991248 -1185.253\n2070 10.020959 1.978124 -1184.682\n2071 10.031037 1.944946 -1185.148\n2072 10.006360 2.038098 -1185.317\n2073  9.907825 2.032977 -1186.392\n2074 10.040771 1.965189 -1184.895\n2075  9.957344 1.996057 -1184.986\n2076 10.016597 2.008149 -1184.783\n2077 10.016597 2.008149 -1184.783\n2078 10.007306 1.957335 -1184.849\n2079  9.898641 1.991962 -1186.143\n2080  9.912224 1.946146 -1186.241\n2081  9.947656 2.026905 -1185.498\n2082 10.059016 1.929228 -1185.843\n2083  9.856385 1.978809 -1187.563\n2084  9.969662 1.953859 -1185.089\n2085 10.045224 1.983777 -1184.828\n2086  9.957024 2.006997 -1185.074\n2087 10.015727 1.970904 -1184.707\n2088 10.009677 1.981528 -1184.649\n2089 10.009677 1.981528 -1184.649\n2090  9.968003 1.972718 -1184.884\n2091  9.994088 1.997591 -1184.703\n2092 10.014314 1.971157 -1184.703\n2093  9.985167 1.960108 -1184.874\n2094 10.015987 1.987073 -1184.654\n2095 10.015987 1.987073 -1184.654\n2096 10.028211 1.963249 -1184.828\n2097 10.037482 2.013393 -1184.950\n2098  9.981880 1.977446 -1184.743\n2099 10.007700 1.947733 -1185.016\n2100  9.999210 2.016231 -1184.887\n2101 10.016581 1.938863 -1185.227\n2102 10.048170 2.024544 -1185.223\n2103  9.937327 2.038636 -1185.920\n2104 10.131437 1.960985 -1186.802\n2105  9.969644 2.016765 -1185.061\n2106 10.028832 2.042782 -1185.495\n2107  9.969258 1.958345 -1185.023\n2108  9.969258 1.958345 -1185.023\n2109  9.972959 1.988927 -1184.796\n2110 10.065849 1.970329 -1185.144\n2111 10.035918 1.958610 -1184.937\n2112  9.910725 1.953916 -1186.124\n2113  9.903227 1.927228 -1187.004\n2114  9.978635 2.041352 -1185.500\n2115  9.902879 1.971037 -1186.100\n2116 10.021077 1.930959 -1185.457\n2117  9.975286 2.036226 -1185.395\n2118  9.911761 1.974728 -1185.844\n2119  9.911761 1.974728 -1185.844\n2120  9.966790 2.036358 -1185.472\n2121 10.070149 1.950917 -1185.474\n2122 10.082288 2.021938 -1185.660\n2123  9.943228 1.980664 -1185.173\n2124 10.149166 1.991329 -1187.191\n2125 10.182950 1.992901 -1188.543\n2126 10.012184 1.983042 -1184.649\n2127 10.027490 1.989820 -1184.700\n2128 10.108316 1.987284 -1185.937\n2129  9.934998 1.971868 -1185.363\n2130 10.073013 2.008488 -1185.312\n2131 10.090316 1.937291 -1186.174\n2132 10.008372 1.980698 -1184.650\n2133  9.977018 1.996481 -1184.790\n2134  9.980027 1.994470 -1184.758\n2135 10.025741 1.995005 -1184.710\n2136 10.039318 1.983225 -1184.776\n2137  9.964167 1.972320 -1184.927\n2138 10.094220 1.978497 -1185.621\n2139  9.973031 1.969831 -1184.858\n2140  9.981587 1.984797 -1184.728\n2141  9.995269 1.982424 -1184.665\n2142 10.025869 2.009928 -1184.836\n2143  9.894130 1.997867 -1186.287\n2144 10.035890 2.044671 -1185.589\n2145 10.028901 2.029435 -1185.174\n2146  9.957343 1.971160 -1185.017\n2147 10.024230 1.921107 -1185.790\n2148  9.962783 1.966957 -1184.988\n2149  9.959535 1.960540 -1185.101\n2150  9.976141 1.997015 -1184.800\n2151 10.003012 1.982651 -1184.648\n2152 10.046612 1.971090 -1184.896\n2153  9.980919 1.967292 -1184.819\n2154  9.980919 1.967292 -1184.819\n2155 10.031542 1.992652 -1184.731\n2156 10.000635 1.970842 -1184.704\n2157 10.008150 2.021922 -1184.972\n2158  9.871932 1.988416 -1186.964\n2159 10.092074 2.030727 -1186.017\n2160  9.913230 1.979187 -1185.783\n2161 10.014395 2.017821 -1184.909\n2162 10.124786 1.945219 -1186.892\n2163 10.026062 1.972375 -1184.733\n2164 10.005056 2.003536 -1184.727\n2165  9.964885 2.034610 -1185.450\n2166 10.032615 1.944008 -1185.179\n2167 10.012255 2.017166 -1184.896\n2168  9.934111 1.983567 -1185.326\n2169  9.982904 2.032052 -1185.246\n2170  9.954580 1.970009 -1185.063\n2171 10.025642 2.034491 -1185.271\n2172 10.087601 1.938492 -1186.083\n2173 10.013869 1.984203 -1184.650\n2174  9.984746 1.999996 -1184.761\n2175  9.965132 2.063460 -1186.300\n2176  9.928684 2.057234 -1186.606\n2177  9.942789 2.057596 -1186.380\n2178  9.951567 2.067999 -1186.622\n2179  9.952499 2.043258 -1185.812\n2180  9.998855 1.953167 -1184.924\n2181 10.007096 2.006516 -1184.755\n2182 10.098248 1.962981 -1185.848\n2183  9.925443 1.984665 -1185.495\n2184  9.981822 1.996745 -1184.758\n2185 10.045125 1.989036 -1184.828\n2186  9.945524 1.921560 -1186.252\n2187 10.025612 1.952009 -1184.979\n2188  9.993203 1.946376 -1185.070\n2189 10.051325 2.002002 -1184.955\n2190 10.051325 2.002002 -1184.955\n2191  9.990108 2.047958 -1185.621\n2192 10.016939 2.010198 -1184.808\n2193  9.984384 2.018519 -1184.979\n2194 10.090133 2.023558 -1185.839\n2195  9.921919 1.937059 -1186.233\n2196 10.191629 2.033770 -1189.321\n2197 10.230926 2.043294 -1191.443\n2198 10.188201 2.034832 -1189.190\n2199 10.176398 1.964399 -1188.463\n2200 10.050981 2.080899 -1187.001\n2201 10.030602 2.055444 -1185.881\n2202 10.039078 1.945735 -1185.190\n2203  9.931710 1.935661 -1186.061\n2204 10.021343 2.078055 -1186.683\n2205  9.976323 2.137203 -1189.914\n2206  9.965134 1.891599 -1187.311\n2207 10.008664 2.001690 -1184.711\n2208 10.044804 1.994349 -1184.841\n2209 10.185359 2.022283 -1188.855\n2210 10.117631 2.023354 -1186.484\n2211  9.868179 1.962328 -1187.295\n2212 10.015648 1.982499 -1184.655\n2213 10.068352 1.957638 -1185.331\n2214  9.961199 1.877322 -1188.197\n2215  9.942991 1.896030 -1187.406\n2216  9.962410 1.914629 -1186.268\n2217  9.920767 1.946109 -1186.037\n2218  9.934868 1.957642 -1185.529\n2219 10.018338 2.011714 -1184.831\n2220 10.036582 2.021540 -1185.070\n2221 10.090351 1.983866 -1185.521\n2222 10.024332 1.965654 -1184.782\n2223 10.060308 1.975247 -1185.031\n2224  9.971895 2.065141 -1186.299\n2225  9.965441 2.042084 -1185.631\n2226  9.965262 2.050852 -1185.882\n2227  9.965262 2.050852 -1185.882\n2228 10.003094 1.926625 -1185.568\n2229 10.047914 2.054504 -1185.982\n2230 10.051903 1.985339 -1184.897\n2231  9.930837 2.013721 -1185.563\n2232 10.031301 2.029623 -1185.191\n2233 10.063450 2.008132 -1185.163\n2234  9.975808 2.039931 -1185.483\n2235  9.956172 1.938433 -1185.574\n2236  9.986393 1.967960 -1184.779\n2237  9.909834 1.983271 -1185.853\n2238 10.035526 1.993233 -1184.760\n2239  9.984247 1.982443 -1184.714\n2240 10.053854 1.999221 -1184.963\n2241  9.989886 1.986737 -1184.683\n2242 10.019218 2.011490 -1184.830\n2243  9.931396 1.977323 -1185.398\n2244  9.900724 1.982385 -1186.091\n2245  9.948237 1.955179 -1185.338\n2246  9.904468 1.967215 -1186.095\n2247  9.942490 1.980336 -1185.186\n2248 10.041013 1.982164 -1184.791\n2249 10.051910 2.002356 -1184.964\n2250 10.008818 2.015920 -1184.874\n2251  9.898988 2.032060 -1186.595\n2252 10.113040 1.945013 -1186.550\n2253 10.016259 1.970836 -1184.709\n2254  9.998037 2.021610 -1184.977\n2255 10.005801 1.933906 -1185.347\n2256 10.072736 2.069402 -1186.812\n2257 10.033338 2.106163 -1188.069\n2258 10.054249 2.041073 -1185.658\n2259 10.068363 2.060157 -1186.415\n2260 10.024774 1.998577 -1184.726\n2261 10.024774 1.998577 -1184.726\n2262  9.989014 1.963908 -1184.807\n2263  9.969341 2.040091 -1185.541\n2264  9.942982 2.054045 -1186.262\n2265 10.051119 1.917326 -1186.151\n2266  9.973179 1.994520 -1184.811\n2267  9.973179 1.994520 -1184.811\n2268  9.974989 1.934798 -1185.461\n2269 10.021910 1.984613 -1184.671\n2270 10.102440 2.035274 -1186.341\n2271  9.975755 2.002686 -1184.843\n2272 10.043135 1.960298 -1184.975\n2273  9.918570 2.029257 -1186.070\n2274  9.965907 2.048107 -1185.794\n2275 10.051085 1.929211 -1185.742\n2276 10.001380 2.013183 -1184.839\n2277 10.007660 1.993167 -1184.659\n2278 10.028394 2.034004 -1185.273\n2279  9.965711 1.940331 -1185.409\n2280 10.003100 1.910994 -1186.143\n2281 10.013433 1.965445 -1184.752\n2282 10.171966 2.003793 -1188.105\n2283  9.842930 1.964851 -1188.252\n2284  9.832356 2.042420 -1189.098\n2285 10.051079 1.929695 -1185.727\n2286 10.009437 2.032540 -1185.186\n2287  9.983539 2.017035 -1184.960\n2288 10.066898 1.953398 -1185.377\n2289 10.068081 2.027982 -1185.536\n2290  9.992042 1.990545 -1184.680\n2291  9.967603 1.982875 -1184.846\n2292  9.965603 2.014803 -1185.072\n2293  9.995569 2.058131 -1185.922\n2294  9.975515 1.889476 -1187.319\n2295 10.002366 2.100871 -1187.721\n2296  9.999049 2.122654 -1188.922\n2297 10.017115 2.111202 -1188.275\n2298  9.945600 1.993911 -1185.141\n2299  9.947218 1.965010 -1185.219\n2300  9.998983 2.009629 -1184.798\n2301  9.918440 1.992667 -1185.652\n2302 10.064471 2.023026 -1185.391\n2303  9.968578 1.943236 -1185.310\n2304  9.955225 1.984245 -1184.989\n2305 10.051941 1.982921 -1184.899\n2306  9.946262 1.975642 -1185.146\n2307  9.918098 1.969842 -1185.732\n2308  9.965580 2.073258 -1186.666\n2309 10.056247 1.933327 -1185.684\n2310 10.004292 1.988605 -1184.648\n2311 10.067546 1.940550 -1185.656\n2312  9.998973 1.983736 -1184.654\n2313  9.977580 2.022779 -1185.095\n2314 10.014401 1.902309 -1186.531\n2315 10.021678 1.965354 -1184.775\n2316 10.010794 2.010666 -1184.804\n2317  9.968725 1.988834 -1184.835\n2318  9.984336 1.925148 -1185.684\n2319 10.069634 2.013411 -1185.317\n2320  9.947293 1.940846 -1185.645\n2321 10.025255 1.959199 -1184.864\n2322  9.889100 1.916599 -1187.819\n2323 10.142241 2.054609 -1187.947\n2324  9.903613 1.915755 -1187.414\n2325  9.946837 1.927837 -1186.018\n2326 10.083184 2.023256 -1185.699\n2327  9.991504 1.980887 -1184.681\n2328  9.980338 1.993799 -1184.753\n2329 10.003288 1.985338 -1184.646\n2330 10.003288 1.985338 -1184.646\n2331 10.031049 2.019262 -1184.995\n2332 10.056270 2.029931 -1185.419\n2333 10.077529 1.953504 -1185.556\n2334  9.959689 1.975919 -1184.957\n2335 10.100765 1.982289 -1185.758\n2336 10.123776 1.950221 -1186.751\n2337  9.933939 1.975165 -1185.361\n2338  9.988711 2.084576 -1186.981\n2339  9.904301 1.933279 -1186.783\n2340  9.966251 1.990556 -1184.863\n2341  9.990412 1.928333 -1185.549\n2342  9.997728 1.945050 -1185.084\n2343 10.031961 2.027853 -1185.159\n2344 10.040039 1.977864 -1184.796\n2345 10.031104 2.016074 -1184.946\n2346  9.934027 2.042520 -1186.076\n2347  9.961670 2.022447 -1185.235\n2348  9.969821 2.023720 -1185.176\n2349 10.059024 1.965090 -1185.097\n2350 10.006393 1.901903 -1186.543\n2351  9.914988 1.990166 -1185.725\n2352 10.062875 1.922813 -1186.110\n2353 10.010017 1.966886 -1184.733\n2354 10.030158 1.989818 -1184.715\n2355 10.038831 1.975301 -1184.798\n2356  9.975433 1.974262 -1184.806\n2357  9.917210 2.026072 -1186.038\n2358  9.936529 1.982150 -1185.284\n2359 10.057082 2.007479 -1185.073\n2360  9.927076 1.972162 -1185.516\n2361 10.085856 1.982513 -1185.431\n2362 10.028670 1.963300 -1184.830\n2363  9.938076 2.011397 -1185.404\n2364  9.903026 2.011132 -1186.152\n2365 10.116371 1.973299 -1186.209\n2366 10.162089 1.985790 -1187.682\n2367  9.870896 1.998850 -1187.018\n2368  9.807362 2.013463 -1189.769\n2369 10.079556 1.935303 -1186.005\n2370 10.074566 1.957217 -1185.441\n2371  9.955607 1.999083 -1185.025\n2372  9.958272 1.995875 -1184.973\n2373 10.032065 1.989574 -1184.726\n2374  9.931256 2.002179 -1185.435\n2375 10.080249 1.970710 -1185.385\n2376  9.957006 1.968433 -1185.045\n2377 10.061997 1.995644 -1185.046\n2378  9.989472 1.951486 -1184.986\n2379  9.990001 2.015613 -1184.906\n2380 10.012156 1.946534 -1185.043\n2381  9.913043 1.928862 -1186.689\n2382 10.007923 2.015172 -1184.863\n2383  9.972755 1.949335 -1185.141\n2384  9.970664 1.938801 -1185.396\n2385  9.950486 1.990384 -1185.058\n2386 10.052664 2.002272 -1184.972\n2387 10.018199 2.039819 -1185.375\n2388  9.961567 1.969449 -1184.979\n2389  9.993307 2.017328 -1184.919\n2390 10.022661 1.988271 -1184.676\n2391 10.013272 1.983221 -1184.650\n2392 10.104139 2.003194 -1185.892\n2393 10.074948 1.997669 -1185.255\n2394  9.971750 2.009309 -1184.942\n2395  9.984299 2.017456 -1184.962\n2396 10.021063 2.022660 -1185.008\n2397 10.021063 2.022660 -1185.008\n2398 10.015794 2.044034 -1185.482\n2399  9.961405 1.961976 -1185.060\n2400 10.066609 1.975179 -1185.122\n2401 10.086157 1.975291 -1185.467\n2402  9.911155 1.959577 -1186.021\n2403 10.037064 2.064724 -1186.241\n2404 10.073630 2.017654 -1185.441\n2405  9.922430 1.968212 -1185.650\n2406 10.119643 2.109112 -1189.569\n2407 10.104802 2.082074 -1187.928\n2408 10.030547 1.931214 -1185.496\n2409 10.031273 1.915530 -1186.037\n2410  9.995542 2.068370 -1186.289\n2411  9.933636 1.965445 -1185.449\n2412 10.048858 2.031748 -1185.377\n2413 10.089089 1.957218 -1185.724\n2414 10.024523 1.988828 -1184.685\n2415 10.024523 1.988828 -1184.685\n2416  9.955870 1.979516 -1184.990\n2417 10.061922 1.980336 -1185.031\n2418 10.048088 2.009771 -1184.997\n2419  9.952477 1.974218 -1185.062\n2420 10.067084 1.970425 -1185.162\n2421  9.925295 1.943385 -1185.998\n2422 10.035145 2.025279 -1185.128\n2423  9.987848 1.961318 -1184.843\n2424 10.004532 2.012775 -1184.830\n2425 10.090753 2.048003 -1186.417\n2426 10.016531 1.933565 -1185.368\n2427 10.013914 2.026384 -1185.060\n2428 10.051367 2.044980 -1185.732\n2429  9.905774 2.049347 -1186.854\n2430 10.094035 1.963019 -1185.750\n2431 10.052460 1.919658 -1186.080\n2432 10.085840 2.034988 -1185.987\n2433 10.100280 1.911338 -1187.309\n2434  9.954787 2.080047 -1187.063\n2435 10.004275 1.984499 -1184.645\n2436 10.018048 1.936794 -1185.284\n2437 10.000103 1.998088 -1184.691\n2438  9.986822 1.971761 -1184.746\n2439  9.931527 2.036252 -1185.964\n2440 10.015894 2.065884 -1186.189\n2441  9.896114 2.017453 -1186.416\n2442  9.922120 2.018364 -1185.802\n2443 10.076276 2.006898 -1185.350\n2444  9.941277 1.953606 -1185.479\n2445 10.067217 2.007245 -1185.208\n2446 10.048012 1.995352 -1184.877\n2447  9.971371 1.983524 -1184.809\n2448 10.054024 2.018948 -1185.189\n2449 10.002937 1.998939 -1184.692\n2450 10.063501 2.026908 -1185.450\n2451 10.118633 2.019219 -1186.446\n2452 10.078194 2.027253 -1185.684\n2453 10.058908 2.016689 -1185.213\n2454  9.995715 1.989080 -1184.664\n2455 10.007633 1.977832 -1184.659\n2456 10.021365 1.973798 -1184.704\n2457  9.974289 2.007359 -1184.899\n2458  9.966523 2.016159 -1185.082\n2459  9.966523 2.016159 -1185.082\n2460 10.040748 1.963789 -1184.910\n2461  9.940737 1.983923 -1185.207\n2462 10.017730 2.002797 -1184.733\n2463 10.010224 1.984442 -1184.645\n2464  9.976219 1.986135 -1184.767\n2465 10.019576 2.042227 -1185.442\n2466  9.984609 2.010431 -1184.863\n2467  9.897625 1.976461 -1186.204\n2468  9.975296 1.928721 -1185.637\n2469  9.975296 1.928721 -1185.637\n2470  9.975286 2.051738 -1185.821\n2471 10.061303 1.929160 -1185.877\n2472 10.008403 1.912089 -1186.095\n2473 10.014927 2.062503 -1186.064\n2474 10.002458 2.070693 -1186.365\n2475 10.017167 1.941075 -1185.174\n2476 10.040034 2.048483 -1185.729\n2477 10.079338 2.019872 -1185.572\n2478 10.010518 1.975244 -1184.672\n2479 10.026316 1.987117 -1184.691\n2480 10.077990 2.012987 -1185.449\n2481  9.949553 1.970627 -1185.130\n2482  9.957519 2.042007 -1185.716\n2483 10.073146 1.966102 -1185.301\n2484 10.091116 2.027735 -1185.937\n2485  9.897803 1.945715 -1186.641\n2486  9.849673 1.974970 -1187.857\n2487  9.871807 1.937613 -1187.692\n2488 10.183983 2.040797 -1189.134\n2489 10.104325 1.936310 -1186.537\n2490 10.027406 2.036420 -1185.325\n2491 10.040976 2.019618 -1185.071\n2492 10.105090 2.004073 -1185.922\n2493 10.014622 1.939717 -1185.202\n2494 10.077717 2.068231 -1186.847\n2495  9.925932 1.957524 -1185.710\n2496  9.925932 1.957524 -1185.710\n2497  9.964634 1.889720 -1187.419\n2498 10.059402 2.066198 -1186.510\n2499  9.955790 2.044755 -1185.811\n2500 10.018671 1.964380 -1184.775\n2501 10.002713 2.006802 -1184.761\n2502 10.097468 1.978164 -1185.696\n2503 10.032110 1.954496 -1184.973\n2504 10.023791 1.941678 -1185.183\n2505  9.963071 1.973454 -1184.932\n2506 10.087759 2.064336 -1186.883\n2507 10.058451 2.063511 -1186.401\n2508  9.971379 2.009578 -1184.949\n2509  9.983875 2.018181 -1184.976\n2510 10.018598 1.950009 -1184.988\n2511 10.018598 1.950009 -1184.988\n2512 10.059440 1.922750 -1186.062\n2513 10.044224 1.985276 -1184.817\n2514  9.970929 1.991582 -1184.820\n2515  9.976916 1.984662 -1184.761\n2516  9.976916 1.984662 -1184.761\n2517  9.978811 1.987118 -1184.748\n2518  9.959981 2.002901 -1184.999\n2519 10.126753 1.965410 -1186.594\n2520 10.126753 1.965410 -1186.594\n2521  9.975921 1.936839 -1185.399\n2522 10.091634 1.980503 -1185.557\n2523  9.967845 1.931871 -1185.613\n2524 10.092014 2.046750 -1186.407\n2525 10.079374 2.036324 -1185.900\n2526  9.996324 1.957410 -1184.863\n2527 10.093572 1.932121 -1186.394\n2528 10.154405 1.928320 -1188.422\n2529  9.875562 1.997318 -1186.855\n2530 10.117273 1.993740 -1186.183\n2531 10.046441 1.985440 -1184.838\n2532 10.032960 1.953774 -1184.991\n2533  9.984298 2.002660 -1184.784\n2534 10.067179 2.012231 -1185.265\n2535  9.949066 1.969840 -1185.143\n2536  9.949066 1.969840 -1185.143\n2537 10.056898 1.962367 -1185.101\n2538  9.975195 1.953444 -1185.045\n2539  9.929806 2.037459 -1186.025\n2540  9.934347 2.002670 -1185.382\n2541 10.020840 1.965955 -1184.765\n2542  9.955889 2.031224 -1185.476\n2543 10.006133 2.006433 -1184.754\n2544 10.017717 1.959141 -1184.837\n2545 10.001723 1.989122 -1184.651\n2546 10.001723 1.989122 -1184.651\n2547 10.057772 2.035109 -1185.552\n2548 10.047104 2.038529 -1185.519\n2549 10.052066 1.940096 -1185.451\n2550  9.976796 2.027759 -1185.196\n2551 10.096021 1.973507 -1185.691\n2552 10.037731 1.954869 -1185.008\n2553 10.073901 2.026580 -1185.599\n2554 10.061874 2.005428 -1185.114\n2555  9.974594 2.016799 -1185.019\n2556  9.954560 1.955559 -1185.239\n2557 10.005627 1.984281 -1184.645\n2558  9.983253 2.006724 -1184.829\n2559  9.985427 1.968950 -1184.775\n2560  9.893958 2.040060 -1186.911\n2561  9.959271 1.952674 -1185.226\n2562 10.094369 2.026372 -1185.978\n2563  9.923184 1.949985 -1185.902\n2564 10.003046 1.939153 -1185.211\n2565  9.975389 2.024908 -1185.151\n2566 10.123164 1.949309 -1186.751\n2567  9.953292 2.002414 -1185.080\n2568 10.027063 2.000021 -1184.746\n2569 10.024846 1.994054 -1184.702\n2570  9.994447 1.966780 -1184.755\n2571  9.948690 1.975127 -1185.111\n2572 10.035344 2.032108 -1185.271\n2573 10.022638 2.049599 -1185.662\n2574 10.026318 2.050816 -1185.714\n2575  9.993986 1.963986 -1184.786\n2576 10.010602 1.998141 -1184.686\n2577  9.967890 1.967225 -1184.930\n2578 10.001669 2.038164 -1185.323\n2579  9.995599 2.039730 -1185.375\n2580 10.020262 2.062057 -1186.061\n2581  9.909359 2.068814 -1187.410\n2582  9.913859 1.983682 -1185.754\n2583 10.024034 1.921904 -1185.761\n2584  9.959221 2.068581 -1186.551\n2585  9.900015 2.004168 -1186.164\n2586  9.979069 1.978600 -1184.758\n2587 10.074850 1.988769 -1185.224\n2588  9.948761 2.023716 -1185.422\n2589  9.968295 1.960360 -1185.005\n2590 10.004386 1.992923 -1184.659\n2591 10.037754 2.020886 -1185.067\n2592  9.953148 1.960032 -1185.193\n2593  9.957140 1.965253 -1185.075\n2594  9.957371 1.989206 -1184.963\n2595  9.909733 1.865278 -1190.071\n2596 10.026959 1.978923 -1184.704\n2597 10.005329 2.009087 -1184.784\n2598  9.941461 2.039536 -1185.875\n2599 10.004669 2.061345 -1186.017\n2600  9.993124 1.896864 -1186.817\n2601  9.959459 1.990985 -1184.941\n2602 10.047439 1.944171 -1185.304\n2603 10.073065 2.007978 -1185.307\n2604  9.985724 1.932993 -1185.435\n2605  9.986773 2.036188 -1185.321\n2606 10.010238 1.947622 -1185.019\n2607  9.918391 1.993227 -1185.654\n2608 10.096475 1.963132 -1185.804\n2609  9.972736 2.025469 -1185.183\n2610 10.055110 1.976939 -1184.955\n2611  9.928902 1.974586 -1185.462\n2612  9.928902 1.974586 -1185.462\n2613  9.871502 1.999103 -1186.998\n2614  9.871502 1.999103 -1186.998\n2615  9.934446 2.014818 -1185.511\n2616 10.060133 2.012720 -1185.173\n2617  9.977417 1.946499 -1185.159\n2618 10.080275 2.028601 -1185.747\n2619  9.875997 2.005158 -1186.885\n2620  9.964717 1.976114 -1184.898\n2621 10.076657 2.061332 -1186.582\n2622 10.112052 2.061490 -1187.313\n2623 10.084875 2.040302 -1186.096\n2624  9.898298 1.976247 -1186.187\n2625 10.001097 1.917734 -1185.879\n2626 10.041317 2.038489 -1185.466\n2627 10.028444 1.918879 -1185.893\n2628 10.007666 1.968323 -1184.719\n2629  9.974188 2.000499 -1184.838\n2630 10.008916 1.965146 -1184.750\n2631  9.936759 1.939726 -1185.855\n2632 10.102638 2.045246 -1186.594\n2633 10.082527 2.074405 -1187.167\n2634  9.927817 1.918759 -1186.694\n2635 10.015348 1.964077 -1184.770\n2636 10.019508 1.986745 -1184.663\n2637  9.961578 2.027367 -1185.329\n2638  9.946179 2.052105 -1186.154\n2639 10.099445 1.940151 -1186.312\n2640 10.109991 1.999001 -1186.010\n2641 10.089935 1.985181 -1185.511\n2642  9.933892 2.043009 -1186.091\n2643  9.988298 1.965483 -1184.793\n2644  9.936444 1.952310 -1185.588\n2645 10.099732 2.020092 -1185.987\n2646 10.029027 1.995316 -1184.728\n2647  9.995969 1.970962 -1184.714\n2648  9.965105 2.024033 -1185.227\n2649 10.107707 1.955172 -1186.201\n2650 10.154682 2.038772 -1187.947\n2651 10.028959 1.897089 -1186.843\n2652 10.028959 1.897089 -1186.843\n2653 10.032626 2.022168 -1185.054\n2654 10.007399 1.959284 -1184.821\n2655  9.962696 2.009267 -1185.032\n2656  9.990731 1.957051 -1184.889\n2657  9.990852 1.991839 -1184.689\n2658 10.017313 2.030217 -1185.146\n2659 10.058994 2.030747 -1185.470\n2660 10.058994 2.030747 -1185.470\n2661 10.030199 1.994230 -1184.730\n2662  9.995831 1.968880 -1184.731\n2663 10.010675 2.056959 -1185.868\n2664 10.031348 2.004538 -1184.807\n2665 10.022134 2.023200 -1185.022\n2666  9.910979 2.001851 -1185.869\n2667 10.007339 2.019418 -1184.929\n2668  9.926466 2.011204 -1185.617\n2669  9.894971 2.014326 -1186.406\n2670 10.003104 1.984878 -1184.646\n2671 10.003104 1.984878 -1184.646\n2672  9.923617 1.972417 -1185.587\n2673 10.022072 1.983088 -1184.673\n2674 10.002988 1.990389 -1184.653\n2675 10.059151 1.993496 -1184.999\n2676  9.964742 2.046281 -1185.753\n2677 10.065895 1.999657 -1185.124\n2678  9.996748 1.907062 -1186.323\n2679  9.993828 2.055130 -1185.828\n2680  9.916436 1.938027 -1186.336\n2681  9.949922 2.047368 -1185.961\n2682 10.124693 2.010924 -1186.510\n2683  9.940104 2.078891 -1187.217\n2684 10.062595 1.894861 -1187.317\n2685  9.941669 1.996311 -1185.214\n2686 10.093544 1.956309 -1185.836\n2687  9.965762 2.010147 -1185.009\n2688 10.097919 2.034581 -1186.224\n2689 10.090911 1.940056 -1186.115\n2690 10.063637 1.955020 -1185.300\n2691 10.016734 1.947996 -1185.022\n2692  9.964953 1.977951 -1184.887\n2693 10.000974 2.038162 -1185.324\n2694  9.937656 1.981675 -1185.265\n2695  9.946668 1.930593 -1185.935\n2696  9.946668 1.930593 -1185.935\n2697 10.058429 2.012897 -1185.154\n2698 10.087136 2.019828 -1185.717\n2699 10.064013 2.003788 -1185.129\n2700 10.041906 2.019054 -1185.070\n2701  9.982121 1.960510 -1184.887\n2702  9.949915 2.031130 -1185.553\n2703  9.960728 2.026486 -1185.321\n2704  9.947344 1.980954 -1185.107\n2705  9.975569 1.955268 -1185.012\n2706  9.974187 2.055598 -1185.952\n2707 10.071815 1.985898 -1185.172\n2708  9.947246 1.987856 -1185.102\n2709 10.007192 1.892580 -1187.010\n2710 10.003064 1.925226 -1185.613\n2711 10.090166 1.973290 -1185.564\n2712  9.955154 1.967175 -1185.081\n2713 10.030097 2.018370 -1184.976\n2714  9.965204 1.971853 -1184.919\n2715 10.043550 1.982139 -1184.814\n2716 10.020469 1.996750 -1184.698\n2717  9.987005 1.958110 -1184.891\n2718 10.049218 2.004565 -1184.954\n2719  9.953042 2.081150 -1187.131\n2720 10.006522 1.897414 -1186.761\n2721 10.074390 1.986849 -1185.215\n2722  9.988704 1.978111 -1184.702\n2723 10.005502 2.027789 -1185.084\n2724  9.913015 2.025598 -1186.123\n2725 10.038128 2.003455 -1184.844\n2726 10.014967 2.079013 -1186.707\n2727  9.968143 1.901637 -1186.768\n2728  9.937803 1.895032 -1187.554\n2729  9.919717 1.921125 -1186.790\n2730 10.062417 1.951734 -1185.339\n2731 10.000796 1.977566 -1184.665\n2732  9.896861 2.004024 -1186.249\n2733  9.991429 2.034709 -1185.266\n2734 10.013018 1.930042 -1185.463\n2735 10.026386 1.916090 -1185.986\n2736  9.925821 2.056415 -1186.634\n2737  9.994378 1.999569 -1184.715\n2738  9.955160 1.984804 -1184.989\n2739 10.041481 2.092079 -1187.420\n2740  9.924099 1.994526 -1185.535\n2741  9.911659 2.057236 -1186.957\n2742 10.108125 1.999292 -1185.964\n2743 10.080803 2.001350 -1185.382\n2744  9.994447 2.011306 -1184.831\n2745  9.919657 2.042487 -1186.352\n2746  9.938038 1.979667 -1185.264\n2747 10.075107 1.986212 -1185.227\n2748 10.063498 1.994379 -1185.061\n2749  9.980919 1.977269 -1184.750\n2750  9.966712 2.065790 -1186.369\n2751  9.975078 2.031055 -1185.278\n2752 10.071834 2.009465 -1185.303\n2753 10.070266 1.937969 -1185.766\n2754 10.005207 1.959741 -1184.815\n2755  9.972729 1.982436 -1184.798\n2756  9.949661 1.944703 -1185.518\n2757  9.961586 1.994940 -1184.929\n2758 10.034677 1.955440 -1184.976\n2759 10.055087 2.002005 -1184.998\n2760 10.022602 2.022410 -1185.009\n2761 10.037025 2.036780 -1185.391\n2762 10.015848 1.919301 -1185.826\n2763 10.019637 2.003054 -1184.741\n2764  9.959519 2.026424 -1185.334\n2765 10.021267 1.953346 -1184.938\n2766 10.004931 2.027810 -1185.084\n2767 10.042980 1.940672 -1185.340\n2768 10.000971 2.043596 -1185.466\n2769  9.996127 2.054236 -1185.793\n2770 10.110221 2.005502 -1186.062\n2771 10.002244 2.009165 -1184.787\n2772  9.995861 1.956242 -1184.882\n2773 10.040857 1.997929 -1184.824\n2774 10.098172 2.027949 -1186.091\n2775 10.019306 2.046267 -1185.554\n2776 10.013416 1.941283 -1185.162\n2777 10.035299 1.918768 -1185.942\n2778  9.989767 2.060586 -1186.026\n2779  9.960848 2.030741 -1185.407\n2780 10.008546 1.964638 -1184.756\n2781  9.951631 2.003985 -1185.116\n2782  9.989882 1.970265 -1184.742\n2783 10.119659 1.975569 -1186.286\n2784  9.888373 1.987867 -1186.435\n2785  9.974487 2.073371 -1186.593\n2786 10.044238 2.033223 -1185.366\n2787  9.955619 1.967413 -1185.072\n2788 10.061407 2.085609 -1187.324\n2789 10.032331 2.013045 -1184.910\n2790 10.051654 1.979321 -1184.905\n2791  9.997475 2.054226 -1185.789\n2792 10.066272 1.997643 -1185.117\n2793 10.076805 2.002173 -1185.317\n2794  9.924119 2.013672 -1185.695\n2795  9.999979 2.040678 -1185.390\n2796  9.980990 1.971144 -1184.785\n2797  9.986972 1.971587 -1184.746\n2798  9.957893 2.004401 -1185.038\n2799 10.027060 1.979381 -1184.703\n2800 10.012846 2.076617 -1186.604\n2801 10.024369 1.966170 -1184.777\n2802  9.956248 2.013274 -1185.158\n2803  9.945667 2.015063 -1185.329\n2804 10.022639 1.982489 -1184.676\n2805  9.975198 1.985381 -1184.775\n2806  9.947660 2.067349 -1186.651\n2807 10.047326 2.020441 -1185.142\n2808 10.034447 2.014629 -1184.946\n2809 10.011388 1.970490 -1184.703\n2810 10.011870 1.963657 -1184.769\n2811  9.952686 1.988929 -1185.024\n2812 10.016456 1.980009 -1184.662\n2813 10.009885 1.906522 -1186.333\n2814  9.888204 1.999935 -1186.470\n2815 10.092276 2.072734 -1187.283\n2816 10.139136 1.952858 -1187.199\n2817 10.116980 1.959056 -1186.392\n2818  9.968817 1.935475 -1185.501\n2819 10.037618 2.057932 -1186.008\n2820 10.064664 1.999392 -1185.105\n2821  9.951145 1.956209 -1185.278\n2822 10.068722 2.027434 -1185.535\n2823  9.972004 1.936750 -1185.436\n2824 10.094736 2.011951 -1185.763\n2825 10.010439 1.991061 -1184.653\n2826  9.999839 1.986226 -1184.651\n2827 10.049031 1.976219 -1184.889\n2828  9.953746 1.989456 -1185.010\n2829  9.974124 2.003203 -1184.860\n2830 10.081601 1.904523 -1187.183\n2831 10.005537 1.994725 -1184.666\n2832  9.898318 2.020324 -1186.399\n2833  9.913653 2.016619 -1185.963\n2834  9.904383 2.014235 -1186.155\n2835 10.082851 2.015437 -1185.570\n2836 10.005170 2.018044 -1184.907\n2837  9.982055 1.964442 -1184.840\n2838  9.984576 2.032064 -1185.237\n2839 10.006360 1.949389 -1184.983\n2840  9.983130 1.949041 -1185.067\n2841 10.032367 1.980305 -1184.731\n2842  9.982779 1.968940 -1184.791\n2843  9.982779 1.968940 -1184.791\n2844  9.957645 1.987195 -1184.957\n2845 10.075677 2.017267 -1185.469\n2846  9.896962 2.030452 -1186.616\n2847  9.925099 2.005858 -1185.588\n2848  9.896688 2.021554 -1186.462\n2849  9.887590 2.020265 -1186.698\n2850  9.880248 2.032236 -1187.133\n2851  9.880248 2.032236 -1187.133\n2852 10.108303 2.008692 -1186.043\n2853  9.906496 1.953701 -1186.237\n2854  9.868239 1.988321 -1187.092\n2855  9.967784 2.027831 -1185.274\n2856 10.076735 2.022318 -1185.568\n2857  9.941380 2.052162 -1186.228\n2858 10.086571 1.926825 -1186.405\n2859 10.028208 2.078963 -1186.749\n2860 10.036277 2.060975 -1186.102\n2861 10.001586 1.911895 -1186.108\n2862 10.014165 1.893678 -1186.959\n2863  9.998869 1.876731 -1187.943\n2864 10.045765 1.850981 -1190.009\n2865  9.924208 2.060850 -1186.812\n2866 10.017652 2.032132 -1185.189\n2867 10.012738 2.055345 -1185.817\n2868 10.090860 2.008802 -1185.645\n2869 10.098043 2.004823 -1185.762\n2870  9.913899 1.953653 -1186.050\n2871  9.943391 1.961556 -1185.322\n2872 10.055493 1.993560 -1184.953\n2873 10.053443 1.874010 -1188.411\n2874 10.044451 1.884139 -1187.675\n2875  9.969736 2.028252 -1185.264\n2876 10.002130 2.025106 -1185.034\n2877 10.030010 1.941729 -1185.215\n2878  9.951392 2.011913 -1185.204\n2879 10.019713 1.912801 -1186.087\n2880  9.987625 1.968422 -1184.768\n2881 10.054949 1.968743 -1185.009\n2882 10.051774 2.015651 -1185.113\n2883 10.051774 2.015651 -1185.113\n2884 10.085645 1.915462 -1186.797\n2885  9.958084 2.022165 -1185.272\n2886  9.964108 2.034982 -1185.467\n2887 10.006540 1.908004 -1186.267\n2888  9.980890 2.011182 -1184.895\n2889 10.010990 1.952656 -1184.926\n2890 10.010858 2.003756 -1184.730\n2891 10.010858 2.003756 -1184.730\n2892 10.109676 1.993187 -1185.978\n2893 10.134656 1.978107 -1186.730\n2894  9.965118 2.029340 -1185.331\n2895 10.086524 2.050346 -1186.403\n2896 10.138918 2.069591 -1188.342\n2897 10.068846 1.952191 -1185.429\n2898  9.934635 1.999186 -1185.352\n2899  9.915396 1.988506 -1185.714\n2900  9.889539 2.009346 -1186.504\n2901  9.997318 1.982936 -1184.658\n2902  9.997318 1.982936 -1184.658\n2903 10.016149 2.012337 -1184.833\n2904 10.056394 1.930401 -1185.771\n2905  9.934282 2.009777 -1185.451\n2906 10.048005 1.966790 -1184.948\n2907 10.014908 2.040953 -1185.398\n2908 10.040305 1.962422 -1184.922\n2909  9.919386 2.033438 -1186.140\n2910  9.904628 2.041335 -1186.665\n2911 10.105034 1.932552 -1186.664\n2912  9.937885 1.983157 -1185.258\n2913 10.023815 2.068616 -1186.314\n2914 10.017256 2.052530 -1185.736\n2915 10.002084 1.972870 -1184.688\n2916 10.000741 1.990127 -1184.655\n2917  9.990866 2.008028 -1184.805\n2918 10.061177 2.001389 -1185.070\n2919  9.956333 1.962412 -1185.118\n2920  9.999647 1.895865 -1186.847\n2921 10.048509 1.937582 -1185.474\n2922  9.937343 2.017011 -1185.492\n2923  9.954516 1.957353 -1185.212\n2924 10.038166 1.959038 -1184.949\n2925 10.045760 1.978349 -1184.846\n2926  9.953258 2.012679 -1185.189\n2927 10.022300 1.927302 -1185.574\n2928  9.972077 1.934115 -1185.507\n2929 10.071985 2.033627 -1185.716\n2930  9.975822 2.001402 -1184.832\n2931  9.969025 2.007158 -1184.943\n2932 10.012424 1.928826 -1185.499\n2933 10.079032 1.992541 -1185.305\n2934 10.089318 1.985582 -1185.497\n2935  9.952266 1.918829 -1186.245\n2936 10.060890 2.067148 -1186.563\n2937 10.031534 1.952168 -1185.009\n2938 10.008354 2.009595 -1184.789\n2939  9.922956 1.910963 -1187.115\n2940 10.041473 1.927179 -1185.705\n2941  9.941796 2.006949 -1185.292\n2942 10.038990 2.051793 -1185.820\n2943  9.937272 1.934025 -1185.999\n2944 10.071335 2.019763 -1185.437\n2945  9.964197 1.938103 -1185.482\n2946  9.992645 1.947506 -1185.049\n2947 10.089766 1.917510 -1186.808\n2948 10.121579 1.921670 -1187.500\n2949  9.937626 1.896030 -1187.506\n2950  9.946989 1.922081 -1186.209\n2951 10.051202 2.026627 -1185.295\n2952  9.955741 2.017761 -1185.229\n2953 10.043824 1.957720 -1185.017\n2954  9.959035 1.993369 -1184.953\n2955 10.051582 2.022569 -1185.223\n2956  9.989325 2.029280 -1185.153\n2957  9.922028 1.986211 -1185.566\n2958  9.922028 1.986211 -1185.566\n2959 10.015503 2.064363 -1186.132\n2960  9.981095 1.981611 -1184.735\n2961 10.028798 1.994702 -1184.724\n2962  9.903541 2.056774 -1187.133\n2963 10.054950 1.998578 -1184.972\n2964 10.028334 2.060543 -1186.041\n2965 10.030507 1.930911 -1185.505\n2966 10.018472 1.945871 -1185.070\n2967 10.081418 2.006690 -1185.439\n2968  9.930865 1.978075 -1185.404\n2969 10.082575 1.984039 -1185.364\n2970  9.972963 1.922748 -1185.854\n2971 10.058864 2.054491 -1186.101\n2972 10.070510 2.049875 -1186.118\n2973  9.940958 1.940048 -1185.771\n2974  9.960227 2.006764 -1185.033\n2975 10.120156 2.024769 -1186.577\n2976 10.117681 2.023464 -1186.487\n2977 10.036576 1.966694 -1184.845\n2978  9.997855 2.014521 -1184.865\n2979  9.814948 1.949530 -1189.848\n2980  9.964213 2.019700 -1185.161\n2981  9.932094 2.023206 -1185.686\n2982 10.090105 1.958633 -1185.724\n2983 10.073459 1.959441 -1185.389\n2984  9.934440 1.971150 -1185.379\n2985  9.913378 1.969828 -1185.843\n2986 10.100867 1.961000 -1185.937\n2987  9.889636 2.039937 -1187.027\n2988  9.955217 1.950965 -1185.310\n2989 10.035909 2.031276 -1185.256\n2990  9.947622 1.984610 -1185.096\n2991  9.967321 1.986078 -1184.847\n2992 10.050243 1.969357 -1184.948\n2993 10.059178 1.967514 -1185.074\n2994  9.936459 2.019048 -1185.538\n2995  9.953766 1.990085 -1185.011\n2996 10.004498 2.004541 -1184.736\n2997 10.005353 1.966245 -1184.739\n2998  9.928778 1.986869 -1185.425\n2999 10.017094 1.961126 -1184.809\n3000 10.017094 1.961126 -1184.809\n3001  9.965247 2.046326 -1185.749\n3002  9.989193 1.983945 -1184.686\n3003  9.956713 2.028487 -1185.409\n3004 10.049307 1.998778 -1184.910\n3005 10.119669 2.007873 -1186.336\n3006 10.148766 2.011454 -1187.286\n3007 10.085267 2.048899 -1186.337\n3008 10.040394 2.052173 -1185.843\n3009  9.964323 1.934152 -1185.587\n3010 10.016464 1.973310 -1184.692\n3011 10.008515 2.006028 -1184.750\n3012 10.064011 1.996652 -1185.079\n3013 10.043833 1.951356 -1185.122\n3014  9.991702 1.968840 -1184.746\n3015 10.088518 1.962100 -1185.641\n3016  9.899431 1.954208 -1186.421\n3017  9.983786 1.967382 -1184.799\n3018 10.071053 2.000995 -1185.212\n3019  9.901326 2.047449 -1186.910\n3020 10.090593 1.974820 -1185.562\n3021  9.986237 1.986853 -1184.701\n3022 10.036523 1.976745 -1184.773\n3023 10.050196 1.983221 -1184.879\n3024 10.010637 1.973106 -1184.684\n3025  9.939060 2.090333 -1187.737\n3026  9.954119 2.061747 -1186.363\n3027  9.865214 2.028019 -1187.542\n3028 10.035796 2.071237 -1186.478\n3029 10.039813 2.047800 -1185.707\n3030 10.110360 2.014582 -1186.163\n3031 10.044608 1.977275 -1184.839\n3032 10.014404 1.920955 -1185.764\n3033  9.954188 1.926556 -1185.947\n3034  9.903921 1.987265 -1185.998\n3035 10.041802 1.957208 -1185.006\n3036 10.021596 1.941819 -1185.171\n3037 10.022338 1.971300 -1184.724\n3038 10.061146 1.989804 -1185.015\n3039  9.949568 1.935937 -1185.736\n3040  9.933927 1.927508 -1186.261\n3041 10.115270 2.030140 -1186.547\n3042 10.087858 2.046632 -1186.322\n3043 10.084275 2.003479 -1185.464\n3044 10.047418 2.020183 -1185.139\n3045 10.034699 1.995171 -1184.762\n3046  9.972379 1.983361 -1184.800\n3047  9.984318 2.014857 -1184.923\n3048  9.893122 1.949009 -1186.706\n3049  9.966316 2.006915 -1184.968\n3050  9.955027 2.009037 -1185.121\n3051  9.911158 1.948266 -1186.223\n3052  9.924733 1.981654 -1185.516\n3053  9.933027 1.975609 -1185.375\n3054 10.101574 2.047770 -1186.640\n3055 10.077896 2.043359 -1186.052\n3056  9.913614 2.015112 -1185.943\n3057 10.032829 1.950426 -1185.049\n3058 10.038626 1.893668 -1187.090\n3059 10.016596 1.915378 -1185.976\n3060  9.983931 1.892050 -1187.115\n3061 10.034779 2.024254 -1185.106\n3062  9.950200 1.966508 -1185.158\n3063  9.997685 1.992445 -1184.668\n3064 10.040533 1.934469 -1185.479\n3065 10.055937 1.917250 -1186.214\n3066  9.973891 2.033490 -1185.342\n3067 10.018016 1.973254 -1184.697\n3068  9.930274 1.972233 -1185.451\n3069  9.933538 2.047459 -1186.220\n3070 10.013009 1.958860 -1184.831\n3071 10.007602 1.992114 -1184.655\n3072 10.102063 2.013784 -1185.951\n3073 10.120868 2.026316 -1186.625\n3074  9.921353 1.980183 -1185.593\n3075  9.935322 2.025397 -1185.667\n3076  9.987281 2.037139 -1185.342\n3077 10.068614 1.941806 -1185.643\n3078 10.063614 1.948123 -1185.426\n3079 10.034820 1.986207 -1184.740\n3080 10.020084 2.010483 -1184.820\n3081 10.047307 1.969582 -1184.915\n3082 10.037033 1.924646 -1185.749\n3083  9.973775 1.972625 -1184.830\n3084 10.039814 1.999584 -1184.827\n3085  9.993434 2.010069 -1184.819\n3086  9.963022 2.023457 -1185.239\n3087  9.979368 2.014944 -1184.956\n3088  9.864317 1.964618 -1187.404\n3089 10.152065 2.008953 -1187.378\n3090 10.039620 1.987533 -1184.777\n3091 10.016346 1.998938 -1184.700\n3092  9.995927 2.014533 -1184.870\n3093 10.172515 1.967269 -1188.256\n3094 10.064439 1.966262 -1185.161\n3095  9.964135 2.007670 -1184.998\n3096 10.018317 1.942909 -1185.135\n3097  9.995326 1.974009 -1184.696\n3098  9.992247 2.021351 -1184.989\n3099 10.006721 1.976316 -1184.665\n3100  9.921502 1.966189 -1185.691\n3101  9.945901 1.950457 -1185.459\n3102 10.025481 1.924762 -1185.671\n3103 10.028333 1.936224 -1185.343\n3104  9.987673 2.037402 -1185.346\n3105 10.085031 1.998203 -1185.442\n3106 10.043664 2.020665 -1185.112\n3107 10.011470 2.040467 -1185.380\n3108  9.928769 2.017629 -1185.657\n3109  9.964611 1.972435 -1184.921\n3110 10.005783 1.943825 -1185.099\n3111 10.049906 1.995118 -1184.896\n3112 10.037153 1.925991 -1185.706\n3113 10.019423 2.048177 -1185.609\n3114  9.990138 2.040443 -1185.413\n3115  9.971097 2.000528 -1184.865\n3116  9.981367 1.981429 -1184.734\n3117 10.060759 1.985936 -1185.007\n3118  9.998444 1.981897 -1184.657\n3119 10.011723 1.985867 -1184.647\n3120  9.971703 2.004501 -1184.893\n3121 10.060676 1.990870 -1185.011\n3122 10.020606 1.972893 -1184.707\n3123 10.127648 2.053030 -1187.458\n3124  9.828819 1.944431 -1189.297\n3125  9.934710 2.000267 -1185.358\n3126 10.098795 1.944159 -1186.198\n3127  9.898734 1.982233 -1186.146\n3128 10.029349 2.034321 -1185.285\n3129 10.015490 1.957197 -1184.860\n3130  9.953661 2.033634 -1185.558\n3131 10.041878 2.031986 -1185.318\n3132  9.944825 1.988525 -1185.140\n3133  9.937748 2.065526 -1186.734\n3134  9.951312 2.063297 -1186.454\n3135 10.030655 1.990367 -1184.719\n3136  9.961775 2.020437 -1185.200\n3137 10.021038 1.936361 -1185.305\n3138 10.021937 1.949764 -1185.004\n3139  9.995334 2.024907 -1185.044\n3140  9.960825 1.979709 -1184.928\n3141  9.886186 2.008145 -1186.591\n3142 10.127709 1.964741 -1186.632\n3143  9.922065 1.966517 -1185.675\n3144 10.014194 1.957521 -1184.852\n3145 10.072834 2.057836 -1186.403\n3146  9.978928 2.054680 -1185.888\n3147  9.976867 2.013720 -1184.957\n3148 10.038337 2.078832 -1186.804\n3149 10.044541 1.974541 -1184.852\n3150  9.974800 1.882680 -1187.716\n3151 10.009010 1.893581 -1186.958\n3152 10.037570 1.940216 -1185.304\n3153  9.955979 1.981408 -1184.984\n3154 10.071403 2.033119 -1185.695\n3155 10.011679 2.003701 -1184.730\n3156 10.034073 1.926770 -1185.657\n3157  9.971463 2.006854 -1184.918\n3158 10.041084 1.966222 -1184.887\n3159 10.010248 1.986989 -1184.646\n3160 10.018276 1.997029 -1184.693\n3161 10.122807 1.941275 -1186.927\n3162  9.873087 1.993170 -1186.926\n3163 10.141505 1.980446 -1186.947\n3164 10.136686 2.012878 -1186.897\n3165 10.099227 2.030866 -1186.173\n3166  9.912432 2.037095 -1186.377\n3167  9.901606 2.013468 -1186.217\n3168 10.048937 1.987988 -1184.865\n3169 10.001211 2.018105 -1184.912\n3170 10.008738 1.957340 -1184.849\n3171  9.981145 2.003547 -1184.811\n3172 10.023606 2.016876 -1184.921\n3173 10.060800 1.961116 -1185.169\n3174 10.043973 2.052072 -1185.869\n3175  9.973332 1.923355 -1185.829\n3176  9.932916 2.020398 -1185.623\n3177  9.907891 2.003177 -1185.954\n3178 10.006262 1.926543 -1185.568\n3179  9.932081 1.981002 -1185.370\n3180  9.988533 2.083343 -1186.928\n3181 10.026626 2.013875 -1184.891\n3182  9.997531 1.963845 -1184.777\n3183 10.020919 2.007580 -1184.789\n3184 10.112377 1.956889 -1186.297\n3185  9.950627 2.043932 -1185.855\n3186 10.080721 1.887630 -1188.037\n3187 10.105768 1.962445 -1186.039\n3188  9.971828 1.971420 -1184.856\n3189  9.957802 1.987455 -1184.955\n3190  9.965662 1.981662 -1184.868\n3191  9.982521 1.978482 -1184.735\n3192 10.009972 1.984134 -1184.645\n3193  9.994714 1.978289 -1184.677\n3194  9.993149 1.986018 -1184.670\n3195 10.018034 1.935390 -1185.321\n3196  9.994987 2.040851 -1185.406\n3197 10.099149 1.998712 -1185.744\n3198 10.050559 1.939171 -1185.457\n3199  9.965194 1.981016 -1184.875\n3200 10.051661 1.991894 -1184.903\n3201 10.002199 2.050359 -1185.660\n3202 10.118652 2.015290 -1186.391\n3203  9.958330 1.932022 -1185.721\n3204  9.965173 1.987693 -1184.870\n3205  9.902975 1.976371 -1186.058\n3206  9.914013 2.034352 -1186.278\n3207  9.857560 1.954140 -1187.834\n3208 10.045968 1.956065 -1185.063\n3209  9.972644 1.911859 -1186.269\n3210 10.045432 2.067086 -1186.395\n3211 10.033382 2.047102 -1185.642\n3212 10.100057 2.047142 -1186.588\n3213  9.917698 1.991759 -1185.666\n3214  9.983956 2.013949 -1184.913\n3215  9.992122 2.017632 -1184.928\n3216 10.058469 1.976874 -1184.998\n3217  9.967021 1.991757 -1184.859\n3218  9.948121 1.969391 -1185.161\n3219 10.047496 1.981665 -1184.853\n3220  9.953912 1.966014 -1185.110\n3221  9.953308 1.957408 -1185.228\n3222 10.100935 2.033017 -1186.257\n3223 10.085399 2.045488 -1186.243\n3224 10.046763 1.929048 -1185.698\n3225 10.025805 1.926753 -1185.607\n3226  9.948636 1.944259 -1185.544\n3227  9.957432 1.984103 -1184.960\n3228 10.045902 1.995561 -1184.857\n3229  9.967547 1.977464 -1184.862\n3230 10.046317 1.994098 -1184.855\n3231  9.975438 1.979434 -1184.783\n3232  9.979841 1.991557 -1184.749\n3233  9.979841 1.991557 -1184.749\n3234  9.938339 1.946067 -1185.678\n3235 10.046256 2.064021 -1186.290\n3236 10.035665 1.970293 -1184.806\n3237  9.990146 2.060407 -1186.018\n3238  9.952370 2.031912 -1185.537\n3239 10.060497 1.941637 -1185.524\n3240 10.005732 1.990372 -1184.651\n3241  9.955839 1.960114 -1185.154\n3242  9.967252 1.985558 -1184.847\n3243  9.977900 2.014798 -1184.964\n3244 10.042484 2.019632 -1185.084\n3245  9.939078 1.977000 -1185.257\n3246 10.076656 1.997164 -1185.282\n3247 10.114479 2.064762 -1187.486\n3248 10.109212 2.015728 -1186.149\n3249 10.019045 1.983402 -1184.663\n3250  9.994851 1.994905 -1184.686\n3251  9.965506 1.958257 -1185.063\n3252  9.981106 2.004430 -1184.820\n3253  9.941045 1.994999 -1185.219\n3254  9.880203 1.907208 -1188.522\n3255 10.049871 2.050670 -1185.882\n3256  9.967005 1.926398 -1185.791\n3257  9.950022 1.943307 -1185.544\n3258 10.094467 2.000905 -1185.653\n3259 10.058059 2.052519 -1186.030\n3260 10.070707 1.943346 -1185.641\n3261 10.020265 1.946331 -1185.067\n3262  9.909882 2.003920 -1185.911\n3263 10.116769 1.996536 -1186.178\n3264  9.890410 1.983124 -1186.382\n3265  9.971040 1.960947 -1184.970\n3266  9.909005 1.969512 -1185.954\n3267  9.938153 1.947165 -1185.658\n3268  9.952364 1.918271 -1186.264\n3269  9.986946 2.016518 -1184.934\n3270  9.965120 1.934089 -1185.579\n3271 10.015189 2.008680 -1184.786\n3272 10.003667 1.966046 -1184.742\n3273 10.011959 2.007209 -1184.765\n3274 10.045908 1.944358 -1185.284\n3275  9.969728 2.028197 -1185.263\n3276  9.919631 2.025896 -1185.982\n3277  9.945308 2.031794 -1185.634\n3278  9.960891 1.989455 -1184.920\n3279 10.080805 1.996214 -1185.351\n3280  9.980297 1.997928 -1184.775\n3281 10.085203 2.026347 -1185.794\n3282  9.913007 1.979416 -1185.788\n3283  9.985608 2.001079 -1184.764\n3284  9.972166 1.996552 -1184.830\n3285  9.975308 2.008572 -1184.904\n3286  9.892798 1.969782 -1186.396\n3287 10.030448 1.925335 -1185.679\n3288  9.935720 2.027652 -1185.704\n3289 10.079074 1.947770 -1185.694\n3290 10.027124 2.014056 -1184.895\n3291  9.926383 1.978257 -1185.494\n3292  9.999617 2.003527 -1184.733\n3293 10.067380 1.999023 -1185.142\n3294 10.083252 1.993457 -1185.386\n3295  9.981021 1.969424 -1184.799\n3296  9.927902 2.017475 -1185.672\n3297  9.965837 1.981795 -1184.866\n3298 10.024164 1.980918 -1184.685\n3299  9.948408 1.964413 -1185.207\n3300 10.001612 2.037771 -1185.313\n3301  9.892935 1.929190 -1187.242\n3302 10.122382 2.050793 -1187.245\n3303  9.957656 1.869853 -1188.737\n3304 10.042059 1.929818 -1185.628\n3305  9.999531 1.951733 -1184.948\n3306 10.085191 1.932812 -1186.190\n3307 10.052347 1.980929 -1184.908\n3308  9.929725 2.022803 -1185.723\n3309  9.956117 1.989681 -1184.979\n3310  9.947780 1.966776 -1185.191\n3311  9.941353 1.950576 -1185.532\n3312 10.051267 1.962856 -1185.027\n3313  9.970734 1.969804 -1184.879\n3314 10.004812 2.037898 -1185.313\n3315  9.916356 1.891516 -1188.223\n3316  9.886789 2.036534 -1187.029\n3317 10.045275 2.016221 -1185.056\n3318  9.911340 1.945605 -1186.276\n3319 10.011844 2.099689 -1187.661\n3320 10.008936 2.014495 -1184.854\n3321  9.991762 2.005781 -1184.777\n3322 10.033583 2.022832 -1185.072\n3323  9.983384 2.004306 -1184.804\n3324 10.003857 1.992351 -1184.658\n3325  9.906604 2.014431 -1186.102\n3326 10.022690 1.941458 -1185.184\n3327  9.991404 2.031295 -1185.188\n3328 10.028174 1.964006 -1184.819\n3329  9.987055 2.008645 -1184.829\n3330 10.071360 2.001674 -1185.222\n3331  9.978430 1.997946 -1184.788\n3332 10.000447 2.052668 -1185.734\n3333 10.012859 1.922238 -1185.716\n3334 10.046769 1.971171 -1184.897\n3335 10.112927 2.012468 -1186.203\n3336  9.970567 2.033700 -1185.375\n3337  9.998320 1.915161 -1185.984\n3338  9.969240 1.972910 -1184.870\n3339 10.040604 2.020162 -1185.077\n3340 10.028936 1.959822 -1184.875\n3341 10.003937 2.029487 -1185.120\n3342 10.010388 1.942421 -1185.131\n3343 10.095060 1.981433 -1185.629\n3344  9.935807 1.962979 -1185.437\n3345 10.016015 2.010889 -1184.814\n3346  9.928707 1.943241 -1185.929\n3347 10.088181 2.028897 -1185.901\n3348  9.952828 1.993137 -1185.032\n3349 10.052156 2.002546 -1184.968\n3350 10.018122 1.960183 -1184.824\n3351  9.928204 2.006686 -1185.533\n3352  9.936510 1.998904 -1185.317\n3353  9.930883 1.999089 -1185.421\n3354 10.014563 2.080105 -1186.753\n3355  9.998013 1.900450 -1186.624\n3356  9.993930 1.874318 -1188.113\n3357 10.023601 1.975223 -1184.705\n3358 10.013274 2.055048 -1185.808\n3359  9.935671 2.030868 -1185.770\n3360  9.958770 2.002248 -1185.009\n3361  9.949944 1.972127 -1185.112\n3362 10.048996 1.977769 -1184.881\n3363 10.006805 1.961734 -1184.789\n3364 10.002404 2.020728 -1184.954\n3365  9.994793 1.967180 -1184.750\n3366 10.029335 1.982933 -1184.707\n3367  9.987921 1.993776 -1184.709\n3368 10.018163 1.867436 -1188.568\n3369 10.112801 1.962746 -1186.222\n3370 10.092545 1.967674 -1185.664\n3371  9.999626 1.992575 -1184.664\n3372  9.859158 1.944787 -1187.978\n3373  9.812798 1.953085 -1189.875\n3374  9.852307 1.957744 -1187.976\n3375 10.061263 2.069367 -1186.651\n3376  9.956106 1.973478 -1185.017\n3377  9.958931 1.923546 -1185.983\n3378  9.977336 1.963567 -1184.884\n3379 10.010556 1.936163 -1185.287\n3380 10.044026 1.915686 -1186.136\n3381 10.031536 1.901410 -1186.648\n3382 10.028351 1.899334 -1186.728\n3383 10.064539 1.978949 -1185.073\n3384 10.048590 2.014863 -1185.069\n3385  9.918314 2.030812 -1186.107\n3386 10.076535 2.062304 -1186.614\n3387  9.937039 1.980809 -1185.279\n3388  9.990542 1.965827 -1184.779\n3389  9.990542 1.965827 -1184.779\n3390  9.881793 2.034366 -1187.130\n3391 10.138038 1.948184 -1187.259\n3392  9.933468 1.978744 -1185.351\n3393 10.081607 1.994195 -1185.358\n3394  9.936162 1.979968 -1185.297\n3395 10.049481 1.973229 -1184.911\n3396  9.958379 1.999874 -1184.996\n3397 10.047674 1.989422 -1184.854\n3398 10.081282 1.990477 -1185.341\n3399 10.066180 2.042297 -1185.842\n3400  9.936143 1.943132 -1185.784\n3401 10.028058 1.967350 -1184.784\n3402 10.041724 1.955204 -1185.036\n3403  9.999908 1.926977 -1185.561\n3404  9.984543 2.016581 -1184.948\n3405  9.978018 1.956116 -1184.979\n3406 10.074456 2.004929 -1185.300\n3407 10.046440 2.009430 -1184.977\n3408 10.090667 1.986380 -1185.525\n3409  9.961777 1.989046 -1184.909\n3410 10.052400 1.981035 -1184.908\n3411  9.987545 1.976391 -1184.715\n3412 10.162579 1.990397 -1187.694\n3413 10.120092 1.994238 -1186.263\n3414 10.040312 1.929602 -1185.618\n3415 10.036309 1.907043 -1186.425\n3416  9.966820 1.936538 -1185.494\n3417  9.957823 1.957261 -1185.169\n3418  9.921570 1.960170 -1185.765\n3419 10.066005 1.950538 -1185.415\n3420 10.007322 1.880539 -1187.696\n3421  9.961708 1.897902 -1187.025\n3422 10.003507 1.964609 -1184.758\n3423  9.986515 1.928605 -1185.561\n3424 10.076689 1.968507 -1185.339\n3425  9.945461 2.010314 -1185.271\n3426  9.948647 2.018786 -1185.341\n3427 10.027909 2.005229 -1184.795\n3428  9.946379 1.966498 -1185.216\n3429  9.981299 1.954151 -1184.987\n3430 10.032175 2.018911 -1184.996\n3431  9.995952 2.021033 -1184.972\n3432 10.021104 1.975223 -1184.695\n3433 10.060040 1.978792 -1185.011\n3434 10.037169 1.999238 -1184.804\n3435  9.986362 2.004449 -1184.789\n3436 10.012035 2.021079 -1184.960\n3437 10.020743 1.944540 -1185.106\n3438  9.934856 1.971658 -1185.368\n3439 10.052399 1.964980 -1185.015\n3440  9.959732 1.983578 -1184.932\n3441  9.990114 1.973594 -1184.718\n3442 10.056193 2.009540 -1185.085\n3443 10.007690 1.991040 -1184.652\n3444 10.007690 1.991040 -1184.652\n3445 10.029602 1.958682 -1184.894\n3446 10.034989 2.028855 -1185.198\n3447  9.982744 1.963449 -1184.847\n3448 10.110133 2.020720 -1186.246\n3449 10.158285 2.069096 -1188.963\n3450 10.010657 2.107445 -1188.062\n3451 10.001394 2.096442 -1187.501\n3452 10.091325 1.895931 -1187.818\n3453 10.068769 1.899300 -1187.192\n3454  9.939824 2.001377 -1185.276\n3455 10.046823 2.080498 -1186.944\n3456 10.080365 1.921829 -1186.449\n3457 10.079050 1.975594 -1185.328\n3458 10.018568 1.893054 -1187.003\n3459  9.927144 1.944925 -1185.923\n3460  9.927144 1.944925 -1185.923\n3461  9.899477 1.958017 -1186.355\n3462  9.896022 1.963936 -1186.368\n3463  9.913866 1.954827 -1186.030\n3464  9.937536 1.966866 -1185.362\n3465 10.047374 1.983948 -1184.849\n3466  9.928171 1.996155 -1185.459\n3467  9.993182 1.977595 -1184.685\n3468  9.988415 2.028423 -1185.140\n3469  9.973902 1.972633 -1184.829\n3470 10.040405 2.004033 -1184.867\n3471  9.975966 1.970083 -1184.831\n3472 10.038916 2.009865 -1184.916\n3473  9.992787 2.081540 -1186.833\n3474  9.971144 1.975616 -1184.836\n3475  9.937133 2.078041 -1187.229\n3476 10.098399 2.004262 -1185.766\n3477  9.981970 2.047735 -1185.655\n3478 10.122405 1.992738 -1186.326\n3479 10.106057 2.018519 -1186.111\n3480 10.101067 2.009073 -1185.872\n3481 10.037471 2.050307 -1185.764\n3482 10.080064 1.913133 -1186.776\n3483 10.026923 1.940987 -1185.215\n3484 10.067603 1.921620 -1186.226\n3485  9.946430 2.058056 -1186.341\n3486  9.977010 1.971161 -1184.814\n3487 10.036429 2.001494 -1184.815\n3488  9.985355 1.987090 -1184.706\n3489 10.020932 1.946860 -1185.058\n3490 10.020861 1.976680 -1184.687\n3491  9.963271 1.964665 -1185.006\n3492 10.015736 1.951461 -1184.954\n3493 10.030964 1.992689 -1184.728\n3494 10.040955 1.976435 -1184.810\n3495  9.999878 1.923820 -1185.665\n3496 10.012875 2.022138 -1184.979\n3497  9.912418 2.020936 -1186.057\n3498  9.944252 1.989919 -1185.151\n3499  9.969404 1.970141 -1184.889\n3500 10.097398 1.973465 -1185.723\n3501 10.093997 1.989500 -1185.598\n3502  9.915111 1.983838 -1185.724\n3503 10.155338 1.932481 -1188.321\n3504 10.114390 1.968224 -1186.200\n3505 10.012788 1.967831 -1184.728\n3506 10.037100 1.980071 -1184.765\n3507  9.972642 1.994939 -1184.818\n3508  9.995750 2.005789 -1184.764\n3509 10.024207 1.976720 -1184.700\n3510 10.024686 1.998682 -1184.726\n3511  9.996011 1.961504 -1184.809\n3512 10.014287 1.995942 -1184.678\n3513 10.004985 1.969895 -1184.707\n3514 10.025273 1.970237 -1184.745\n3515  9.978325 2.007228 -1184.867\n3516 10.074215 2.057542 -1186.415\n3517 10.090135 1.988753 -1185.514\n3518  9.926311 1.982486 -1185.481\n3519  9.996708 2.037893 -1185.326\n3520  9.975995 1.878755 -1187.944\n3521  9.979481 1.902469 -1186.623\n3522 10.004266 2.021542 -1184.966\n3523 10.083799 1.911912 -1186.903\n3524  9.957458 1.966874 -1185.054\n3525 10.085422 1.992371 -1185.425\n3526  9.883989 2.015385 -1186.738\n3527  9.890793 2.011289 -1186.488\n3528 10.026143 2.028280 -1185.137\n3529 10.053471 1.954461 -1185.173\n3530  9.980724 1.958486 -1184.924\n3531 10.022079 2.076429 -1186.618\n3532 10.073448 1.838457 -1191.515\n3533 10.067827 1.868258 -1189.019\n3534 10.084521 1.888003 -1188.096\n3535 10.025749 2.091454 -1187.296\n3536  9.898651 1.993104 -1186.145\n3537 10.104830 1.895075 -1188.204\n3538 10.084204 2.010366 -1185.530\n3539  9.934401 1.967567 -1185.412\n3540  9.926541 1.948197 -1185.866\n3541  9.998324 2.046323 -1185.548\n3542 10.069174 2.025138 -1185.498\n3543 10.005947 2.046028 -1185.530\n3544  9.941628 2.049284 -1186.138\n3545  9.944273 2.070519 -1186.819\n3546  9.941279 2.100048 -1188.171\n3547 10.036505 2.077189 -1186.723\n3548  9.933282 2.030200 -1185.798\n3549  9.929813 2.031479 -1185.889\n3550 10.075042 1.953835 -1185.505\n3551 10.037043 1.955509 -1184.992\n3552 10.082371 1.973409 -1185.405\n3553  9.970831 2.013044 -1184.997\n3554  9.919264 2.005247 -1185.706\n3555  9.915599 2.001368 -1185.757\n3556 10.096350 1.976080 -1185.682\n3557 10.085271 1.962822 -1185.565\n3558 10.098150 1.960930 -1185.873\n3559  9.914938 2.010376 -1185.854\n3560  9.916549 2.050717 -1186.647\n3561 10.006109 1.938346 -1185.229\n3562  9.982153 2.011978 -1184.897\n3563 10.000151 1.960184 -1184.816\n3564  9.995385 1.986997 -1184.663\n3565  9.878225 2.062148 -1188.004\n3566 10.030121 1.914837 -1186.056\n3567 10.050867 2.023318 -1185.229\n3568 10.032323 1.992736 -1184.736\n3569  9.966959 1.964877 -1184.964\n3570 10.063368 1.985143 -1185.043\n3571  9.954941 2.029191 -1185.445\n3572  9.950335 2.044761 -1185.882\n3573 10.147906 1.925240 -1188.277\n3574 10.134524 1.926499 -1187.750\n3575 10.108391 1.940920 -1186.522\n3576  9.942690 1.992668 -1185.183\n3577  9.964629 1.981093 -1184.881\n3578 10.080795 1.984040 -1185.331\n3579 10.030592 1.969633 -1184.778\n3580  9.988126 2.027894 -1185.130\n3581 10.016697 1.998495 -1184.698\n3582 10.055442 1.952742 -1185.226\n3583 10.086940 1.943993 -1185.934\n3584  9.996598 2.032422 -1185.196\n3585 10.016009 1.941442 -1185.163\n3586 10.021400 2.005783 -1184.772\n3587  9.988468 1.971500 -1184.739\n3588  9.983230 2.006426 -1184.826\n3589  9.981430 1.992340 -1184.740\n3590  9.994291 1.989036 -1184.669\n3591 10.066971 1.934230 -1185.814\n3592 10.033788 1.930508 -1185.539\n3593  9.920248 2.034181 -1186.138\n3594  9.983929 1.939280 -1185.278\n3595  9.968783 1.922280 -1185.911\n3596 10.038849 1.928912 -1185.627\n3597 10.028108 1.941710 -1185.204\n3598 10.044712 2.032452 -1185.353\n3599 10.104328 2.014123 -1186.008\n3600 10.065568 2.017819 -1185.320\n3601  9.968960 1.985960 -1184.830\n3602 10.088699 1.994556 -1185.498\n3603  9.982593 1.962562 -1184.858\n3604 10.032472 2.029261 -1185.191\n3605  9.984131 1.942320 -1185.204\n3606  9.980423 2.002742 -1184.809\n3607 10.056885 2.017822 -1185.205\n3608 10.074743 1.973125 -1185.267\n3609 10.100155 1.963293 -1185.889\n3610  9.853186 2.095249 -1190.144\n3611  9.924876 2.064071 -1186.911\n3612  9.976692 1.906244 -1186.473\n3613 10.026434 2.046391 -1185.584\n3614 10.044456 1.963653 -1184.945\n3615 10.045051 1.962770 -1184.962\n3616 10.001589 1.953161 -1184.919\n3617 10.032643 1.982141 -1184.729\n3618 10.016328 1.989577 -1184.659\n3619 10.037679 2.003328 -1184.839\n3620  9.976847 1.966987 -1184.851\n3621 10.064650 2.052147 -1186.103\n3622 10.079042 2.018676 -1185.548\n3623  9.932197 1.954794 -1185.626\n3624 10.114910 2.002940 -1186.164\n3625  9.963986 1.947180 -1185.274\n3626  9.954432 1.948875 -1185.361\n3627 10.062203 2.035616 -1185.620\n3628 10.020145 2.031560 -1185.183\n3629  9.996721 1.942417 -1185.145\n3630 10.094204 2.038011 -1186.224\n3631 10.015778 2.039036 -1185.350\n3632 10.023002 2.075601 -1186.587\n3633 10.060063 2.038029 -1185.651\n3634 10.084649 1.918737 -1186.650\n3635  9.942421 1.991044 -1185.183\n3636 10.010029 1.975363 -1184.671\n3637 10.105387 1.964303 -1186.006\n3638 10.070383 2.035141 -1185.726\n3639 10.058013 2.037133 -1185.603\n3640 10.011983 1.971221 -1184.699\n3641 10.013778 1.992898 -1184.663\n3642 10.021834 1.954200 -1184.925\n3643  9.969135 2.029867 -1185.303\n3644 10.019696 1.993087 -1184.678\n3645 10.075175 1.944335 -1185.696\n3646 10.047128 1.976861 -1184.866\n3647 10.014311 1.941412 -1185.160\n3648  9.999642 2.031397 -1185.167\n3649 10.011024 1.995660 -1184.672\n3650 10.055086 2.007636 -1185.050\n3651 10.019897 1.978934 -1184.675\n3652  9.914633 2.032061 -1186.214\n3653  9.864864 1.998896 -1187.228\n3654  9.872582 2.004531 -1186.993\n3655  9.981111 2.023707 -1185.088\n3656 10.035770 1.950686 -1185.065\n3657 10.048800 2.034070 -1185.428\n3658  9.964053 1.940213 -1185.431\n3659 10.099615 2.002155 -1185.777\n3660 10.000096 1.998021 -1184.690\n3661  9.935846 1.978845 -1185.307\n3662 10.116351 1.947700 -1186.584\n3663  9.967990 1.994855 -1184.861\n3664 10.081624 1.998376 -1185.378\n3665  9.895272 1.994426 -1186.242\n3666  9.880486 1.998674 -1186.701\n3667  9.933877 1.957838 -1185.545\n3668  9.914580 1.946383 -1186.178\n3669 10.005384 2.024548 -1185.020\n3670  9.901846 1.917988 -1187.376\n3671  9.944061 1.972255 -1185.202\n3672 10.018145 1.992752 -1184.672\n3673  9.987075 2.007954 -1184.821\n3674 10.010841 1.984848 -1184.646\n3675  9.934736 2.023307 -1185.640\n3676 10.002143 1.973606 -1184.683\n3677 10.063068 2.001141 -1185.094\n3678 10.077049 1.996004 -1185.283\n3679 10.038375 1.963613 -1184.892\n3680 10.096111 2.021021 -1185.922\n3681 10.097592 1.932543 -1186.477\n3682 10.059271 1.927754 -1185.893\n3683 10.044641 1.934761 -1185.509\n3684  9.969911 1.998481 -1184.862\n3685 10.075647 1.998167 -1185.270\n3686 10.077094 1.983088 -1185.265\n3687  9.946928 1.971486 -1185.163\n3688 10.025065 2.028375 -1185.134\n3689  9.941633 1.953547 -1185.473\n3690 10.086682 1.976902 -1185.469\n3691  9.928300 1.996389 -1185.457\n3692  9.913112 2.000827 -1185.811\n3693 10.046870 1.967479 -1184.929\n3694  9.944581 1.945583 -1185.580\n3695 10.040888 2.002347 -1184.856\n3696 10.082289 1.972986 -1185.406\n3697  9.932492 1.998144 -1185.385\n3698  9.932492 1.998144 -1185.385\n3699 10.020721 1.975372 -1184.693\n3700  9.986780 2.039069 -1185.392\n3701 10.029962 1.933811 -1185.418\n3702  9.921151 1.956337 -1185.833\n3703  9.961239 2.004979 -1185.003\n3704 10.041908 1.991027 -1184.803\n3705 10.055558 1.925217 -1185.925\n3706  9.958503 2.051241 -1185.967\n3707  9.978716 1.857253 -1189.416\n3708  9.966239 1.969258 -1184.929\n3709 10.028255 1.969547 -1184.765\n3710  9.964286 1.915698 -1186.204\n3711  9.918723 1.984720 -1185.640\n3712 10.096127 1.986484 -1185.644\n3713  9.921040 1.985159 -1185.588\n3714 10.003831 1.996457 -1184.676\n3715 10.049179 1.963183 -1184.999\n3716 10.085890 1.984159 -1185.429\n3717  9.964930 1.925207 -1185.853\n3718  9.932142 1.972549 -1185.412\n3719  9.932142 1.972549 -1185.412\n3720  9.927823 1.882647 -1188.460\n3721  9.957232 1.953910 -1185.231\n3722 10.024686 2.027451 -1185.113\n3723 10.015946 1.969236 -1184.721\n3724 10.106231 2.004900 -1185.956\n3725  9.997024 1.944041 -1185.107\n3726  9.934884 2.090691 -1187.821\n3727  9.923654 2.016202 -1185.739\n3728 10.064036 1.995312 -1185.073\n3729 10.011393 1.945024 -1185.074\n3730  9.881828 1.960554 -1186.852\n3731  9.916099 2.012328 -1185.850\n3732  9.906522 2.024603 -1186.259\n3733  9.925212 1.981204 -1185.507\n3734 10.005701 2.002596 -1184.718\n3735  9.911814 1.984019 -1185.803\n3736  9.995200 1.940022 -1185.206\n3737 10.026343 1.955059 -1184.931\n3738 10.064978 1.974427 -1185.102\n3739 10.034583 1.987651 -1184.740\n3740  9.951564 2.050503 -1186.031\n3741  9.920246 2.067404 -1187.123\n3742  9.970835 1.994708 -1184.833\n3743  9.970704 2.003118 -1184.889\n3744 10.001915 1.926434 -1185.575\n3745 10.054347 1.928616 -1185.800\n3746  9.966090 2.014379 -1185.061\n3747  9.943032 1.992264 -1185.176\n3748 10.070802 1.958741 -1185.354\n3749 10.016253 2.015655 -1184.880\n3750 10.033685 1.955320 -1184.971\n3751 10.004516 2.008383 -1184.776\n3752  9.990501 1.947012 -1185.068\n3753  9.993927 1.997014 -1184.700\n3754  9.981241 1.922696 -1185.788\n3755 10.033114 2.054485 -1185.865\n3756 10.038981 2.059568 -1186.073\n3757 10.022471 2.050757 -1185.697\n3758  9.983993 2.028706 -1185.168\n3759 10.043449 1.986996 -1184.810\n3760 10.052748 1.965582 -1185.013\n3761 10.048196 1.929004 -1185.715\n3762  9.917148 2.041406 -1186.378\n3763  9.889566 2.052820 -1187.378\n3764  9.889566 2.052820 -1187.378\n3765  9.895580 2.021104 -1186.485\n3766  9.950091 2.067407 -1186.619\n3767 10.068100 1.979873 -1185.124\n3768  9.946198 1.996388 -1185.143\n3769  9.961773 2.059888 -1186.210\n3770 10.060707 2.008960 -1185.135\n3771 10.008500 1.917928 -1185.867\n3772 10.026814 1.949755 -1185.026\n3773  9.999891 1.978892 -1184.662\n3774 10.038572 2.030016 -1185.249\n3775 10.088738 1.926507 -1186.463\n3776 10.121770 1.909805 -1187.986\n3777 10.088278 1.873261 -1189.091\n3778  9.995961 1.937087 -1185.278\n3779 10.017390 2.038436 -1185.338\n3780 10.049595 1.968971 -1184.944\n3781 10.061915 1.935855 -1185.691\n3782 10.046492 2.030648 -1185.330\n3783  9.988668 2.022871 -1185.031\n3784 10.057782 2.004484 -1185.052\n3785  9.971249 1.947297 -1185.196\n3786 10.033345 1.993528 -1184.746\n3787  9.993032 1.981094 -1184.675\n3788 10.030173 2.025478 -1185.101\n3789  9.986840 1.949453 -1185.037\n3790 10.064631 2.041429 -1185.798\n3791  9.950165 1.933402 -1185.797\n3792 10.120631 1.998602 -1186.296\n3793 10.033889 2.054503 -1185.870\n3794 10.062385 1.971377 -1185.085\n3795  9.946027 2.119233 -1189.133\n3796  9.937172 2.125479 -1189.626\n3797  9.939399 2.084796 -1187.482\n3798 10.053645 1.964276 -1185.038\n3799  9.964548 2.012112 -1185.046\n3800  9.997004 2.015203 -1184.876\n3801 10.000520 1.970870 -1184.704\n3802 10.000520 1.970870 -1184.704\n3803  9.938511 2.010782 -1185.389\n3804 10.071691 1.964154 -1185.298\n3805 10.014418 1.914438 -1186.008\n3806 10.046925 2.053367 -1185.937\n3807 10.137585 2.063230 -1188.077\n3808  9.959426 1.989872 -1184.938\n3809  9.956570 1.980500 -1184.978\n3810  9.961188 1.978219 -1184.929\n3811 10.008625 1.985268 -1184.644\n3812 10.012330 1.992368 -1184.659\n3813 10.027729 1.957267 -1184.904\n3814  9.980324 1.931826 -1185.503\n3815 10.038716 1.965557 -1184.874\n3816  9.975452 2.005188 -1184.868\n3817 10.103984 1.939738 -1186.436\n3818  9.910847 1.990059 -1185.824\n3819 10.002116 1.962816 -1184.780\n3820  9.975168 1.961994 -1184.920\n3821 10.107019 2.046862 -1186.740\n3822  9.956405 2.026115 -1185.365\n3823 10.093533 1.985009 -1185.588\n3824 10.002418 2.044337 -1185.485\n3825  9.888138 2.047784 -1187.273\n3826 10.026814 1.910389 -1186.218\n3827  9.930428 2.040562 -1186.090\n3828 10.046438 2.052556 -1185.907\n3829 10.002276 2.061921 -1186.040\n3830 10.050382 1.963794 -1185.005\n3831 10.066535 1.960463 -1185.262\n3832  9.964975 1.994292 -1184.889\n3833 10.026247 1.999662 -1184.740\n3834 10.073894 2.058487 -1186.441\n3835 10.104254 2.075008 -1187.626\n3836 10.122254 2.047209 -1187.140\n3837 10.122645 2.054517 -1187.363\n3838 10.101199 2.022050 -1186.052\n3839 10.096086 1.982922 -1185.648\n3840 10.088682 1.989614 -1185.485\n3841 10.001951 1.939198 -1185.211\n3842 10.070281 1.956473 -1185.380\n3843 10.084014 1.951368 -1185.719\n3844  9.944057 2.075404 -1187.014\n3845  9.962306 2.021318 -1185.209\n3846  9.973187 2.027013 -1185.209\n3847 10.085267 1.967039 -1185.517\n3848 10.097103 1.955246 -1185.936\n3849  9.975079 1.934572 -1185.467\n3850 10.054549 2.077116 -1186.879\n3851 10.059252 1.929222 -1185.846\n3852 10.070331 1.954270 -1185.417\n3853  9.970975 2.031502 -1185.322\n3854 10.047176 1.945328 -1185.276\n3855 10.035174 1.991705 -1184.752\n3856  9.981670 1.987302 -1184.728\n3857 10.090806 1.937203 -1186.187\n3858  9.921773 1.984068 -1185.574\n3859  9.922644 1.931936 -1186.363\n3860 10.036756 2.069793 -1186.429\n3861 10.019733 1.904764 -1186.432\n3862  9.952820 2.046599 -1185.900\n3863 10.020062 2.003280 -1184.744\n3864  9.981953 2.012218 -1184.901\n3865  9.941956 2.015469 -1185.393\n3866 10.075264 1.956909 -1185.458\n3867 10.089016 1.942435 -1186.015\n3868  9.995996 1.918817 -1185.851\n3869  9.989104 1.931272 -1185.467\n3870 10.018126 2.061510 -1186.036\n3871 10.035342 1.942353 -1185.236\n3872 10.031861 1.955407 -1184.957\n3873  9.982665 1.994513 -1184.741\n3874  9.980863 2.003765 -1184.815\n3875 10.001903 1.948881 -1184.997\n3876 10.013044 2.022665 -1184.989\n3877 10.092041 1.929183 -1186.450\n3878  9.962034 2.029541 -1185.368\n3879 10.051481 1.942513 -1185.387\n3880  9.994795 1.988834 -1184.667\n3881 10.026650 1.976827 -1184.711\n3882  9.953438 1.976742 -1185.034\n3883  9.914100 2.024391 -1186.076\n3884 10.096768 1.948297 -1186.059\n3885 10.080218 1.961184 -1185.487\n3886  9.999261 2.000656 -1184.710\n3887  9.929497 1.959081 -1185.612\n3888  9.964956 1.987012 -1184.872\n3889 10.039034 1.940831 -1185.301\n3890 10.020478 1.943628 -1185.126\n3891  9.973153 1.955206 -1185.034\n3892 10.042773 2.016856 -1185.043\n3893 10.051804 2.003999 -1184.977\n3894  9.938963 1.953228 -1185.526\n3895  9.979875 1.915656 -1186.056\n3896  9.983683 1.977561 -1184.731\n3897 10.108967 2.000297 -1185.991\n3898  9.925014 1.957517 -1185.730\n3899  9.880870 1.983279 -1186.677\n3900  9.924203 1.967211 -1185.621\n3901  9.929250 1.992611 -1185.424\n3902 10.064706 1.908083 -1186.716\n3903 10.036055 1.993709 -1184.765\n3904 10.014147 1.977536 -1184.666\n3905 10.014147 1.977536 -1184.666\n3906 10.023633 1.956334 -1184.899\n3907 10.020557 1.948592 -1185.022\n3908  9.914685 1.975534 -1185.768\n3909 10.020476 2.031534 -1185.184\n3910  9.995981 1.942277 -1185.150\n3911  9.840546 1.980390 -1188.195\n3912 10.142990 1.931210 -1187.893\n3913 10.039026 2.050953 -1185.795\n3914 10.033370 2.033052 -1185.279\n3915  9.980588 1.940547 -1185.269\n3916 10.023505 1.987118 -1184.678\n3917  9.975849 2.012752 -1184.951\n3918 10.007471 1.966052 -1184.741\n3919  9.953708 1.982053 -1185.012\n3920 10.054850 2.020848 -1185.230\n3921  9.988947 1.997777 -1184.725\n3922  9.928174 1.966180 -1185.549\n3923 10.053840 2.002875 -1184.990\n3924 10.048868 1.999067 -1184.907\n3925 10.081906 1.993589 -1185.361\n3926 10.119816 1.977828 -1186.277\n3927 10.022524 2.005842 -1184.777\n3928 10.001896 2.015670 -1184.874\n3929 10.008622 1.961475 -1184.793\n3930 10.004124 1.955755 -1184.874\n3931 10.111410 1.928940 -1186.949\n3932 10.083366 1.901702 -1187.353\n3933 10.083705 1.900363 -1187.425\n3934 10.056667 1.917069 -1186.231\n3935  9.958258 2.060404 -1186.267\n3936 10.004076 2.046003 -1185.530\n3937 10.060941 2.050185 -1185.994\n3938 10.019437 2.095969 -1187.491\n3939 10.031781 1.947981 -1185.090\n3940  9.979684 1.947778 -1185.115\n3941 10.013340 1.984745 -1184.649\n3942 10.010818 1.973311 -1184.683\n3943  9.943990 2.011279 -1185.305\n3944  9.949541 1.994305 -1185.083\n3945 10.066113 1.976342 -1185.108\n3946 10.068990 2.075931 -1187.013\n3947 10.061252 2.014036 -1185.206\n3948  9.998885 1.976849 -1184.672\n3949  9.970773 2.019218 -1185.089\n3950  9.928472 2.073383 -1187.191\n3951  9.929706 2.100158 -1188.365\n3952  9.958997 1.991032 -1184.946\n3953 10.056884 2.033355 -1185.501\n3954 10.055005 2.023485 -1185.278\n3955 10.062729 2.028430 -1185.470\n3956 10.060899 1.993269 -1185.021\n3957 10.149378 2.038649 -1187.760\n3958 10.155584 2.039318 -1187.992\n3959 10.017205 1.957581 -1184.858\n3960  9.968423 2.015361 -1185.052\n3961  9.859055 2.012224 -1187.536\n3962  9.869312 1.987540 -1187.055\n3963  9.958888 1.958275 -1185.141\n3964 10.047929 1.983544 -1184.855\n3965  9.917719 1.947423 -1186.080\n3966  9.941915 1.955315 -1185.439\n3967 10.037486 2.051859 -1185.811\n3968 10.024329 1.957430 -1184.885\n3969  9.995620 2.019340 -1184.944\n3970 10.086284 1.958237 -1185.649\n3971  9.960690 1.986301 -1184.920\n3972  9.904951 1.953773 -1186.277\n3973 10.061628 1.965924 -1185.124\n3974  9.976320 1.968445 -1184.842\n3975  9.988562 1.933208 -1185.413\n3976 10.014046 1.979150 -1184.660\n3977 10.051423 2.045351 -1185.743\n3978 10.061960 2.053694 -1186.115\n3979 10.009654 1.953079 -1184.917\n3980 10.021988 1.982000 -1184.675\n3981  9.965962 1.911450 -1186.355\n3982  9.957325 2.002911 -1185.032\n3983  9.939633 2.008092 -1185.340\n3984  9.987423 2.026589 -1185.107\n3985 10.085472 1.998509 -1185.452\n3986  9.988338 1.973190 -1184.729\n3987 10.004757 1.997770 -1184.683\n3988  9.972195 1.999508 -1184.848\n3989  9.993180 2.055771 -1185.851\n3990 10.004741 2.073843 -1186.488\n3991 10.040564 2.041804 -1185.546\n3992 10.036061 1.914024 -1186.130\n3993 10.100665 2.044771 -1186.537\n3994  9.934790 1.979046 -1185.326\n3995 10.036083 2.007120 -1184.864\n3996  9.974646 2.053198 -1185.871\n3997  9.905728 2.072251 -1187.625\n3998  9.903439 2.088733 -1188.366\n3999 10.063012 1.982178 -1185.042\n4000  9.949445 1.988534 -1185.070\n\nmean(ajuste$mu)\n\n[1] 10.00715"
  },
  {
    "objectID": "presentaciones/09-medidas-repetidas/medidas-repetidas.html",
    "href": "presentaciones/09-medidas-repetidas/medidas-repetidas.html",
    "title": "Medidas Repetidas",
    "section": "",
    "text": "El tiempo es una variable problemática en el análisis estadístico, sobre todo por la necesidad de postular el supuesto de independencia entre las observaciones.\nSituaciones en las que el tiempo es una variable fundamental:\n\nDinámica poblacional\nCrecimiento de organismos,\nSucesión de comunidades, etc.\n\nLa información necesaria para la construcción de modelos en los que el tiempo interviene como una covariable o como variable explicativa puede obtenerse, según convenga, de observaciones realizadas independientemente sobre sujetos diferentes o sobre los mismos sujetos.\n\n\n\n\\[  \n\\begin{align*}\nn_{t+1} &= rn_t \\\\\nn_{t+1} &= rn_t (1 - \\alpha n_t) \\\\\n\\end{align*}\n\\]\n\nEsta última versión de crecimiento logístico se ve así arreglando un poco los términos \\[  \nn_{t-1} = rn_t - r \\alpha n_t^2\n\\]\nOtra forma de incorporar densodependencia\n\n\\[\nn_{t+1} = rn_t e^{-an_t}\n\\]\n\n¿se puede arreglar ésta de alguna forma conveniente?"
  },
  {
    "objectID": "ejercicios/shinylive/secure.html",
    "href": "ejercicios/shinylive/secure.html",
    "title": "Secure",
    "section": "",
    "text": "define some basic credentials (on data.frame)\ncredentials &lt;- data.frame( user = c(“shiny”, “shinymanager”), # mandatory password = c(“azerty”, “12345”), # mandatory start = c(“2019-04-15”), # optinal (all others) expire = c(NA, “2019-12-31”), admin = c(FALSE, TRUE), comment = “Simple and secure authentification mechanism for single ‘Shiny’ applications.”, stringsAsFactors = FALSE )\nlibrary(shiny) library(shinymanager)\nui &lt;- fluidPage( tags$h2(“My secure application”), verbatimTextOutput(“auth_output”) )\n\n\nWrap your UI with secure_app\nui &lt;- secure_app(ui)\nserver &lt;- function(input, output, session) {\n# call the server part # check_credentials returns a function to authenticate users res_auth &lt;- secure_server( check_credentials = check_credentials(credentials) )\noutput$auth_output &lt;- renderPrint({ reactiveValuesToList(res_auth) })\n# your classic server logic\n}\nshinyApp(ui, server)"
  }
]